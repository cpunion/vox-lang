import "ast" as ast
import "lex" as lex

pub enum ParseError {
  None,
  Lex(lex.LexError),
  UnexpectedToken(lex.TokenKind, lex.TokenKind, i32), // expected, got, byte offset
}

pub fn parse_error_to_string(e: ParseError) -> String {
  return match e {
    ParseError.None => "none",
    ParseError.Lex(le) => "lex error: ".concat(lex.lex_error_to_string(le)),
    ParseError.UnexpectedToken(exp, got, at) =>
      "unexpected token at ".concat(at.to_string())
        .concat(": expected ").concat(lex.token_kind_name(exp))
        .concat(", got ").concat(lex.token_kind_name(got)),
  };
}

struct LineCol { line: i32, col: i32 }

fn build_line_starts(text: String) -> Vec[i32] {
  // line_starts[i] is the byte offset of the first character of line (i+1).
  // Always contains 0 for line 1.
  let mut out: Vec[i32] = Vec();
  out.push(0);
  let mut i: i32 = 0;
  while i < text.len() {
    if text.byte_at(i) == 10 { out.push(i + 1); } // '\n'
    i = i + 1;
  }
  return out;
}

fn pos_to_line_col(text: String, line_starts: Vec[i32], at0: i32) -> LineCol {
  let mut at: i32 = at0;
  if at < 0 { at = 0; }
  if at > text.len() { at = text.len(); }

  // Binary search for the last line start <= at.
  let mut lo: i32 = 0;
  let mut hi: i32 = line_starts.len();
  while lo + 1 < hi {
    let mid: i32 = (lo + hi) / 2;
    if line_starts.get(mid) <= at { lo = mid; } else { hi = mid; }
  }
  let line: i32 = lo + 1;
  let col: i32 = (at - line_starts.get(lo)) + 1;
  return LineCol { line: line, col: col };
}

fn span_at(p: Parser, at: i32) -> ast.Span {
  let lc: LineCol = pos_to_line_col(p.text, p.line_starts, at);
  return ast.Span { file: p.file, line: lc.line, col: lc.col };
}

fn span_tok(p: Parser, t: lex.Token) -> ast.Span { return span_at(p, t.start); }

fn span_expr(exprs: ast.ExprPool, id: i32) -> ast.Span { return ast.expr_pool_span(exprs, id); }

pub fn parse_error_to_string_with_source(file: String, text: String, e: ParseError) -> String {
  return match e {
    ParseError.None => file.concat(":1:1: parse error: none"),
    ParseError.UnexpectedToken(exp, got, at) => format_unexpected_token(file, text, exp, got, at),
    ParseError.Lex(le) => format_lex_error(file, text, le),
  };
}

fn format_unexpected_token(file: String, text: String, exp: lex.TokenKind, got: lex.TokenKind, at: i32) -> String {
  let lc: LineCol = pos_to_line_col(text, build_line_starts(text), at);
  return file.concat(":").concat(lc.line.to_string()).concat(":").concat(lc.col.to_string())
    .concat(": parse error: unexpected token: expected ").concat(lex.token_kind_name(exp))
    .concat(", got ").concat(lex.token_kind_name(got));
}

fn format_lex_error(file: String, text: String, le: lex.LexError) -> String {
  return match le {
    lex.LexError.None => file.concat(":1:1: lex error: none"),
    lex.LexError.UnexpectedChar(at) => format_lex_unexpected_char(file, text, at),
    lex.LexError.UnterminatedString(at) => format_lex_unterminated_string(file, text, at),
  };
}

fn format_lex_unexpected_char(file: String, text: String, at: i32) -> String {
  let lc: LineCol = pos_to_line_col(text, build_line_starts(text), at);
  return file.concat(":").concat(lc.line.to_string()).concat(":").concat(lc.col.to_string())
    .concat(": lex error: unexpected char");
}

fn format_lex_unterminated_string(file: String, text: String, at: i32) -> String {
  let lc: LineCol = pos_to_line_col(text, build_line_starts(text), at);
  return file.concat(":").concat(lc.line.to_string()).concat(":").concat(lc.col.to_string())
    .concat(": lex error: unterminated string");
}

pub struct ParseResult {
  pub prog: ast.Program,
  pub err: ParseError,
}

struct Parser {
  file: String,
  text: String,
  line_starts: Vec[i32],
  toks: Vec[lex.Token],
  pos: i32,
  has_err: bool,
  err: ParseError,
  exprs: ast.ExprPool,
}

struct AdvanceResult { p: Parser, tok: lex.Token }
struct ParseIdentResult { p: Parser, name: String, at: i32 }
struct ParseTypeResult { p: Parser, ty: ast.TypeName }
	struct ParseExprResult { p: Parser, id: i32 }
	struct ParseStmtResult { p: Parser, st: ast.Stmt }
	struct ParseBlockResult { p: Parser, b: ast.Block }
		struct ParseFnResult { p: Parser, f: ast.FuncDecl }
		struct ParseStructResult { p: Parser, s: ast.StructDecl }
		struct ParseEnumResult { p: Parser, e: ast.EnumDecl }
		struct ParseTraitResult { p: Parser, t: ast.TraitDecl }
		struct ParseImplResult { p: Parser, i: ast.ImplDecl }
		struct ParseTraitMethodResult { p: Parser, m: ast.TraitMethodDecl }
		struct ParseTypeAliasResult { p: Parser, t: ast.TypeAliasDecl }
		struct ParseConstResult { p: Parser, c: ast.ConstDecl }
		struct ParseProgramResult { p: Parser, prog: ast.Program }
	struct ParseImportResult { p: Parser, imp: ast.ImportDecl }
	struct ParseStringResult { p: Parser, s: String, at: i32 }
struct ParseImportNameResult { p: Parser, nm: ast.ImportName }
struct ParseParamsResult { p: Parser, params: Vec[ast.Param] }
struct ParseFieldResult { p: Parser, f: ast.FieldDecl }
struct ParseVariantResult { p: Parser, v: ast.EnumVariantDecl }
struct ParsePatResult { p: Parser, pat: ast.Pat }
struct ParseArmResult { p: Parser, arm: ast.MatchArm }
struct ParseTypeParamsResult { p: Parser, tps: Vec[String] }
struct ParseBracedExprResult { p: Parser, id: i32 }
struct ParseTypeDeclResult { p: Parser, is_union: bool, t: ast.TypeAliasDecl, e: ast.EnumDecl }

fn dummy_token() -> lex.Token {
  return lex.Token { kind: lex.TokenKind.Eof, start: 0, end: 0 };
}

fn lex_err_none(e: lex.LexError) -> bool {
  return match e {
    lex.LexError.None => true,
    _ => false,
  };
}

fn peek(p: Parser) -> lex.Token {
  let toks: Vec[lex.Token] = p.toks;
  if p.pos < toks.len() { return toks.get(p.pos); }
  return dummy_token();
}

fn peek_kind(p: Parser) -> lex.TokenKind {
  return peek(p).kind;
}

	fn peek2_kind(p: Parser) -> lex.TokenKind {
	  let toks: Vec[lex.Token] = p.toks;
	  let i: i32 = p.pos + 1;
	  if i < toks.len() { return toks.get(i).kind; }
	  return lex.TokenKind.Eof;
	}

fn peek3_kind(p: Parser) -> lex.TokenKind {
  let toks: Vec[lex.Token] = p.toks;
  let i: i32 = p.pos + 2;
  if i < toks.len() { return toks.get(i).kind; }
  return lex.TokenKind.Eof;
}

fn peek4_kind(p: Parser) -> lex.TokenKind {
  let toks: Vec[lex.Token] = p.toks;
  let i: i32 = p.pos + 3;
  if i < toks.len() { return toks.get(i).kind; }
  return lex.TokenKind.Eof;
}

fn kind_is(k: lex.TokenKind, want: lex.TokenKind) -> bool {
  return lex.token_kind_eq(k, want);
}

fn is_assign_op(k: lex.TokenKind) -> bool {
  return match k {
    lex.TokenKind.Eq => true,
    lex.TokenKind.PlusEq => true,
    lex.TokenKind.MinusEq => true,
    lex.TokenKind.StarEq => true,
    lex.TokenKind.SlashEq => true,
    lex.TokenKind.PercentEq => true,
    lex.TokenKind.AmpEq => true,
    lex.TokenKind.PipeEq => true,
    lex.TokenKind.CaretEq => true,
    lex.TokenKind.LtLtEq => true,
    lex.TokenKind.GtGtEq => true,
    _ => false,
  };
}

fn assign_op_to_binary(k: lex.TokenKind) -> ast.BinaryOp {
  return match k {
    lex.TokenKind.PlusEq => ast.BinaryOp.Add,
    lex.TokenKind.MinusEq => ast.BinaryOp.Sub,
    lex.TokenKind.StarEq => ast.BinaryOp.Mul,
    lex.TokenKind.SlashEq => ast.BinaryOp.Div,
    lex.TokenKind.PercentEq => ast.BinaryOp.Mod,
    lex.TokenKind.AmpEq => ast.BinaryOp.BitAnd,
    lex.TokenKind.PipeEq => ast.BinaryOp.BitOr,
    lex.TokenKind.CaretEq => ast.BinaryOp.BitXor,
    lex.TokenKind.LtLtEq => ast.BinaryOp.Shl,
    lex.TokenKind.GtGtEq => ast.BinaryOp.Shr,
    _ => ast.BinaryOp.Add,
  };
}

fn advance(p: Parser) -> AdvanceResult {
  let tok: lex.Token = peek(p);
  let mut q: Parser = p;
  let toks: Vec[lex.Token] = q.toks;
  if q.pos < toks.len() { q.pos = q.pos + 1; }
  return AdvanceResult { p: q, tok: tok };
}

fn expect(p: Parser, want: lex.TokenKind) -> AdvanceResult {
  if p.has_err {
    return AdvanceResult { p: p, tok: dummy_token() };
  }
  let got: lex.TokenKind = peek_kind(p);
  if kind_is(got, want) {
    return advance(p);
  }
  let mut q: Parser = p;
  let at: i32 = peek(p).start;
  q.has_err = true;
  q.err = ParseError.UnexpectedToken(want, got, at);
  return AdvanceResult { p: q, tok: dummy_token() };
}

fn lexeme(p: Parser, t: lex.Token) -> String {
  let text: String = p.text;
  return text.slice(t.start, t.end);
}

fn parse_ident(p: Parser) -> ParseIdentResult {
  let ar: AdvanceResult = expect(p, lex.TokenKind.Ident);
  let name: String = lexeme(ar.p, ar.tok);
  return ParseIdentResult { p: ar.p, name: name, at: ar.tok.start };
}

fn parse_type_name(p: Parser) -> ParseTypeResult {
  // Unit type: `()`
  if kind_is(peek_kind(p), lex.TokenKind.LParen) && kind_is(peek2_kind(p), lex.TokenKind.RParen) {
    let ar1: AdvanceResult = advance(p);
    let ar2: AdvanceResult = expect(ar1.p, lex.TokenKind.RParen);
    let mut parts: Vec[String] = Vec();
    parts.push("()");
    return ParseTypeResult { p: ar2.p, ty: ast.TypeName { parts: parts, args: Vec() } };
  }

  // Range type: `@range(lo..=hi) Base`
  if kind_is(peek_kind(p), lex.TokenKind.At) {
    let ar0: AdvanceResult = advance(p); // @
    let rkw: ParseIdentResult = parse_ident(ar0.p);
    let mut q: Parser = rkw.p;
    if rkw.name != "range" {
      q.has_err = true;
      q.err = ParseError.UnexpectedToken(lex.TokenKind.Ident, peek_kind(q), rkw.at);
      return ParseTypeResult { p: q, ty: ast.TypeName { parts: Vec(), args: Vec() } };
    }
    let ar1: AdvanceResult = expect(q, lex.TokenKind.LParen);
    let mut q2: Parser = ar1.p;
    let mut lo_neg: bool = false;
    if kind_is(peek_kind(q2), lex.TokenKind.Minus) { lo_neg = true; let arx: AdvanceResult = advance(q2); q2 = arx.p; }
    let arlo: AdvanceResult = expect(q2, lex.TokenKind.Int);
    let mut lo_s: String = lexeme(arlo.p, arlo.tok);
    if lo_neg { lo_s = "-".concat(lo_s); }

    let ardd: AdvanceResult = expect(arlo.p, lex.TokenKind.DotDotEq);
    let mut q3: Parser = ardd.p;
    let mut hi_neg: bool = false;
    if kind_is(peek_kind(q3), lex.TokenKind.Minus) { hi_neg = true; let ary: AdvanceResult = advance(q3); q3 = ary.p; }
    let arhi: AdvanceResult = expect(q3, lex.TokenKind.Int);
    let mut hi_s: String = lexeme(arhi.p, arhi.tok);
    if hi_neg { hi_s = "-".concat(hi_s); }
    let ar2: AdvanceResult = expect(arhi.p, lex.TokenKind.RParen);
    let trb: ParseTypeResult = parse_type_name(ar2.p);
    let mut parts: Vec[String] = Vec();
    parts.push("@range");
    parts.push(lo_s);
    parts.push(hi_s);
    let mut args: Vec[ast.TypeName] = Vec();
    args.push(trb.ty);
    return ParseTypeResult { p: trb.p, ty: ast.TypeName { parts: parts, args: args } };
  }

  let r0: ParseIdentResult = parse_ident(p);
  let mut q: Parser = r0.p;
  let mut parts: Vec[String] = Vec();
  parts.push(r0.name);
  while kind_is(peek_kind(q), lex.TokenKind.Dot) && !q.has_err {
    let ar1: AdvanceResult = advance(q);
    let r2: ParseIdentResult = parse_ident(ar1.p);
    q = r2.p;
    parts.push(r2.name);
  }

  let mut args: Vec[ast.TypeName] = Vec();
  if kind_is(peek_kind(q), lex.TokenKind.LBracket) {
    let ar3: AdvanceResult = advance(q);
    q = ar3.p;
    if !kind_is(peek_kind(q), lex.TokenKind.RBracket) {
      while !q.has_err {
        let tr: ParseTypeResult = parse_type_name(q);
        q = tr.p;
        args.push(tr.ty);
        if kind_is(peek_kind(q), lex.TokenKind.Comma) {
          let ar4: AdvanceResult = advance(q);
          q = ar4.p;
          if kind_is(peek_kind(q), lex.TokenKind.RBracket) {
            break;
          }
          continue;
        }
        break;
      }
    }
    let ar5: AdvanceResult = expect(q, lex.TokenKind.RBracket);
    q = ar5.p;
  }
  return ParseTypeResult { p: q, ty: ast.TypeName { parts: parts, args: args } };
}

fn add_expr(p: Parser, sp: ast.Span, node: ast.ExprNode) -> ParseExprResult {
  let r: ast.AddExprResult = ast.expr_pool_add(p.exprs, node, sp);
  let mut q: Parser = p;
  q.exprs = r.pool;
  return ParseExprResult { p: q, id: r.id };
}

fn parse_string_inner(p: Parser) -> ParseStringResult {
  let ar: AdvanceResult = expect(p, lex.TokenKind.Str);
  let at: i32 = ar.tok.start;
  let mut s: String = lexeme(ar.p, ar.tok); // includes quotes
  let n: i32 = s.len();
  if n >= 2 {
    s = s.slice(1, n - 1);
  }
  // Unescape common sequences in string literals.
  // Supported: \\ \" \n \r \t
  let mut out: String = "";
  let mut i: i32 = 0;
  while i < s.len() {
    let b: i32 = s.byte_at(i);
    if b == 92 { // '\\'
      if (i + 1) < s.len() {
        let nb: i32 = s.byte_at(i + 1);
        if nb == 110 { out = out.concat("\n"); i = i + 2; continue; } // n
        if nb == 114 { out = out.concat("\r"); i = i + 2; continue; } // r
        if nb == 116 { out = out.concat("\t"); i = i + 2; continue; } // t
        if nb == 34 { out = out.concat("\""); i = i + 2; continue; }  // "
        if nb == 92 { out = out.concat("\\"); i = i + 2; continue; }  // \
        // Unknown escape: drop '\' and keep next char as-is.
        out = out.concat(s.slice(i + 1, i + 2));
        i = i + 2;
        continue;
      }
      // trailing '\' -> keep it
      out = out.concat("\\");
      i = i + 1;
      continue;
    }
    out = out.concat(s.slice(i, i + 1));
    i = i + 1;
  }
  s = out;
  return ParseStringResult { p: ar.p, s: s, at: at };
}

fn parse_import_name(p: Parser) -> ParseImportNameResult {
  let r0: ParseIdentResult = parse_ident(p);
  let mut q: Parser = r0.p;
  let mut alias: String = "";
  if kind_is(peek_kind(q), lex.TokenKind.KwAs) {
    let ar1: AdvanceResult = advance(q);
    let r2: ParseIdentResult = parse_ident(ar1.p);
    q = r2.p;
    alias = r2.name;
  }
  return ParseImportNameResult { p: q, nm: ast.ImportName { name: r0.name, alias: alias } };
}

fn parse_import_decl(p: Parser) -> ParseImportResult {
  let ar1: AdvanceResult = expect(p, lex.TokenKind.KwImport);

  // Named imports: `import { a, b as c } from "path"`
  if kind_is(peek_kind(ar1.p), lex.TokenKind.LBrace) {
    let ar2: AdvanceResult = advance(ar1.p);
    let mut q: Parser = ar2.p;
    let mut names: Vec[ast.ImportName] = Vec();
    if !kind_is(peek_kind(q), lex.TokenKind.RBrace) {
      while !q.has_err {
        let nr: ParseImportNameResult = parse_import_name(q);
        q = nr.p;
        names.push(nr.nm);
        if kind_is(peek_kind(q), lex.TokenKind.Comma) {
          let ar3: AdvanceResult = advance(q);
          q = ar3.p;
          if kind_is(peek_kind(q), lex.TokenKind.RBrace) {
            break;
          }
          continue;
        }
        break;
      }
    }
    let ar4: AdvanceResult = expect(q, lex.TokenKind.RBrace);
    let ar5: AdvanceResult = expect(ar4.p, lex.TokenKind.KwFrom);
    let r6: ParseStringResult = parse_string_inner(ar5.p);
    return ParseImportResult { p: r6.p, imp: ast.ImportDecl { file: p.file, path: r6.s, alias: "", names: names } };
  }

  // Module import: `import "path" as alias`
  let r2: ParseStringResult = parse_string_inner(ar1.p);
  let mut q: Parser = r2.p;
  let path: String = r2.s;
  let mut alias: String = "";
  if kind_is(peek_kind(q), lex.TokenKind.KwAs) {
    let ar3: AdvanceResult = advance(q);
    let r4: ParseIdentResult = parse_ident(ar3.p);
    q = r4.p;
    alias = r4.name;
  }
  return ParseImportResult { p: q, imp: ast.ImportDecl { file: p.file, path: path, alias: alias, names: Vec() } };
}

fn parse_braced_expr(p: Parser) -> ParseBracedExprResult {
  // Back-compat helper used by if-expr parsing; now parses a full block expression.
  let r: ParseExprResult = parse_expr_block(p);
  return ParseBracedExprResult { p: r.p, id: r.id };
}

fn if_expr_has_else_ahead(p: Parser) -> bool {
  // Look ahead to see if this `if` is syntactically an if-expression (has an `else`
  // immediately after its then-branch). This is used to disambiguate `if` inside
  // expression blocks so `{ if cond { a } else { b } }` parses as a block tail expression,
  // while still allowing statement `if` without `else`.
  if !kind_is(peek_kind(p), lex.TokenKind.KwIf) { return false; }
  let toks: Vec[lex.Token] = p.toks;
  let mut i: i32 = p.pos + 1;
  let mut dp: i32 = 0; // ()
  let mut db: i32 = 0; // []
  let mut dc: i32 = 0; // {} inside condition
  let mut then_i: i32 = -1;

  while i < toks.len() {
    let k: lex.TokenKind = toks.get(i).kind;
    if kind_is(k, lex.TokenKind.Eof) { return false; }
    if kind_is(k, lex.TokenKind.LParen) { dp = dp + 1; }
    else if kind_is(k, lex.TokenKind.RParen) { if dp > 0 { dp = dp - 1; } }
    else if kind_is(k, lex.TokenKind.LBracket) { db = db + 1; }
    else if kind_is(k, lex.TokenKind.RBracket) { if db > 0 { db = db - 1; } }
    else if kind_is(k, lex.TokenKind.LBrace) {
      if dp == 0 && db == 0 && dc == 0 { then_i = i; break; }
      dc = dc + 1;
    } else if kind_is(k, lex.TokenKind.RBrace) {
      if dc > 0 { dc = dc - 1; }
    }
    i = i + 1;
  }
  if then_i == -1 { return false; }

  // Match the then-branch `{ ... }`.
  i = then_i + 1;
  let mut brace: i32 = 1;
  while i < toks.len() {
    let k2: lex.TokenKind = toks.get(i).kind;
    if kind_is(k2, lex.TokenKind.Eof) { return false; }
    if kind_is(k2, lex.TokenKind.LBrace) { brace = brace + 1; }
    else if kind_is(k2, lex.TokenKind.RBrace) {
      brace = brace - 1;
      if brace == 0 { i = i + 1; break; }
    }
    i = i + 1;
  }
  if brace != 0 { return false; }
  return i < toks.len() && kind_is(toks.get(i).kind, lex.TokenKind.KwElse);
}

fn parse_expr_block(p: Parser) -> ParseExprResult {
  // `{ stmt*; tailExpr }` where tailExpr is optional (missing => unit).
  let ar1: AdvanceResult = expect(p, lex.TokenKind.LBrace);
  let mut q: Parser = ar1.p;
  let sp0: ast.Span = span_tok(p, ar1.tok);
  let mut stmts: Vec[ast.Stmt] = Vec();
  let mut has_tail: bool = false;
  let mut tail: i32 = -1;

  while !q.has_err && !kind_is(peek_kind(q), lex.TokenKind.RBrace) && !kind_is(peek_kind(q), lex.TokenKind.Eof) {
    let k: lex.TokenKind = peek_kind(q);

    let is_stmt: bool =
      kind_is(k, lex.TokenKind.KwLet) ||
      (kind_is(k, lex.TokenKind.KwIf) && !if_expr_has_else_ahead(q)) ||
      kind_is(k, lex.TokenKind.KwWhile) ||
      kind_is(k, lex.TokenKind.KwBreak) ||
      kind_is(k, lex.TokenKind.KwContinue) ||
      kind_is(k, lex.TokenKind.KwReturn) ||
      // assignment: ident <assign-op> ...
      (kind_is(k, lex.TokenKind.Ident) && is_assign_op(peek2_kind(q))) ||
      // field assignment: ident . ident <assign-op> ...
      (kind_is(k, lex.TokenKind.Ident) && kind_is(peek2_kind(q), lex.TokenKind.Dot) && kind_is(peek3_kind(q), lex.TokenKind.Ident) && is_assign_op(peek4_kind(q)));

    if is_stmt {
      let sr: ParseStmtResult = parse_stmt(q);
      q = sr.p;
      stmts.push(sr.st);
      continue;
    }

    let er: ParseExprResult = parse_expr(q, 0);
    q = er.p;
    if kind_is(peek_kind(q), lex.TokenKind.Semicolon) {
      let ar2: AdvanceResult = advance(q);
      q = ar2.p;
      stmts.push(ast.Stmt.Expr(span_expr(q.exprs, er.id), er.id));
      continue;
    }
    has_tail = true;
    tail = er.id;
    break;
  }

  let ar3: AdvanceResult = expect(q, lex.TokenKind.RBrace);
  let b: ast.ExprBlock = ast.ExprBlock { stmts: stmts, has_tail: has_tail, tail: tail };
  return add_expr(ar3.p, sp0, ast.ExprNode.Block(b));
}

fn parse_if_expr(p: Parser) -> ParseExprResult {
  // if <cond> { <expr> } else { <expr> }
  let ar1: AdvanceResult = expect(p, lex.TokenKind.KwIf);
  let sp0: ast.Span = span_tok(p, ar1.tok);
  let r2: ParseExprResult = parse_expr(ar1.p, 0);
  let br1: ParseBracedExprResult = parse_braced_expr(r2.p);
  let ar3: AdvanceResult = expect(br1.p, lex.TokenKind.KwElse);

  // else if ...  ==> else { if ... } (AST nests If)
  if kind_is(peek_kind(ar3.p), lex.TokenKind.KwIf) {
    let r4: ParseExprResult = parse_if_expr(ar3.p);
    return add_expr(r4.p, sp0, ast.ExprNode.If(r2.id, br1.id, r4.id));
  }
  let br2: ParseBracedExprResult = parse_braced_expr(ar3.p);
  return add_expr(br2.p, sp0, ast.ExprNode.If(r2.id, br1.id, br2.id));
}

	fn parse_primary(p: Parser) -> ParseExprResult {
  if p.has_err {
    return ParseExprResult { p: p, id: -1 };
  }
  let k: lex.TokenKind = peek_kind(p);

  if kind_is(k, lex.TokenKind.Int) {
    let ar: AdvanceResult = advance(p);
    let tok: lex.Token = ar.tok;
    return add_expr(ar.p, span_tok(p, tok), ast.ExprNode.Int(lexeme(ar.p, tok)));
  }

  if kind_is(k, lex.TokenKind.Float) {
    let ar: AdvanceResult = advance(p);
    let tok: lex.Token = ar.tok;
    return add_expr(ar.p, span_tok(p, tok), ast.ExprNode.Float(lexeme(ar.p, tok)));
  }

  if kind_is(k, lex.TokenKind.KwTrue) {
    let ar: AdvanceResult = advance(p);
    return add_expr(ar.p, span_tok(p, ar.tok), ast.ExprNode.Bool(true));
  }
  if kind_is(k, lex.TokenKind.KwFalse) {
    let ar: AdvanceResult = advance(p);
    return add_expr(ar.p, span_tok(p, ar.tok), ast.ExprNode.Bool(false));
  }

  if kind_is(k, lex.TokenKind.Ident) {
    let r: ParseIdentResult = parse_ident(p);
    return add_expr(r.p, span_at(p, r.at), ast.ExprNode.Ident(r.name));
  }

  // Enum variant shorthand: `.Variant`
  if kind_is(k, lex.TokenKind.Dot) {
    let ar: AdvanceResult = advance(p);
    let sp0: ast.Span = span_tok(p, ar.tok);
    let r: ParseIdentResult = parse_ident(ar.p);
    return add_expr(r.p, sp0, ast.ExprNode.DotIdent(r.name));
  }

		  if kind_is(k, lex.TokenKind.Str) {
		    let r: ParseStringResult = parse_string_inner(p);
		    return add_expr(r.p, span_at(p, r.at), ast.ExprNode.Str(r.s));
		  }

	if kind_is(k, lex.TokenKind.KwMatch) {
    let ar1: AdvanceResult = advance(p);
    let sp0: ast.Span = span_tok(p, ar1.tok);
    let r2: ParseExprResult = parse_expr(ar1.p, 0);
    let ar3: AdvanceResult = expect(r2.p, lex.TokenKind.LBrace);
    let mut q: Parser = ar3.p;
    let mut arms: Vec[ast.MatchArm] = Vec();
    while !q.has_err && !kind_is(peek_kind(q), lex.TokenKind.RBrace) && !kind_is(peek_kind(q), lex.TokenKind.Eof) {
      let pr: ParsePatResult = parse_pat(q);
      let ar4: AdvanceResult = expect(pr.p, lex.TokenKind.FatArrow);
      let er: ParseExprResult = parse_expr(ar4.p, 0);
      q = er.p;
      arms.push(ast.MatchArm { pat: pr.pat, expr: er.id });
      if kind_is(peek_kind(q), lex.TokenKind.Comma) {
        let ar5: AdvanceResult = advance(q);
        q = ar5.p;
        continue;
      }
      break;
    }
    let ar6: AdvanceResult = expect(q, lex.TokenKind.RBrace);
    return add_expr(ar6.p, sp0, ast.ExprNode.Match(r2.id, arms));
  }

  if kind_is(k, lex.TokenKind.KwIf) {
    return parse_if_expr(p);
  }

  if kind_is(k, lex.TokenKind.LBrace) {
    return parse_expr_block(p);
  }

  let mut q: Parser = p;
  let at: i32 = peek(p).start;
  q.has_err = true;
  q.err = ParseError.UnexpectedToken(lex.TokenKind.Ident, k, at);
  return ParseExprResult { p: q, id: -1 };
}

		fn parse_postfix(p: Parser, base: i32) -> ParseExprResult {
		  let mut q: Parser = p;
		  let mut cur: i32 = base;
		  let mut pending_targs: Vec[ast.TypeName] = Vec();
		  while !q.has_err {
	    // Struct literal: `TypePath { field: expr, ... }`
	    //
	    // Ambiguity note: blocks also start with `{`. We only parse a struct literal
	    // when the first field looks like `ident :` (i.e. `{ Ident Colon ... }`).
	    if kind_is(peek_kind(q), lex.TokenKind.LBrace) &&
	      kind_is(peek2_kind(q), lex.TokenKind.Ident) &&
	      kind_is(peek3_kind(q), lex.TokenKind.Colon) {
	      let sp0: ast.Span = span_expr(q.exprs, cur);
	      let ar1: AdvanceResult = advance(q);
	      let mut r: Parser = ar1.p;
	      let mut fields: Vec[ast.StructLitField] = Vec();
	      while !r.has_err && !kind_is(peek_kind(r), lex.TokenKind.RBrace) && !kind_is(peek_kind(r), lex.TokenKind.Eof) {
	        let fr: ParseIdentResult = parse_ident(r);
	        let ar2: AdvanceResult = expect(fr.p, lex.TokenKind.Colon);
	        let er: ParseExprResult = parse_expr(ar2.p, 0);
	        r = er.p;
	        fields.push(ast.StructLitField { name: fr.name, expr: er.id });
	        if kind_is(peek_kind(r), lex.TokenKind.Comma) {
	          let ar3: AdvanceResult = advance(r);
	          r = ar3.p;
	          continue;
	        }
	        break;
	      }
	      let ar4: AdvanceResult = expect(r, lex.TokenKind.RBrace);
	      let r5: ParseExprResult = add_expr(ar4.p, sp0, ast.ExprNode.StructLit(cur, fields));
	      q = r5.p;
	      cur = r5.id;
	      continue;
	    }
		    if kind_is(peek_kind(q), lex.TokenKind.Dot) {
		      let sp0: ast.Span = span_expr(q.exprs, cur);
		      if pending_targs.len() != 0 {
		        let mut qq: Parser = q;
		        let at: i32 = peek(q).start;
		        qq.has_err = true;
		        qq.err = ParseError.UnexpectedToken(lex.TokenKind.LParen, lex.TokenKind.Dot, at);
		        return ParseExprResult { p: qq, id: cur };
		      }
		      let ar1: AdvanceResult = advance(q);
		      let r2: ParseIdentResult = parse_ident(ar1.p);
		      let r3: ParseExprResult = add_expr(r2.p, sp0, ast.ExprNode.Member(cur, r2.name));
	      q = r3.p;
	      cur = r3.id;
	      continue;
	    }
	    if kind_is(peek_kind(q), lex.TokenKind.KwAs) {
	      if pending_targs.len() != 0 {
	        let mut qq: Parser = q;
	        let at: i32 = peek(q).start;
	        qq.has_err = true;
	        qq.err = ParseError.UnexpectedToken(lex.TokenKind.LParen, lex.TokenKind.KwAs, at);
	        return ParseExprResult { p: qq, id: cur };
	      }
	      let sp0: ast.Span = span_expr(q.exprs, cur);
	      let ar1: AdvanceResult = advance(q);
	      let tr: ParseTypeResult = parse_type_name(ar1.p);
	      let r2: ParseExprResult = add_expr(tr.p, sp0, ast.ExprNode.As(cur, tr.ty));
	      q = r2.p;
	      cur = r2.id;
	      continue;
	    }
	    if kind_is(peek_kind(q), lex.TokenKind.LBracket) {
	      if pending_targs.len() != 0 {
	        let mut qq: Parser = q;
	        let at: i32 = peek(q).start;
	        qq.has_err = true;
	        qq.err = ParseError.UnexpectedToken(lex.TokenKind.LBracket, lex.TokenKind.LBracket, at);
	        return ParseExprResult { p: qq, id: cur };
	      }
	      let ar0: AdvanceResult = advance(q);
	      let mut r: Parser = ar0.p;
	      if !kind_is(peek_kind(r), lex.TokenKind.RBracket) {
	        while !r.has_err {
	          let tr: ParseTypeResult = parse_type_name(r);
	          r = tr.p;
	          pending_targs.push(tr.ty);
	          if kind_is(peek_kind(r), lex.TokenKind.Comma) {
	            let arx: AdvanceResult = advance(r);
	            r = arx.p;
	            continue;
	          }
	          break;
	        }
	      }
	      let ar1: AdvanceResult = expect(r, lex.TokenKind.RBracket);
	      q = ar1.p;
	      continue;
	    }
	    if kind_is(peek_kind(q), lex.TokenKind.LParen) {
	      let sp0: ast.Span = span_expr(q.exprs, cur);
	      let ar1: AdvanceResult = advance(q);
	      let mut r: Parser = ar1.p;
	      let mut args: Vec[i32] = Vec();
      if !kind_is(peek_kind(r), lex.TokenKind.RParen) {
        while !r.has_err {
          let er: ParseExprResult = parse_expr(r, 0);
          r = er.p;
          args.push(er.id);
          if kind_is(peek_kind(r), lex.TokenKind.Comma) {
            let ar2: AdvanceResult = advance(r);
            r = ar2.p;
            if kind_is(peek_kind(r), lex.TokenKind.RParen) {
              break;
            }
            continue;
          }
          break;
        }
	      }
	      let ar3: AdvanceResult = expect(r, lex.TokenKind.RParen);
	      let r4: ParseExprResult = add_expr(ar3.p, sp0, ast.ExprNode.Call(cur, pending_targs, args));
	      q = r4.p;
	      cur = r4.id;
	      pending_targs = Vec();
	      continue;
	    }
	    break;
	  }
	  if pending_targs.len() != 0 {
	    let mut qq: Parser = q;
	    let at: i32 = peek(q).start;
	    qq.has_err = true;
	    qq.err = ParseError.UnexpectedToken(lex.TokenKind.LParen, peek_kind(q), at);
	    return ParseExprResult { p: qq, id: cur };
	  }
		  return ParseExprResult { p: q, id: cur };
		}

fn parse_pat(p: Parser) -> ParsePatResult {
  let sp0: ast.Span = span_at(p, peek(p).start);
  let k: lex.TokenKind = peek_kind(p);
  // Negative integer pattern: `-123`
  if kind_is(k, lex.TokenKind.Minus) && kind_is(peek2_kind(p), lex.TokenKind.Int) {
    let ar0: AdvanceResult = advance(p);
    let ar1: AdvanceResult = expect(ar0.p, lex.TokenKind.Int);
    let tok: lex.Token = ar1.tok;
    let text: String = "-".concat(lexeme(ar1.p, tok));
    return ParsePatResult { p: ar1.p, pat: ast.Pat.Int(sp0, text) };
  }
  if kind_is(k, lex.TokenKind.Int) {
    let ar1: AdvanceResult = advance(p);
    let tok: lex.Token = ar1.tok;
    return ParsePatResult { p: ar1.p, pat: ast.Pat.Int(sp0, lexeme(ar1.p, tok)) };
  }
  if kind_is(k, lex.TokenKind.Str) {
    let r: ParseStringResult = parse_string_inner(p);
    return ParsePatResult { p: r.p, pat: ast.Pat.Str(sp0, r.s) };
  }

  // Enum variant shorthand pattern: `.Variant(x, y, ...)`
  if kind_is(k, lex.TokenKind.Dot) {
    let ar0: AdvanceResult = advance(p);
    let r0: ParseIdentResult = parse_ident(ar0.p);
    let mut q: Parser = r0.p;
    let mut args: Vec[ast.Pat] = Vec();
    if kind_is(peek_kind(q), lex.TokenKind.LParen) {
      let ar3: AdvanceResult = advance(q);
      q = ar3.p;
      if !kind_is(peek_kind(q), lex.TokenKind.RParen) {
        while !q.has_err {
          let pr: ParsePatResult = parse_pat(q);
          q = pr.p;
          args.push(pr.pat);
          if kind_is(peek_kind(q), lex.TokenKind.Comma) {
            let ar4: AdvanceResult = advance(q);
            q = ar4.p;
            if kind_is(peek_kind(q), lex.TokenKind.RParen) { break; }
            continue;
          }
          break;
        }
      }
      let ar5: AdvanceResult = expect(q, lex.TokenKind.RParen);
      q = ar5.p;
    }
    return ParsePatResult { p: q, pat: ast.Pat.EnumVariant(sp0, Vec(), r0.name, args) };
  }

  // Wildcard: `_`
  if kind_is(k, lex.TokenKind.Ident) {
    let r0: ParseIdentResult = parse_ident(p);
    if r0.name == "_" {
      return ParsePatResult { p: r0.p, pat: ast.Pat.Wild(sp0) };
    }

    // path: a.b.c
    let mut q: Parser = r0.p;
    let mut parts: Vec[String] = Vec();
    parts.push(r0.name);
    while kind_is(peek_kind(q), lex.TokenKind.Dot) && !q.has_err {
      let ar1: AdvanceResult = advance(q);
      let r2: ParseIdentResult = parse_ident(ar1.p);
      q = r2.p;
      parts.push(r2.name);
    }

    // optional payload patterns: (p0, p1, ...)
    let mut args: Vec[ast.Pat] = Vec();
    if kind_is(peek_kind(q), lex.TokenKind.LParen) {
      let ar3: AdvanceResult = advance(q);
      q = ar3.p;
      if !kind_is(peek_kind(q), lex.TokenKind.RParen) {
        while !q.has_err {
          let pr: ParsePatResult = parse_pat(q);
          q = pr.p;
          args.push(pr.pat);
          if kind_is(peek_kind(q), lex.TokenKind.Comma) {
            let ar4: AdvanceResult = advance(q);
            q = ar4.p;
            if kind_is(peek_kind(q), lex.TokenKind.RParen) {
              break;
            }
            continue;
          }
          break;
        }
      }
      let ar5: AdvanceResult = expect(q, lex.TokenKind.RParen);
      q = ar5.p;
    }

    if parts.len() >= 2 {
      let n: i32 = parts.len();
      let variant: String = parts.get(n - 1);
      let mut enum_parts: Vec[String] = Vec();
      let mut i: i32 = 0;
      while i < n - 1 {
        enum_parts.push(parts.get(i));
        i = i + 1;
      }
      return ParsePatResult { p: q, pat: ast.Pat.EnumVariant(sp0, enum_parts, variant, args) };
    }

    if args.len() != 0 {
      // `x(...)` with no path doesn't exist in this subset.
      let mut qq: Parser = q;
      let at: i32 = peek(p).start;
      qq.has_err = true;
      qq.err = ParseError.UnexpectedToken(lex.TokenKind.FatArrow, lex.TokenKind.LParen, at);
      return ParsePatResult { p: qq, pat: ast.Pat.Wild(sp0) };
    }
    return ParsePatResult { p: q, pat: ast.Pat.Bind(sp0, parts.get(0)) };
  }

  let mut q: Parser = p;
  let at: i32 = peek(p).start;
  q.has_err = true;
  q.err = ParseError.UnexpectedToken(lex.TokenKind.Ident, k, at);
  return ParsePatResult { p: q, pat: ast.Pat.Wild(sp0) };
}

fn parse_prefix(p: Parser) -> ParseExprResult {
  let k: lex.TokenKind = peek_kind(p);
  if kind_is(k, lex.TokenKind.Minus) {
    let ar: AdvanceResult = advance(p);
    let r: ParseExprResult = parse_expr(ar.p, 11);
    if r.p.has_err { return r; }
    return add_expr(r.p, span_tok(p, ar.tok), ast.ExprNode.Unary(ast.UnaryOp.Neg, r.id));
  }
  if kind_is(k, lex.TokenKind.Not) {
    let ar: AdvanceResult = advance(p);
    let r: ParseExprResult = parse_expr(ar.p, 11);
    if r.p.has_err { return r; }
    return add_expr(r.p, span_tok(p, ar.tok), ast.ExprNode.Unary(ast.UnaryOp.Not, r.id));
  }
  if kind_is(k, lex.TokenKind.LParen) {
    let ar1: AdvanceResult = advance(p);
    let r2: ParseExprResult = parse_expr(ar1.p, 0);
    let ar3: AdvanceResult = expect(r2.p, lex.TokenKind.RParen);
    // Allow postfix ops on parenthesized expressions: `(expr).method(...)`.
    return parse_postfix(ar3.p, r2.id);
  }
  let r0: ParseExprResult = parse_primary(p);
  return parse_postfix(r0.p, r0.id);
}

fn infix_prec(k: lex.TokenKind) -> i32 {
  return match k {
    lex.TokenKind.OrOr => 1,
    lex.TokenKind.AndAnd => 2,
    lex.TokenKind.Pipe => 3,
    lex.TokenKind.Caret => 4,
    lex.TokenKind.Amp => 5,
    lex.TokenKind.EqEq => 6,
    lex.TokenKind.Ne => 6,
    lex.TokenKind.Lt => 7,
    lex.TokenKind.Le => 7,
    lex.TokenKind.Gt => 7,
    lex.TokenKind.Ge => 7,
    lex.TokenKind.LtLt => 8,
    lex.TokenKind.GtGt => 8,
    lex.TokenKind.Plus => 9,
    lex.TokenKind.Minus => 9,
    lex.TokenKind.Star => 10,
    lex.TokenKind.Slash => 10,
    lex.TokenKind.Percent => 10,
    _ => 0,
  };
}

fn infix_op(k: lex.TokenKind) -> ast.BinaryOp {
  return match k {
    lex.TokenKind.Plus => ast.BinaryOp.Add,
    lex.TokenKind.Minus => ast.BinaryOp.Sub,
    lex.TokenKind.Star => ast.BinaryOp.Mul,
    lex.TokenKind.Slash => ast.BinaryOp.Div,
    lex.TokenKind.Percent => ast.BinaryOp.Mod,
    lex.TokenKind.Amp => ast.BinaryOp.BitAnd,
    lex.TokenKind.Pipe => ast.BinaryOp.BitOr,
    lex.TokenKind.Caret => ast.BinaryOp.BitXor,
    lex.TokenKind.LtLt => ast.BinaryOp.Shl,
    lex.TokenKind.GtGt => ast.BinaryOp.Shr,
    lex.TokenKind.EqEq => ast.BinaryOp.Eq,
    lex.TokenKind.Ne => ast.BinaryOp.Ne,
    lex.TokenKind.Lt => ast.BinaryOp.Lt,
    lex.TokenKind.Le => ast.BinaryOp.Le,
    lex.TokenKind.Gt => ast.BinaryOp.Gt,
    lex.TokenKind.Ge => ast.BinaryOp.Ge,
    lex.TokenKind.AndAnd => ast.BinaryOp.AndAnd,
    lex.TokenKind.OrOr => ast.BinaryOp.OrOr,
    _ => ast.BinaryOp.Add,
  };
}

fn parse_expr(p: Parser, min_prec: i32) -> ParseExprResult {
  let r0: ParseExprResult = parse_prefix(p);
  let mut q: Parser = r0.p;
  let mut left: i32 = r0.id;
  while !q.has_err {
    let k: lex.TokenKind = peek_kind(q);
    let prec: i32 = infix_prec(k);
    if prec < min_prec || prec == 0 {
      break;
    }
    let ar1: AdvanceResult = advance(q);
    let op: ast.BinaryOp = infix_op(k);
    let r2: ParseExprResult = parse_expr(ar1.p, prec + 1);
    let sp0: ast.Span = span_expr(r2.p.exprs, left);
    let r3: ParseExprResult = add_expr(r2.p, sp0, ast.ExprNode.Binary(op, left, r2.id));
    q = r3.p;
    left = r3.id;
  }
  return ParseExprResult { p: q, id: left };
}

fn parse_stmt(p: Parser) -> ParseStmtResult {
  let sp0: ast.Span = span_at(p, peek(p).start);
  let k: lex.TokenKind = peek_kind(p);
  if kind_is(k, lex.TokenKind.KwLet) {
    let ar1: AdvanceResult = advance(p);
    let mut q: Parser = ar1.p;

    // optional `mut`
    let mut is_mut: bool = false;
    if kind_is(peek_kind(q), lex.TokenKind.KwMut) {
      let ar2: AdvanceResult = advance(q);
      q = ar2.p;
      is_mut = true;
    }

    let r3: ParseIdentResult = parse_ident(q);
    q = r3.p;
    let name: String = r3.name;

    // optional type annotation: : Type
    let mut has_ann: bool = false;
    let mut ann: ast.TypeName = ast.TypeName { parts: Vec(), args: Vec() };
    if kind_is(peek_kind(q), lex.TokenKind.Colon) {
      let ar4: AdvanceResult = advance(q);
      let r5: ParseTypeResult = parse_type_name(ar4.p);
      q = r5.p;
      has_ann = true;
      ann = r5.ty;
    }

    let ar6: AdvanceResult = expect(q, lex.TokenKind.Eq);
    let r7: ParseExprResult = parse_expr(ar6.p, 0);
    let ar8: AdvanceResult = expect(r7.p, lex.TokenKind.Semicolon);
    return ParseStmtResult { p: ar8.p, st: ast.Stmt.Let(sp0, is_mut, name, has_ann, ann, r7.id) };
  }
  if kind_is(k, lex.TokenKind.KwIf) {
    let ar1: AdvanceResult = advance(p);
    let r2: ParseExprResult = parse_expr(ar1.p, 0);
    let r3: ParseBlockResult = parse_block(r2.p);
    let mut q: Parser = r3.p;
    let mut has_else: bool = false;
    let mut else_b: ast.Block = ast.Block { stmts: Vec() };
    if kind_is(peek_kind(q), lex.TokenKind.KwElse) {
      let ar4: AdvanceResult = advance(q);
      has_else = true;
      if kind_is(peek_kind(ar4.p), lex.TokenKind.KwIf) {
        // else if ... ; lower into else { if ... }
        let r5: ParseStmtResult = parse_stmt(ar4.p);
        let mut ss: Vec[ast.Stmt] = Vec();
        ss.push(r5.st);
        q = r5.p;
        else_b = ast.Block { stmts: ss };
      } else {
        let r5: ParseBlockResult = parse_block(ar4.p);
        q = r5.p;
        else_b = r5.b;
      }
    }
    return ParseStmtResult { p: q, st: ast.Stmt.If(sp0, r2.id, r3.b, has_else, else_b) };
  }
  if kind_is(k, lex.TokenKind.KwWhile) {
    let ar1: AdvanceResult = advance(p);
    let r2: ParseExprResult = parse_expr(ar1.p, 0);
    let r3: ParseBlockResult = parse_block(r2.p);
    return ParseStmtResult { p: r3.p, st: ast.Stmt.While(sp0, r2.id, r3.b) };
  }
  if kind_is(k, lex.TokenKind.KwBreak) {
    let ar1: AdvanceResult = advance(p);
    let ar2: AdvanceResult = expect(ar1.p, lex.TokenKind.Semicolon);
    return ParseStmtResult { p: ar2.p, st: ast.Stmt.Break(sp0) };
  }
  if kind_is(k, lex.TokenKind.KwContinue) {
    let ar1: AdvanceResult = advance(p);
    let ar2: AdvanceResult = expect(ar1.p, lex.TokenKind.Semicolon);
    return ParseStmtResult { p: ar2.p, st: ast.Stmt.Continue(sp0) };
  }
  if kind_is(k, lex.TokenKind.KwReturn) {
    let ar1: AdvanceResult = advance(p);
    if kind_is(peek_kind(ar1.p), lex.TokenKind.Semicolon) {
      let ar2: AdvanceResult = expect(ar1.p, lex.TokenKind.Semicolon);
      return ParseStmtResult { p: ar2.p, st: ast.Stmt.Return(sp0, false, -1) };
    }
    let r2: ParseExprResult = parse_expr(ar1.p, 0);
    let ar3: AdvanceResult = expect(r2.p, lex.TokenKind.Semicolon);
    return ParseStmtResult { p: ar3.p, st: ast.Stmt.Return(sp0, true, r2.id) };
  }

  // field assignment: ident . ident <assign-op> expr ;
  if kind_is(k, lex.TokenKind.Ident) &&
     kind_is(peek2_kind(p), lex.TokenKind.Dot) &&
     kind_is(peek3_kind(p), lex.TokenKind.Ident) &&
     is_assign_op(peek4_kind(p)) {
    let r1: ParseIdentResult = parse_ident(p);
    let ar2: AdvanceResult = expect(r1.p, lex.TokenKind.Dot);
    let r3: ParseIdentResult = parse_ident(ar2.p);
    let op_tok: lex.Token = peek(r3.p);
    let ar4: AdvanceResult = advance(r3.p);
    let r5: ParseExprResult = parse_expr(ar4.p, 0);
    let mut q: Parser = r5.p;
    let mut rhs_id: i32 = r5.id;
    if !kind_is(op_tok.kind, lex.TokenKind.Eq) {
      let lhs_add0: ast.AddExprResult = ast.expr_pool_add(
        q.exprs,
        ast.ExprNode.Ident(r1.name),
        span_at(q, op_tok.start)
      );
      let mut lhs_recv_id: i32 = lhs_add0.id;
      let mut q2: Parser = q;
      q2.exprs = lhs_add0.pool;
      let lhs_add1: ast.AddExprResult = ast.expr_pool_add(
        q2.exprs,
        ast.ExprNode.Member(lhs_recv_id, r3.name),
        span_at(q2, op_tok.start)
      );
      lhs_recv_id = lhs_add1.id;
      q2.exprs = lhs_add1.pool;
      let bop: ast.BinaryOp = assign_op_to_binary(op_tok.kind);
      let addb: ast.AddExprResult = ast.expr_pool_add(
        q2.exprs,
        ast.ExprNode.Binary(bop, lhs_recv_id, rhs_id),
        span_at(q2, op_tok.start)
      );
      q = q2;
      q.exprs = addb.pool;
      rhs_id = addb.id;
    }
    let ar6: AdvanceResult = expect(q, lex.TokenKind.Semicolon);
    return ParseStmtResult { p: ar6.p, st: ast.Stmt.AssignField(sp0, r1.name, r3.name, rhs_id) };
  }

  // assignment: ident <assign-op> expr ;
  if kind_is(k, lex.TokenKind.Ident) && is_assign_op(peek2_kind(p)) {
    let r1: ParseIdentResult = parse_ident(p);
    let op_tok: lex.Token = peek(r1.p);
    let ar2: AdvanceResult = advance(r1.p);
    let r3: ParseExprResult = parse_expr(ar2.p, 0);
    let mut q: Parser = r3.p;
    let mut rhs_id: i32 = r3.id;
    if !kind_is(op_tok.kind, lex.TokenKind.Eq) {
      let lhs_add: ast.AddExprResult = ast.expr_pool_add(
        q.exprs,
        ast.ExprNode.Ident(r1.name),
        span_at(q, op_tok.start)
      );
      let bop: ast.BinaryOp = assign_op_to_binary(op_tok.kind);
      let bin_add: ast.AddExprResult = ast.expr_pool_add(
        lhs_add.pool,
        ast.ExprNode.Binary(bop, lhs_add.id, rhs_id),
        span_at(q, op_tok.start)
      );
      q.exprs = bin_add.pool;
      rhs_id = bin_add.id;
    }
    let ar4: AdvanceResult = expect(q, lex.TokenKind.Semicolon);
    return ParseStmtResult { p: ar4.p, st: ast.Stmt.Assign(sp0, r1.name, rhs_id) };
  }

  // expr stmt
  let r1: ParseExprResult = parse_expr(p, 0);
  let ar2: AdvanceResult = expect(r1.p, lex.TokenKind.Semicolon);
  if !ar2.p.has_err {
    return ParseStmtResult { p: ar2.p, st: ast.Stmt.Expr(span_expr(ar2.p.exprs, r1.id), r1.id) };
  }

  let mut q: Parser = p;
  let at: i32 = peek(p).start;
  q.has_err = true;
  q.err = ParseError.UnexpectedToken(lex.TokenKind.KwReturn, k, at);
  return ParseStmtResult { p: q, st: ast.Stmt.Return(sp0, false, -1) };
}

fn parse_block(p: Parser) -> ParseBlockResult {
  let ar1: AdvanceResult = expect(p, lex.TokenKind.LBrace);
  let mut q: Parser = ar1.p;
  let mut stmts: Vec[ast.Stmt] = Vec();
  while !q.has_err && !kind_is(peek_kind(q), lex.TokenKind.RBrace) && !kind_is(peek_kind(q), lex.TokenKind.Eof) {
    let r: ParseStmtResult = parse_stmt(q);
    q = r.p;
    stmts.push(r.st);
  }
  let ar2: AdvanceResult = expect(q, lex.TokenKind.RBrace);
  return ParseBlockResult { p: ar2.p, b: ast.Block { stmts: stmts } };
}

fn parse_fn_decl(p: Parser, is_pub: bool) -> ParseFnResult {
  let ar1: AdvanceResult = expect(p, lex.TokenKind.KwFn);
  let r2: ParseIdentResult = parse_ident(ar1.p);
  let mut q: Parser = r2.p;
  let mut tps: Vec[String] = Vec();
  if kind_is(peek_kind(q), lex.TokenKind.LBracket) {
    let r3: ParseTypeParamsResult = parse_type_params(q);
    q = r3.p;
    tps = r3.tps;
  }
  let _ar4: AdvanceResult = expect(q, lex.TokenKind.LParen);
  let r5: ParseParamsResult = parse_params(_ar4.p);
  let _ar6: AdvanceResult = expect(r5.p, lex.TokenKind.RParen);
  let _ar7: AdvanceResult = expect(_ar6.p, lex.TokenKind.Arrow);
  let r8: ParseTypeResult = parse_type_name(_ar7.p);
  let params: Vec[ast.Param] = r5.params;
  let r9: ParseBlockResult = parse_block(r8.p);
  return ParseFnResult { p: r9.p, f: ast.FuncDecl { file: p.file, is_pub: is_pub, name: r2.name, type_params: tps, params: params, ret: r8.ty, body: r9.b } };
}

fn parse_type_params(p: Parser) -> ParseTypeParamsResult {
  let ar1: AdvanceResult = expect(p, lex.TokenKind.LBracket);
  let mut q: Parser = ar1.p;
  let mut tps: Vec[String] = Vec();
  if kind_is(peek_kind(q), lex.TokenKind.RBracket) {
    let ar2: AdvanceResult = expect(q, lex.TokenKind.RBracket);
    return ParseTypeParamsResult { p: ar2.p, tps: tps };
  }
  while !q.has_err {
    let r1: ParseIdentResult = parse_ident(q);
    q = r1.p;
    tps.push(r1.name);
    if kind_is(peek_kind(q), lex.TokenKind.Comma) {
      let ar3: AdvanceResult = advance(q);
      q = ar3.p;
      if kind_is(peek_kind(q), lex.TokenKind.RBracket) {
        break;
      }
      continue;
    }
    break;
  }
  let ar4: AdvanceResult = expect(q, lex.TokenKind.RBracket);
  return ParseTypeParamsResult { p: ar4.p, tps: tps };
}

fn parse_field_decl(p: Parser) -> ParseFieldResult {
	  let mut q: Parser = p;
	  let mut is_pub: bool = false;
	  if kind_is(peek_kind(q), lex.TokenKind.KwPub) {
	    let ar1: AdvanceResult = advance(q);
	    q = ar1.p;
	    is_pub = true;
	  }
	  let r2: ParseIdentResult = parse_ident(q);
	  let ar3: AdvanceResult = expect(r2.p, lex.TokenKind.Colon);
	  let r4: ParseTypeResult = parse_type_name(ar3.p);
	  return ParseFieldResult { p: r4.p, f: ast.FieldDecl { is_pub: is_pub, name: r2.name, ty: r4.ty } };
}

fn parse_struct_decl(p: Parser, is_pub: bool) -> ParseStructResult {
	  let ar1: AdvanceResult = expect(p, lex.TokenKind.KwStruct);
	  let r2: ParseIdentResult = parse_ident(ar1.p);
	  let ar3: AdvanceResult = expect(r2.p, lex.TokenKind.LBrace);
	  let mut q: Parser = ar3.p;
	  let mut fields: Vec[ast.FieldDecl] = Vec();
	  if !kind_is(peek_kind(q), lex.TokenKind.RBrace) {
	    while !q.has_err {
	      let r: ParseFieldResult = parse_field_decl(q);
	      q = r.p;
	      fields.push(r.f);
	      if kind_is(peek_kind(q), lex.TokenKind.Comma) {
	        let ar4: AdvanceResult = advance(q);
	        q = ar4.p;
	        if kind_is(peek_kind(q), lex.TokenKind.RBrace) {
	          break;
	        }
	        continue;
	      }
	      break;
	    }
	  }
	  let ar5: AdvanceResult = expect(q, lex.TokenKind.RBrace);
	  return ParseStructResult { p: ar5.p, s: ast.StructDecl { file: p.file, is_pub: is_pub, name: r2.name, fields: fields } };
}

fn parse_enum_variant_decl(p: Parser) -> ParseVariantResult {
	  let r1: ParseIdentResult = parse_ident(p);
	  let mut q: Parser = r1.p;
	  let mut fields: Vec[ast.TypeName] = Vec();
	  if kind_is(peek_kind(q), lex.TokenKind.LParen) {
	    let ar2: AdvanceResult = advance(q);
	    q = ar2.p;
	    if !kind_is(peek_kind(q), lex.TokenKind.RParen) {
	      while !q.has_err {
	        let tr: ParseTypeResult = parse_type_name(q);
	        q = tr.p;
	        fields.push(tr.ty);
	        if kind_is(peek_kind(q), lex.TokenKind.Comma) {
	          let ar3: AdvanceResult = advance(q);
	          q = ar3.p;
	          if kind_is(peek_kind(q), lex.TokenKind.RParen) {
	            break;
	          }
	          continue;
	        }
	        break;
	      }
	    }
	    let ar4: AdvanceResult = expect(q, lex.TokenKind.RParen);
	    q = ar4.p;
	  }
	  return ParseVariantResult { p: q, v: ast.EnumVariantDecl { name: r1.name, fields: fields } };
}

fn parse_enum_decl(p: Parser, is_pub: bool) -> ParseEnumResult {
	  let ar1: AdvanceResult = expect(p, lex.TokenKind.KwEnum);
	  let r2: ParseIdentResult = parse_ident(ar1.p);
	  let ar3: AdvanceResult = expect(r2.p, lex.TokenKind.LBrace);
	  let mut q: Parser = ar3.p;
	  let mut vars: Vec[ast.EnumVariantDecl] = Vec();
	  if !kind_is(peek_kind(q), lex.TokenKind.RBrace) {
	    while !q.has_err {
	      let vr: ParseVariantResult = parse_enum_variant_decl(q);
	      q = vr.p;
	      vars.push(vr.v);
	      if kind_is(peek_kind(q), lex.TokenKind.Comma) {
	        let ar4: AdvanceResult = advance(q);
	        q = ar4.p;
	        if kind_is(peek_kind(q), lex.TokenKind.RBrace) {
	          break;
	        }
	        continue;
	      }
	      break;
	    }
	  }
	  let ar5: AdvanceResult = expect(q, lex.TokenKind.RBrace);
	  return ParseEnumResult { p: ar5.p, e: ast.EnumDecl { file: p.file, is_pub: is_pub, name: r2.name, variants: vars } };
}

fn parse_trait_method_decl(p: Parser) -> ParseTraitMethodResult {
  let ar1: AdvanceResult = expect(p, lex.TokenKind.KwFn);
  let r2: ParseIdentResult = parse_ident(ar1.p);
  let ar3: AdvanceResult = expect(r2.p, lex.TokenKind.LParen);
  let r4: ParseParamsResult = parse_params(ar3.p);
  let ar5: AdvanceResult = expect(r4.p, lex.TokenKind.RParen);
  let ar6: AdvanceResult = expect(ar5.p, lex.TokenKind.Arrow);
  let r7: ParseTypeResult = parse_type_name(ar6.p);
  let mut q: Parser = r7.p;
  if kind_is(peek_kind(q), lex.TokenKind.Semicolon) {
    let ar8: AdvanceResult = advance(q);
    q = ar8.p;
  }
  return ParseTraitMethodResult { p: q, m: ast.TraitMethodDecl { name: r2.name, params: r4.params, ret: r7.ty } };
}

fn parse_trait_decl(p: Parser, is_pub: bool) -> ParseTraitResult {
  let ar1: AdvanceResult = expect(p, lex.TokenKind.KwTrait);
  let r2: ParseIdentResult = parse_ident(ar1.p);
  let ar3: AdvanceResult = expect(r2.p, lex.TokenKind.LBrace);
  let mut q: Parser = ar3.p;
  let mut ms: Vec[ast.TraitMethodDecl] = Vec();
  if !kind_is(peek_kind(q), lex.TokenKind.RBrace) {
    while !q.has_err {
      let mr: ParseTraitMethodResult = parse_trait_method_decl(q);
      q = mr.p;
      ms.push(mr.m);
      if kind_is(peek_kind(q), lex.TokenKind.Comma) {
        let ar4: AdvanceResult = advance(q);
        q = ar4.p;
        if kind_is(peek_kind(q), lex.TokenKind.RBrace) { break; }
        continue;
      }
      if kind_is(peek_kind(q), lex.TokenKind.RBrace) { break; }
    }
  }
  let ar5: AdvanceResult = expect(q, lex.TokenKind.RBrace);
  return ParseTraitResult { p: ar5.p, t: ast.TraitDecl { file: p.file, is_pub: is_pub, name: r2.name, methods: ms } };
}

fn parse_impl_decl(p: Parser) -> ParseImplResult {
  let ar1: AdvanceResult = expect(p, lex.TokenKind.KwImpl);
  let tr: ParseTypeResult = parse_type_name(ar1.p);
  let ar2: AdvanceResult = expect(tr.p, lex.TokenKind.KwFor);
  let fr: ParseTypeResult = parse_type_name(ar2.p);
  let ar3: AdvanceResult = expect(fr.p, lex.TokenKind.LBrace);
  let mut q: Parser = ar3.p;
  let mut methods: Vec[ast.FuncDecl] = Vec();
  while !q.has_err && !kind_is(peek_kind(q), lex.TokenKind.RBrace) && !kind_is(peek_kind(q), lex.TokenKind.Eof) {
    let r: ParseFnResult = parse_fn_decl(q, false);
    q = r.p;
    methods.push(r.f);
  }
  let ar4: AdvanceResult = expect(q, lex.TokenKind.RBrace);
  return ParseImplResult { p: ar4.p, i: ast.ImplDecl { file: p.file, trait_name: tr.ty, for_ty: fr.ty, methods: methods } };
}

fn parse_type_alias_decl(p: Parser, is_pub: bool) -> ParseTypeAliasResult {
  // `type Name = Type;` (semicolon optional)
  let ar0: AdvanceResult = expect(p, lex.TokenKind.KwType);
  let r1: ParseIdentResult = parse_ident(ar0.p);
  let ar2: AdvanceResult = expect(r1.p, lex.TokenKind.Eq);
  let r3: ParseTypeResult = parse_type_name(ar2.p);
  let mut q: Parser = r3.p;
  if kind_is(peek_kind(q), lex.TokenKind.Semicolon) {
    let ar4: AdvanceResult = advance(q);
    q = ar4.p;
  }
  return ParseTypeAliasResult { p: q, t: ast.TypeAliasDecl { file: p.file, is_pub: is_pub, name: r1.name, ty: r3.ty } };
}

fn parse_const_decl(p: Parser, is_pub: bool) -> ParseConstResult {
  // `const Name: Type = Expr;` (semicolon optional)
  let ar0: AdvanceResult = expect(p, lex.TokenKind.KwConst);
  let r1: ParseIdentResult = parse_ident(ar0.p);
  let ar2: AdvanceResult = expect(r1.p, lex.TokenKind.Colon);
  let r3: ParseTypeResult = parse_type_name(ar2.p);
  let ar4: AdvanceResult = expect(r3.p, lex.TokenKind.Eq);
  let r5: ParseExprResult = parse_expr(ar4.p, 0);
  let mut q: Parser = r5.p;
  if kind_is(peek_kind(q), lex.TokenKind.Semicolon) {
    let ar6: AdvanceResult = advance(q);
    q = ar6.p;
  }
  return ParseConstResult { p: q, c: ast.ConstDecl { file: p.file, is_pub: is_pub, name: r1.name, ty: r3.ty, init: r5.id } };
}

fn parse_type_decl(p: Parser, is_pub: bool) -> ParseTypeDeclResult {
  // Either:
  // - type alias: `type Name = TypeName;`
  // - union type decl (tagged union): `type Name = A: TA | B: TB;` (stage1 v0 only labeled form)
  let ar0: AdvanceResult = expect(p, lex.TokenKind.KwType);
  let r1: ParseIdentResult = parse_ident(ar0.p);
  let ar2: AdvanceResult = expect(r1.p, lex.TokenKind.Eq);

  // Disambiguation: union uses labeled arms `Ident :`.
  if kind_is(peek_kind(ar2.p), lex.TokenKind.Ident) && kind_is(peek2_kind(ar2.p), lex.TokenKind.Colon) {
    let mut q: Parser = ar2.p;
    let mut vars: Vec[ast.EnumVariantDecl] = Vec();
    while !q.has_err {
      let rlbl: ParseIdentResult = parse_ident(q);
      let arcol: AdvanceResult = expect(rlbl.p, lex.TokenKind.Colon);
      let rty: ParseTypeResult = parse_type_name(arcol.p);
      vars.push(ast.EnumVariantDecl { name: rlbl.name, fields: vec1_type(rty.ty) });
      q = rty.p;
      if kind_is(peek_kind(q), lex.TokenKind.Pipe) {
        let arbar: AdvanceResult = advance(q);
        q = arbar.p;
        continue;
      }
      break;
    }
    if kind_is(peek_kind(q), lex.TokenKind.Semicolon) {
      let arsemi: AdvanceResult = advance(q);
      q = arsemi.p;
    }
    return ParseTypeDeclResult {
      p: q,
      is_union: true,
      t: ast.TypeAliasDecl { file: "", is_pub: false, name: "", ty: ast.TypeName { parts: Vec(), args: Vec() } },
      e: ast.EnumDecl { file: p.file, is_pub: is_pub, name: r1.name, variants: vars },
    };
  }

  // Alias fallback.
  let r3: ParseTypeResult = parse_type_name(ar2.p);
  let mut q2: Parser = r3.p;
  if kind_is(peek_kind(q2), lex.TokenKind.Semicolon) {
    let ar4: AdvanceResult = advance(q2);
    q2 = ar4.p;
  }
  return ParseTypeDeclResult {
    p: q2,
    is_union: false,
    t: ast.TypeAliasDecl { file: p.file, is_pub: is_pub, name: r1.name, ty: r3.ty },
    e: ast.EnumDecl { file: "", is_pub: false, name: "", variants: Vec() },
  };
}

fn vec1_type(x: ast.TypeName) -> Vec[ast.TypeName] {
  let mut v: Vec[ast.TypeName] = Vec();
  v.push(x);
  return v;
}

fn parse_params(p: Parser) -> ParseParamsResult {
  let mut q: Parser = p;
  let mut params: Vec[ast.Param] = Vec();
  if kind_is(peek_kind(q), lex.TokenKind.RParen) {
    return ParseParamsResult { p: q, params: params };
  }
  while !q.has_err {
    let r1: ParseIdentResult = parse_ident(q);
    let ar2: AdvanceResult = expect(r1.p, lex.TokenKind.Colon);
    let r3: ParseTypeResult = parse_type_name(ar2.p);
    params.push(ast.Param { name: r1.name, ty: r3.ty });
    q = r3.p;
    if kind_is(peek_kind(q), lex.TokenKind.Comma) {
      let ar4: AdvanceResult = advance(q);
      q = ar4.p;
      if kind_is(peek_kind(q), lex.TokenKind.RParen) {
        break;
      }
      continue;
    }
    break;
  }
  return ParseParamsResult { p: q, params: params };
}

		fn parse_program(p: Parser) -> ParseProgramResult {
		  let mut q: Parser = p;
		  let mut imports: Vec[ast.ImportDecl] = Vec();
		  let mut types: Vec[ast.TypeAliasDecl] = Vec();
		  let mut consts: Vec[ast.ConstDecl] = Vec();
		  let mut structs: Vec[ast.StructDecl] = Vec();
		  let mut enums: Vec[ast.EnumDecl] = Vec();
		  let mut traits: Vec[ast.TraitDecl] = Vec();
		  let mut impls: Vec[ast.ImplDecl] = Vec();
		  let mut funcs: Vec[ast.FuncDecl] = Vec();
	  while !q.has_err && !kind_is(peek_kind(q), lex.TokenKind.Eof) {
	    if kind_is(peek_kind(q), lex.TokenKind.KwImport) {
	      let r: ParseImportResult = parse_import_decl(q);
	      q = r.p;
	      imports.push(r.imp);
	    } else {
	      // optional `pub`
	      let mut is_pub: bool = false;
	      if kind_is(peek_kind(q), lex.TokenKind.KwPub) {
	        let ar1: AdvanceResult = advance(q);
	        q = ar1.p;
	        is_pub = true;
	      }
	      let k: lex.TokenKind = peek_kind(q);
	      if kind_is(k, lex.TokenKind.KwType) {
	        let r: ParseTypeDeclResult = parse_type_decl(q, is_pub);
	        q = r.p;
	        if r.is_union {
	          enums.push(r.e);
	        } else {
	          types.push(r.t);
	        }
	      } else if kind_is(k, lex.TokenKind.KwConst) {
	        let r: ParseConstResult = parse_const_decl(q, is_pub);
	        q = r.p;
	        consts.push(r.c);
	      } else if kind_is(k, lex.TokenKind.KwStruct) {
	        let r: ParseStructResult = parse_struct_decl(q, is_pub);
	        q = r.p;
	        structs.push(r.s);
		      } else if kind_is(k, lex.TokenKind.KwEnum) {
		        let r: ParseEnumResult = parse_enum_decl(q, is_pub);
		        q = r.p;
		        enums.push(r.e);
		      } else if kind_is(k, lex.TokenKind.KwTrait) {
		        let r: ParseTraitResult = parse_trait_decl(q, is_pub);
		        q = r.p;
		        traits.push(r.t);
		      } else if kind_is(k, lex.TokenKind.KwImpl) {
		        let r: ParseImplResult = parse_impl_decl(q);
		        q = r.p;
		        impls.push(r.i);
		      } else {
		        let r: ParseFnResult = parse_fn_decl(q, is_pub);
		        q = r.p;
		        funcs.push(r.f);
		      }
		    }
		  }
		  return ParseProgramResult { p: q, prog: ast.Program { imports: imports, types: types, consts: consts, structs: structs, enums: enums, traits: traits, impls: impls, funcs: funcs, exprs: q.exprs } };
		}

	pub fn parse_text_with_path(path: String, text: String) -> ParseResult {
	  let lr: lex.LexResult = lex.lex_text(text);
	  if !lex_err_none(lr.err) {
	    return ParseResult { prog: ast.Program { imports: Vec(), types: Vec(), consts: Vec(), structs: Vec(), enums: Vec(), traits: Vec(), impls: Vec(), funcs: Vec(), exprs: ast.expr_pool() }, err: ParseError.Lex(lr.err) };
	  }
	  let p: Parser = Parser { file: path, text: text, line_starts: build_line_starts(text), toks: lr.tokens, pos: 0, has_err: false, err: ParseError.None, exprs: ast.expr_pool() };
	  let r: ParseProgramResult = parse_program(p);
	  return ParseResult { prog: r.prog, err: r.p.err };
	}

	pub fn parse_text(text: String) -> ParseResult {
	  return parse_text_with_path("src/main.vox", text);
	}
