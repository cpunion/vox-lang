import "ast" as ast
import "lex" as lex

pub enum ParseError {
  None,
  Lex(lex.LexError),
  UnexpectedToken(lex.TokenKind, lex.TokenKind, i32), // expected, got, byte offset
}

pub fn parse_error_to_string(e: ParseError) -> String {
  return match e {
    ParseError.None => "none",
    ParseError.Lex(le) => "lex error: ".concat(lex.lex_error_to_string(le)),
    ParseError.UnexpectedToken(exp, got, at) =>
      "unexpected token at ".concat(at.to_string())
        .concat(": expected ").concat(lex.token_kind_name(exp))
        .concat(", got ").concat(lex.token_kind_name(got)),
  };
}

struct LineCol { line: i32, col: i32 }

fn pos_to_line_col(text: String, at0: i32) -> LineCol {
  let mut at: i32 = at0;
  if at < 0 { at = 0; }
  if at > text.len() { at = text.len(); }
  let mut line: i32 = 1;
  let mut col: i32 = 1;
  let mut i: i32 = 0;
  while i < at {
    if text.byte_at(i) == 10 { // '\n'
      line = line + 1;
      col = 1;
    } else {
      col = col + 1;
    }
    i = i + 1;
  }
  return LineCol { line: line, col: col };
}

pub fn parse_error_to_string_with_source(file: String, text: String, e: ParseError) -> String {
  return match e {
    ParseError.None => file.concat(":1:1: parse error: none"),
    ParseError.UnexpectedToken(exp, got, at) => format_unexpected_token(file, text, exp, got, at),
    ParseError.Lex(le) => format_lex_error(file, text, le),
  };
}

fn format_unexpected_token(file: String, text: String, exp: lex.TokenKind, got: lex.TokenKind, at: i32) -> String {
  let lc: LineCol = pos_to_line_col(text, at);
  return file.concat(":").concat(lc.line.to_string()).concat(":").concat(lc.col.to_string())
    .concat(": parse error: unexpected token: expected ").concat(lex.token_kind_name(exp))
    .concat(", got ").concat(lex.token_kind_name(got));
}

fn format_lex_error(file: String, text: String, le: lex.LexError) -> String {
  return match le {
    lex.LexError.None => file.concat(":1:1: lex error: none"),
    lex.LexError.UnexpectedChar(at) => format_lex_unexpected_char(file, text, at),
    lex.LexError.UnterminatedString(at) => format_lex_unterminated_string(file, text, at),
  };
}

fn format_lex_unexpected_char(file: String, text: String, at: i32) -> String {
  let lc: LineCol = pos_to_line_col(text, at);
  return file.concat(":").concat(lc.line.to_string()).concat(":").concat(lc.col.to_string())
    .concat(": lex error: unexpected char");
}

fn format_lex_unterminated_string(file: String, text: String, at: i32) -> String {
  let lc: LineCol = pos_to_line_col(text, at);
  return file.concat(":").concat(lc.line.to_string()).concat(":").concat(lc.col.to_string())
    .concat(": lex error: unterminated string");
}

pub struct ParseResult {
  pub prog: ast.Program,
  pub err: ParseError,
}

struct Parser {
  file: String,
  text: String,
  toks: Vec[lex.Token],
  pos: i32,
  has_err: bool,
  err: ParseError,
  exprs: ast.ExprPool,
}

struct AdvanceResult { p: Parser, tok: lex.Token }
struct ParseIdentResult { p: Parser, name: String }
struct ParseTypeResult { p: Parser, ty: ast.TypeName }
	struct ParseExprResult { p: Parser, id: i32 }
	struct ParseStmtResult { p: Parser, st: ast.Stmt }
	struct ParseBlockResult { p: Parser, b: ast.Block }
	struct ParseFnResult { p: Parser, f: ast.FuncDecl }
	struct ParseStructResult { p: Parser, s: ast.StructDecl }
	struct ParseEnumResult { p: Parser, e: ast.EnumDecl }
	struct ParseProgramResult { p: Parser, prog: ast.Program }
	struct ParseImportResult { p: Parser, imp: ast.ImportDecl }
	struct ParseStringResult { p: Parser, s: String }
struct ParseImportNameResult { p: Parser, nm: ast.ImportName }
struct ParseParamsResult { p: Parser, params: Vec[ast.Param] }
struct ParseFieldResult { p: Parser, f: ast.FieldDecl }
struct ParseVariantResult { p: Parser, v: ast.EnumVariantDecl }
struct ParsePatResult { p: Parser, pat: ast.Pat }
struct ParseArmResult { p: Parser, arm: ast.MatchArm }
struct ParseTypeParamsResult { p: Parser, tps: Vec[String] }
struct ParseBracedExprResult { p: Parser, id: i32 }

fn dummy_token() -> lex.Token {
  return lex.Token { kind: lex.TokenKind.Eof, start: 0, end: 0 };
}

fn lex_err_none(e: lex.LexError) -> bool {
  return match e {
    lex.LexError.None => true,
    _ => false,
  };
}

fn peek(p: Parser) -> lex.Token {
  let toks: Vec[lex.Token] = p.toks;
  if p.pos < toks.len() { return toks.get(p.pos); }
  return dummy_token();
}

fn peek_kind(p: Parser) -> lex.TokenKind {
  return peek(p).kind;
}

	fn peek2_kind(p: Parser) -> lex.TokenKind {
	  let toks: Vec[lex.Token] = p.toks;
	  let i: i32 = p.pos + 1;
	  if i < toks.len() { return toks.get(i).kind; }
	  return lex.TokenKind.Eof;
	}

fn peek3_kind(p: Parser) -> lex.TokenKind {
  let toks: Vec[lex.Token] = p.toks;
  let i: i32 = p.pos + 2;
  if i < toks.len() { return toks.get(i).kind; }
  return lex.TokenKind.Eof;
}

fn peek4_kind(p: Parser) -> lex.TokenKind {
  let toks: Vec[lex.Token] = p.toks;
  let i: i32 = p.pos + 3;
  if i < toks.len() { return toks.get(i).kind; }
  return lex.TokenKind.Eof;
}

fn kind_is(k: lex.TokenKind, want: lex.TokenKind) -> bool {
  return lex.token_kind_eq(k, want);
}

fn advance(p: Parser) -> AdvanceResult {
  let tok: lex.Token = peek(p);
  let mut q: Parser = p;
  let toks: Vec[lex.Token] = q.toks;
  if q.pos < toks.len() { q.pos = q.pos + 1; }
  return AdvanceResult { p: q, tok: tok };
}

fn expect(p: Parser, want: lex.TokenKind) -> AdvanceResult {
  if p.has_err {
    return AdvanceResult { p: p, tok: dummy_token() };
  }
  let got: lex.TokenKind = peek_kind(p);
  if kind_is(got, want) {
    return advance(p);
  }
  let mut q: Parser = p;
  let at: i32 = peek(p).start;
  q.has_err = true;
  q.err = ParseError.UnexpectedToken(want, got, at);
  return AdvanceResult { p: q, tok: dummy_token() };
}

fn lexeme(p: Parser, t: lex.Token) -> String {
  let text: String = p.text;
  return text.slice(t.start, t.end);
}

fn parse_ident(p: Parser) -> ParseIdentResult {
  let ar: AdvanceResult = expect(p, lex.TokenKind.Ident);
  let name: String = lexeme(ar.p, ar.tok);
  return ParseIdentResult { p: ar.p, name: name };
}

fn parse_type_name(p: Parser) -> ParseTypeResult {
  // Unit type: `()`
  if kind_is(peek_kind(p), lex.TokenKind.LParen) && kind_is(peek2_kind(p), lex.TokenKind.RParen) {
    let ar1: AdvanceResult = advance(p);
    let ar2: AdvanceResult = expect(ar1.p, lex.TokenKind.RParen);
    let mut parts: Vec[String] = Vec();
    parts.push("()");
    return ParseTypeResult { p: ar2.p, ty: ast.TypeName { parts: parts, args: Vec() } };
  }

  let r0: ParseIdentResult = parse_ident(p);
  let mut q: Parser = r0.p;
  let mut parts: Vec[String] = Vec();
  parts.push(r0.name);
  while kind_is(peek_kind(q), lex.TokenKind.Dot) && !q.has_err {
    let ar1: AdvanceResult = advance(q);
    let r2: ParseIdentResult = parse_ident(ar1.p);
    q = r2.p;
    parts.push(r2.name);
  }

  let mut args: Vec[ast.TypeName] = Vec();
  if kind_is(peek_kind(q), lex.TokenKind.LBracket) {
    let ar3: AdvanceResult = advance(q);
    q = ar3.p;
    if !kind_is(peek_kind(q), lex.TokenKind.RBracket) {
      while !q.has_err {
        let tr: ParseTypeResult = parse_type_name(q);
        q = tr.p;
        args.push(tr.ty);
        if kind_is(peek_kind(q), lex.TokenKind.Comma) {
          let ar4: AdvanceResult = advance(q);
          q = ar4.p;
          if kind_is(peek_kind(q), lex.TokenKind.RBracket) {
            break;
          }
          continue;
        }
        break;
      }
    }
    let ar5: AdvanceResult = expect(q, lex.TokenKind.RBracket);
    q = ar5.p;
  }
  return ParseTypeResult { p: q, ty: ast.TypeName { parts: parts, args: args } };
}

fn add_expr(p: Parser, node: ast.ExprNode) -> ParseExprResult {
  let r: ast.AddExprResult = ast.expr_pool_add(p.exprs, node);
  let mut q: Parser = p;
  q.exprs = r.pool;
  return ParseExprResult { p: q, id: r.id };
}

fn parse_string_inner(p: Parser) -> ParseStringResult {
  let ar: AdvanceResult = expect(p, lex.TokenKind.Str);
  let mut s: String = lexeme(ar.p, ar.tok); // includes quotes
  let n: i32 = s.len();
  if n >= 2 {
    s = s.slice(1, n - 1);
  }
  // Unescape common sequences in string literals.
  // Supported: \\ \" \n \r \t
  let mut out: String = "";
  let mut i: i32 = 0;
  while i < s.len() {
    let b: i32 = s.byte_at(i);
    if b == 92 { // '\\'
      if (i + 1) < s.len() {
        let nb: i32 = s.byte_at(i + 1);
        if nb == 110 { out = out.concat("\n"); i = i + 2; continue; } // n
        if nb == 114 { out = out.concat("\r"); i = i + 2; continue; } // r
        if nb == 116 { out = out.concat("\t"); i = i + 2; continue; } // t
        if nb == 34 { out = out.concat("\""); i = i + 2; continue; }  // "
        if nb == 92 { out = out.concat("\\"); i = i + 2; continue; }  // \
        // Unknown escape: drop '\' and keep next char as-is.
        out = out.concat(s.slice(i + 1, i + 2));
        i = i + 2;
        continue;
      }
      // trailing '\' -> keep it
      out = out.concat("\\");
      i = i + 1;
      continue;
    }
    out = out.concat(s.slice(i, i + 1));
    i = i + 1;
  }
  s = out;
  return ParseStringResult { p: ar.p, s: s };
}

fn parse_import_name(p: Parser) -> ParseImportNameResult {
  let r0: ParseIdentResult = parse_ident(p);
  let mut q: Parser = r0.p;
  let mut alias: String = "";
  if kind_is(peek_kind(q), lex.TokenKind.KwAs) {
    let ar1: AdvanceResult = advance(q);
    let r2: ParseIdentResult = parse_ident(ar1.p);
    q = r2.p;
    alias = r2.name;
  }
  return ParseImportNameResult { p: q, nm: ast.ImportName { name: r0.name, alias: alias } };
}

fn parse_import_decl(p: Parser) -> ParseImportResult {
  let ar1: AdvanceResult = expect(p, lex.TokenKind.KwImport);

  // Named imports: `import { a, b as c } from "path"`
  if kind_is(peek_kind(ar1.p), lex.TokenKind.LBrace) {
    let ar2: AdvanceResult = advance(ar1.p);
    let mut q: Parser = ar2.p;
    let mut names: Vec[ast.ImportName] = Vec();
    if !kind_is(peek_kind(q), lex.TokenKind.RBrace) {
      while !q.has_err {
        let nr: ParseImportNameResult = parse_import_name(q);
        q = nr.p;
        names.push(nr.nm);
        if kind_is(peek_kind(q), lex.TokenKind.Comma) {
          let ar3: AdvanceResult = advance(q);
          q = ar3.p;
          if kind_is(peek_kind(q), lex.TokenKind.RBrace) {
            break;
          }
          continue;
        }
        break;
      }
    }
    let ar4: AdvanceResult = expect(q, lex.TokenKind.RBrace);
    let ar5: AdvanceResult = expect(ar4.p, lex.TokenKind.KwFrom);
    let r6: ParseStringResult = parse_string_inner(ar5.p);
    return ParseImportResult { p: r6.p, imp: ast.ImportDecl { file: p.file, path: r6.s, alias: "", names: names } };
  }

  // Module import: `import "path" as alias`
  let r2: ParseStringResult = parse_string_inner(ar1.p);
  let mut q: Parser = r2.p;
  let path: String = r2.s;
  let mut alias: String = "";
  if kind_is(peek_kind(q), lex.TokenKind.KwAs) {
    let ar3: AdvanceResult = advance(q);
    let r4: ParseIdentResult = parse_ident(ar3.p);
    q = r4.p;
    alias = r4.name;
  }
  return ParseImportResult { p: q, imp: ast.ImportDecl { file: p.file, path: path, alias: alias, names: Vec() } };
}

fn parse_braced_expr(p: Parser) -> ParseBracedExprResult {
  // Back-compat helper used by if-expr parsing; now parses a full block expression.
  let r: ParseExprResult = parse_expr_block(p);
  return ParseBracedExprResult { p: r.p, id: r.id };
}

fn parse_expr_block(p: Parser) -> ParseExprResult {
  // `{ stmt*; tailExpr }` where tailExpr is optional (missing => unit).
  let ar1: AdvanceResult = expect(p, lex.TokenKind.LBrace);
  let mut q: Parser = ar1.p;
  let mut stmts: Vec[ast.Stmt] = Vec();
  let mut has_tail: bool = false;
  let mut tail: i32 = -1;

  while !q.has_err && !kind_is(peek_kind(q), lex.TokenKind.RBrace) && !kind_is(peek_kind(q), lex.TokenKind.Eof) {
    let k: lex.TokenKind = peek_kind(q);

    let is_stmt: bool =
      kind_is(k, lex.TokenKind.KwLet) ||
      kind_is(k, lex.TokenKind.KwIf) ||
      kind_is(k, lex.TokenKind.KwWhile) ||
      kind_is(k, lex.TokenKind.KwBreak) ||
      kind_is(k, lex.TokenKind.KwContinue) ||
      kind_is(k, lex.TokenKind.KwReturn) ||
      // assignment: ident = ...
      (kind_is(k, lex.TokenKind.Ident) && kind_is(peek2_kind(q), lex.TokenKind.Eq)) ||
      // field assignment: ident . ident = ...
      (kind_is(k, lex.TokenKind.Ident) && kind_is(peek2_kind(q), lex.TokenKind.Dot) && kind_is(peek3_kind(q), lex.TokenKind.Ident) && kind_is(peek4_kind(q), lex.TokenKind.Eq));

    if is_stmt {
      let sr: ParseStmtResult = parse_stmt(q);
      q = sr.p;
      stmts.push(sr.st);
      continue;
    }

    let er: ParseExprResult = parse_expr(q, 0);
    q = er.p;
    if kind_is(peek_kind(q), lex.TokenKind.Semicolon) {
      let ar2: AdvanceResult = advance(q);
      q = ar2.p;
      stmts.push(ast.Stmt.Expr(er.id));
      continue;
    }
    has_tail = true;
    tail = er.id;
    break;
  }

  let ar3: AdvanceResult = expect(q, lex.TokenKind.RBrace);
  let b: ast.ExprBlock = ast.ExprBlock { stmts: stmts, has_tail: has_tail, tail: tail };
  return add_expr(ar3.p, ast.ExprNode.Block(b));
}

fn parse_if_expr(p: Parser) -> ParseExprResult {
  // if <cond> { <expr> } else { <expr> }
  let ar1: AdvanceResult = expect(p, lex.TokenKind.KwIf);
  let r2: ParseExprResult = parse_expr(ar1.p, 0);
  let br1: ParseBracedExprResult = parse_braced_expr(r2.p);
  let ar3: AdvanceResult = expect(br1.p, lex.TokenKind.KwElse);

  // else if ...  ==> else { if ... } (AST nests If)
  if kind_is(peek_kind(ar3.p), lex.TokenKind.KwIf) {
    let r4: ParseExprResult = parse_if_expr(ar3.p);
    return add_expr(r4.p, ast.ExprNode.If(r2.id, br1.id, r4.id));
  }
  let br2: ParseBracedExprResult = parse_braced_expr(ar3.p);
  return add_expr(br2.p, ast.ExprNode.If(r2.id, br1.id, br2.id));
}

	fn parse_primary(p: Parser) -> ParseExprResult {
  if p.has_err {
    return ParseExprResult { p: p, id: -1 };
  }
  let k: lex.TokenKind = peek_kind(p);

  if kind_is(k, lex.TokenKind.Int) {
    let ar: AdvanceResult = advance(p);
    let tok: lex.Token = ar.tok;
    let mut n: i32 = 0;
    let mut i: i32 = tok.start;
    let text: String = p.text;
    while i < tok.end {
      let d: i32 = text.byte_at(i) - 48;
      n = n * 10 + d;
      i = i + 1;
    }
    return add_expr(ar.p, ast.ExprNode.Int(n));
  }

  if kind_is(k, lex.TokenKind.KwTrue) {
    let ar: AdvanceResult = advance(p);
    return add_expr(ar.p, ast.ExprNode.Bool(true));
  }
  if kind_is(k, lex.TokenKind.KwFalse) {
    let ar: AdvanceResult = advance(p);
    return add_expr(ar.p, ast.ExprNode.Bool(false));
  }

  if kind_is(k, lex.TokenKind.Ident) {
    let r: ParseIdentResult = parse_ident(p);
    return add_expr(r.p, ast.ExprNode.Ident(r.name));
  }

  // Enum variant shorthand: `.Variant`
  if kind_is(k, lex.TokenKind.Dot) {
    let ar: AdvanceResult = advance(p);
    let r: ParseIdentResult = parse_ident(ar.p);
    return add_expr(r.p, ast.ExprNode.DotIdent(r.name));
  }

		  if kind_is(k, lex.TokenKind.Str) {
		    let r: ParseStringResult = parse_string_inner(p);
		    return add_expr(r.p, ast.ExprNode.Str(r.s));
		  }

	if kind_is(k, lex.TokenKind.KwMatch) {
    let ar1: AdvanceResult = advance(p);
    let r2: ParseExprResult = parse_expr(ar1.p, 0);
    let ar3: AdvanceResult = expect(r2.p, lex.TokenKind.LBrace);
    let mut q: Parser = ar3.p;
    let mut arms: Vec[ast.MatchArm] = Vec();
    while !q.has_err && !kind_is(peek_kind(q), lex.TokenKind.RBrace) && !kind_is(peek_kind(q), lex.TokenKind.Eof) {
      let pr: ParsePatResult = parse_pat(q);
      let ar4: AdvanceResult = expect(pr.p, lex.TokenKind.FatArrow);
      let er: ParseExprResult = parse_expr(ar4.p, 0);
      q = er.p;
      arms.push(ast.MatchArm { pat: pr.pat, expr: er.id });
      if kind_is(peek_kind(q), lex.TokenKind.Comma) {
        let ar5: AdvanceResult = advance(q);
        q = ar5.p;
        continue;
      }
      break;
    }
    let ar6: AdvanceResult = expect(q, lex.TokenKind.RBrace);
    return add_expr(ar6.p, ast.ExprNode.Match(r2.id, arms));
  }

  if kind_is(k, lex.TokenKind.KwIf) {
    return parse_if_expr(p);
  }

  if kind_is(k, lex.TokenKind.LBrace) {
    return parse_expr_block(p);
  }

  let mut q: Parser = p;
  let at: i32 = peek(p).start;
  q.has_err = true;
  q.err = ParseError.UnexpectedToken(lex.TokenKind.Ident, k, at);
  return ParseExprResult { p: q, id: -1 };
}

		fn parse_postfix(p: Parser, base: i32) -> ParseExprResult {
		  let mut q: Parser = p;
		  let mut cur: i32 = base;
		  let mut pending_targs: Vec[ast.TypeName] = Vec();
		  while !q.has_err {
	    // Struct literal: `TypePath { field: expr, ... }`
	    //
	    // Ambiguity note: blocks also start with `{`. We only parse a struct literal
	    // when the first field looks like `ident :` (i.e. `{ Ident Colon ... }`).
	    if kind_is(peek_kind(q), lex.TokenKind.LBrace) &&
	      kind_is(peek2_kind(q), lex.TokenKind.Ident) &&
	      kind_is(peek3_kind(q), lex.TokenKind.Colon) {
	      let ar1: AdvanceResult = advance(q);
	      let mut r: Parser = ar1.p;
	      let mut fields: Vec[ast.StructLitField] = Vec();
	      while !r.has_err && !kind_is(peek_kind(r), lex.TokenKind.RBrace) && !kind_is(peek_kind(r), lex.TokenKind.Eof) {
	        let fr: ParseIdentResult = parse_ident(r);
	        let ar2: AdvanceResult = expect(fr.p, lex.TokenKind.Colon);
	        let er: ParseExprResult = parse_expr(ar2.p, 0);
	        r = er.p;
	        fields.push(ast.StructLitField { name: fr.name, expr: er.id });
	        if kind_is(peek_kind(r), lex.TokenKind.Comma) {
	          let ar3: AdvanceResult = advance(r);
	          r = ar3.p;
	          continue;
	        }
	        break;
	      }
	      let ar4: AdvanceResult = expect(r, lex.TokenKind.RBrace);
	      let r5: ParseExprResult = add_expr(ar4.p, ast.ExprNode.StructLit(cur, fields));
	      q = r5.p;
	      cur = r5.id;
	      continue;
	    }
		    if kind_is(peek_kind(q), lex.TokenKind.Dot) {
		      if pending_targs.len() != 0 {
		        let mut qq: Parser = q;
		        let at: i32 = peek(q).start;
		        qq.has_err = true;
		        qq.err = ParseError.UnexpectedToken(lex.TokenKind.LParen, lex.TokenKind.Dot, at);
		        return ParseExprResult { p: qq, id: cur };
		      }
		      let ar1: AdvanceResult = advance(q);
		      let r2: ParseIdentResult = parse_ident(ar1.p);
		      let r3: ParseExprResult = add_expr(r2.p, ast.ExprNode.Member(cur, r2.name));
	      q = r3.p;
	      cur = r3.id;
	      continue;
	    }
	    if kind_is(peek_kind(q), lex.TokenKind.LBracket) {
	      if pending_targs.len() != 0 {
	        let mut qq: Parser = q;
	        let at: i32 = peek(q).start;
	        qq.has_err = true;
	        qq.err = ParseError.UnexpectedToken(lex.TokenKind.LBracket, lex.TokenKind.LBracket, at);
	        return ParseExprResult { p: qq, id: cur };
	      }
	      let ar0: AdvanceResult = advance(q);
	      let mut r: Parser = ar0.p;
	      if !kind_is(peek_kind(r), lex.TokenKind.RBracket) {
	        while !r.has_err {
	          let tr: ParseTypeResult = parse_type_name(r);
	          r = tr.p;
	          pending_targs.push(tr.ty);
	          if kind_is(peek_kind(r), lex.TokenKind.Comma) {
	            let arx: AdvanceResult = advance(r);
	            r = arx.p;
	            continue;
	          }
	          break;
	        }
	      }
	      let ar1: AdvanceResult = expect(r, lex.TokenKind.RBracket);
	      q = ar1.p;
	      continue;
	    }
	    if kind_is(peek_kind(q), lex.TokenKind.LParen) {
	      let ar1: AdvanceResult = advance(q);
	      let mut r: Parser = ar1.p;
	      let mut args: Vec[i32] = Vec();
      if !kind_is(peek_kind(r), lex.TokenKind.RParen) {
        while !r.has_err {
          let er: ParseExprResult = parse_expr(r, 0);
          r = er.p;
          args.push(er.id);
          if kind_is(peek_kind(r), lex.TokenKind.Comma) {
            let ar2: AdvanceResult = advance(r);
            r = ar2.p;
            if kind_is(peek_kind(r), lex.TokenKind.RParen) {
              break;
            }
            continue;
          }
          break;
        }
	      }
	      let ar3: AdvanceResult = expect(r, lex.TokenKind.RParen);
	      let r4: ParseExprResult = add_expr(ar3.p, ast.ExprNode.Call(cur, pending_targs, args));
	      q = r4.p;
	      cur = r4.id;
	      pending_targs = Vec();
	      continue;
	    }
	    break;
	  }
	  if pending_targs.len() != 0 {
	    let mut qq: Parser = q;
	    let at: i32 = peek(q).start;
	    qq.has_err = true;
	    qq.err = ParseError.UnexpectedToken(lex.TokenKind.LParen, peek_kind(q), at);
	    return ParseExprResult { p: qq, id: cur };
	  }
		  return ParseExprResult { p: q, id: cur };
		}

fn parse_pat(p: Parser) -> ParsePatResult {
  let k: lex.TokenKind = peek_kind(p);
  if kind_is(k, lex.TokenKind.Int) {
    let ar1: AdvanceResult = advance(p);
    let tok: lex.Token = ar1.tok;
    let mut n: i32 = 0;
    let mut i: i32 = tok.start;
    let text: String = p.text;
    while i < tok.end {
      let d: i32 = text.byte_at(i) - 48;
      n = n * 10 + d;
      i = i + 1;
    }
    return ParsePatResult { p: ar1.p, pat: ast.Pat.Int(n) };
  }
  if kind_is(k, lex.TokenKind.Str) {
    let r: ParseStringResult = parse_string_inner(p);
    return ParsePatResult { p: r.p, pat: ast.Pat.Str(r.s) };
  }

  // Enum variant shorthand pattern: `.Variant(x, y, ...)`
  if kind_is(k, lex.TokenKind.Dot) {
    let ar0: AdvanceResult = advance(p);
    let r0: ParseIdentResult = parse_ident(ar0.p);
    let mut q: Parser = r0.p;
    let mut binders: Vec[String] = Vec();
    if kind_is(peek_kind(q), lex.TokenKind.LParen) {
      let ar3: AdvanceResult = advance(q);
      q = ar3.p;
      if !kind_is(peek_kind(q), lex.TokenKind.RParen) {
        while !q.has_err {
          let br: ParseIdentResult = parse_ident(q);
          q = br.p;
          binders.push(br.name);
          if kind_is(peek_kind(q), lex.TokenKind.Comma) {
            let ar4: AdvanceResult = advance(q);
            q = ar4.p;
            if kind_is(peek_kind(q), lex.TokenKind.RParen) { break; }
            continue;
          }
          break;
        }
      }
      let ar5: AdvanceResult = expect(q, lex.TokenKind.RParen);
      q = ar5.p;
    }
    return ParsePatResult { p: q, pat: ast.Pat.EnumVariant(Vec(), r0.name, binders) };
  }

  // Wildcard: `_`
  if kind_is(k, lex.TokenKind.Ident) {
    let r0: ParseIdentResult = parse_ident(p);
    if r0.name == "_" {
      return ParsePatResult { p: r0.p, pat: ast.Pat.Wild };
    }

    // path: a.b.c
    let mut q: Parser = r0.p;
    let mut parts: Vec[String] = Vec();
    parts.push(r0.name);
    while kind_is(peek_kind(q), lex.TokenKind.Dot) && !q.has_err {
      let ar1: AdvanceResult = advance(q);
      let r2: ParseIdentResult = parse_ident(ar1.p);
      q = r2.p;
      parts.push(r2.name);
    }

    // optional binders: (x, y, ...)
    let mut binders: Vec[String] = Vec();
    if kind_is(peek_kind(q), lex.TokenKind.LParen) {
      let ar3: AdvanceResult = advance(q);
      q = ar3.p;
      if !kind_is(peek_kind(q), lex.TokenKind.RParen) {
        while !q.has_err {
          let br: ParseIdentResult = parse_ident(q);
          q = br.p;
          binders.push(br.name);
          if kind_is(peek_kind(q), lex.TokenKind.Comma) {
            let ar4: AdvanceResult = advance(q);
            q = ar4.p;
            if kind_is(peek_kind(q), lex.TokenKind.RParen) {
              break;
            }
            continue;
          }
          break;
        }
      }
      let ar5: AdvanceResult = expect(q, lex.TokenKind.RParen);
      q = ar5.p;
    }

    if parts.len() >= 2 {
      let n: i32 = parts.len();
      let variant: String = parts.get(n - 1);
      let mut enum_parts: Vec[String] = Vec();
      let mut i: i32 = 0;
      while i < n - 1 {
        enum_parts.push(parts.get(i));
        i = i + 1;
      }
      return ParsePatResult { p: q, pat: ast.Pat.EnumVariant(enum_parts, variant, binders) };
    }

    if binders.len() != 0 {
      // `x(...)` with no path doesn't exist in this subset.
      let mut qq: Parser = q;
      let at: i32 = peek(p).start;
      qq.has_err = true;
      qq.err = ParseError.UnexpectedToken(lex.TokenKind.FatArrow, lex.TokenKind.LParen, at);
      return ParsePatResult { p: qq, pat: ast.Pat.Wild };
    }
    return ParsePatResult { p: q, pat: ast.Pat.Bind(parts.get(0)) };
  }

  let mut q: Parser = p;
  let at: i32 = peek(p).start;
  q.has_err = true;
  q.err = ParseError.UnexpectedToken(lex.TokenKind.Ident, k, at);
  return ParsePatResult { p: q, pat: ast.Pat.Wild };
}

fn parse_prefix(p: Parser) -> ParseExprResult {
  let k: lex.TokenKind = peek_kind(p);
  if kind_is(k, lex.TokenKind.Minus) {
    let ar: AdvanceResult = advance(p);
    let r: ParseExprResult = parse_expr(ar.p, 7);
    if r.p.has_err { return r; }
    return add_expr(r.p, ast.ExprNode.Unary(ast.UnaryOp.Neg, r.id));
  }
  if kind_is(k, lex.TokenKind.Not) {
    let ar: AdvanceResult = advance(p);
    let r: ParseExprResult = parse_expr(ar.p, 7);
    if r.p.has_err { return r; }
    return add_expr(r.p, ast.ExprNode.Unary(ast.UnaryOp.Not, r.id));
  }
  if kind_is(k, lex.TokenKind.LParen) {
    let ar1: AdvanceResult = advance(p);
    let r2: ParseExprResult = parse_expr(ar1.p, 0);
    let ar3: AdvanceResult = expect(r2.p, lex.TokenKind.RParen);
    // Allow postfix ops on parenthesized expressions: `(expr).method(...)`.
    return parse_postfix(ar3.p, r2.id);
  }
  let r0: ParseExprResult = parse_primary(p);
  return parse_postfix(r0.p, r0.id);
}

fn infix_prec(k: lex.TokenKind) -> i32 {
  return match k {
    lex.TokenKind.OrOr => 1,
    lex.TokenKind.AndAnd => 2,
    lex.TokenKind.EqEq => 3,
    lex.TokenKind.Ne => 3,
    lex.TokenKind.Lt => 4,
    lex.TokenKind.Le => 4,
    lex.TokenKind.Gt => 4,
    lex.TokenKind.Ge => 4,
    lex.TokenKind.Plus => 5,
    lex.TokenKind.Minus => 5,
    lex.TokenKind.Star => 6,
    lex.TokenKind.Slash => 6,
    lex.TokenKind.Percent => 6,
    _ => 0,
  };
}

fn infix_op(k: lex.TokenKind) -> ast.BinaryOp {
  return match k {
    lex.TokenKind.Plus => ast.BinaryOp.Add,
    lex.TokenKind.Minus => ast.BinaryOp.Sub,
    lex.TokenKind.Star => ast.BinaryOp.Mul,
    lex.TokenKind.Slash => ast.BinaryOp.Div,
    lex.TokenKind.Percent => ast.BinaryOp.Mod,
    lex.TokenKind.EqEq => ast.BinaryOp.Eq,
    lex.TokenKind.Ne => ast.BinaryOp.Ne,
    lex.TokenKind.Lt => ast.BinaryOp.Lt,
    lex.TokenKind.Le => ast.BinaryOp.Le,
    lex.TokenKind.Gt => ast.BinaryOp.Gt,
    lex.TokenKind.Ge => ast.BinaryOp.Ge,
    lex.TokenKind.AndAnd => ast.BinaryOp.AndAnd,
    lex.TokenKind.OrOr => ast.BinaryOp.OrOr,
    _ => ast.BinaryOp.Add,
  };
}

fn parse_expr(p: Parser, min_prec: i32) -> ParseExprResult {
  let r0: ParseExprResult = parse_prefix(p);
  let mut q: Parser = r0.p;
  let mut left: i32 = r0.id;
  while !q.has_err {
    let k: lex.TokenKind = peek_kind(q);
    let prec: i32 = infix_prec(k);
    if prec < min_prec || prec == 0 {
      break;
    }
    let ar1: AdvanceResult = advance(q);
    let op: ast.BinaryOp = infix_op(k);
    let r2: ParseExprResult = parse_expr(ar1.p, prec + 1);
    let r3: ParseExprResult = add_expr(r2.p, ast.ExprNode.Binary(op, left, r2.id));
    q = r3.p;
    left = r3.id;
  }
  return ParseExprResult { p: q, id: left };
}

fn parse_stmt(p: Parser) -> ParseStmtResult {
  let k: lex.TokenKind = peek_kind(p);
  if kind_is(k, lex.TokenKind.KwLet) {
    let ar1: AdvanceResult = advance(p);
    let mut q: Parser = ar1.p;

    // optional `mut`
    let mut is_mut: bool = false;
    if kind_is(peek_kind(q), lex.TokenKind.KwMut) {
      let ar2: AdvanceResult = advance(q);
      q = ar2.p;
      is_mut = true;
    }

    let r3: ParseIdentResult = parse_ident(q);
    q = r3.p;
    let name: String = r3.name;

    // optional type annotation: : Type
    let mut has_ann: bool = false;
    let mut ann: ast.TypeName = ast.TypeName { parts: Vec(), args: Vec() };
    if kind_is(peek_kind(q), lex.TokenKind.Colon) {
      let ar4: AdvanceResult = advance(q);
      let r5: ParseTypeResult = parse_type_name(ar4.p);
      q = r5.p;
      has_ann = true;
      ann = r5.ty;
    }

    let ar6: AdvanceResult = expect(q, lex.TokenKind.Eq);
    let r7: ParseExprResult = parse_expr(ar6.p, 0);
    let ar8: AdvanceResult = expect(r7.p, lex.TokenKind.Semicolon);
    return ParseStmtResult { p: ar8.p, st: ast.Stmt.Let(is_mut, name, has_ann, ann, r7.id) };
  }
  if kind_is(k, lex.TokenKind.KwIf) {
    let ar1: AdvanceResult = advance(p);
    let r2: ParseExprResult = parse_expr(ar1.p, 0);
    let r3: ParseBlockResult = parse_block(r2.p);
    let mut q: Parser = r3.p;
    let mut has_else: bool = false;
    let mut else_b: ast.Block = ast.Block { stmts: Vec() };
    if kind_is(peek_kind(q), lex.TokenKind.KwElse) {
      let ar4: AdvanceResult = advance(q);
      has_else = true;
      if kind_is(peek_kind(ar4.p), lex.TokenKind.KwIf) {
        // else if ... ; lower into else { if ... }
        let r5: ParseStmtResult = parse_stmt(ar4.p);
        let mut ss: Vec[ast.Stmt] = Vec();
        ss.push(r5.st);
        q = r5.p;
        else_b = ast.Block { stmts: ss };
      } else {
        let r5: ParseBlockResult = parse_block(ar4.p);
        q = r5.p;
        else_b = r5.b;
      }
    }
    return ParseStmtResult { p: q, st: ast.Stmt.If(r2.id, r3.b, has_else, else_b) };
  }
  if kind_is(k, lex.TokenKind.KwWhile) {
    let ar1: AdvanceResult = advance(p);
    let r2: ParseExprResult = parse_expr(ar1.p, 0);
    let r3: ParseBlockResult = parse_block(r2.p);
    return ParseStmtResult { p: r3.p, st: ast.Stmt.While(r2.id, r3.b) };
  }
  if kind_is(k, lex.TokenKind.KwBreak) {
    let ar1: AdvanceResult = advance(p);
    let ar2: AdvanceResult = expect(ar1.p, lex.TokenKind.Semicolon);
    return ParseStmtResult { p: ar2.p, st: ast.Stmt.Break };
  }
  if kind_is(k, lex.TokenKind.KwContinue) {
    let ar1: AdvanceResult = advance(p);
    let ar2: AdvanceResult = expect(ar1.p, lex.TokenKind.Semicolon);
    return ParseStmtResult { p: ar2.p, st: ast.Stmt.Continue };
  }
  if kind_is(k, lex.TokenKind.KwReturn) {
    let ar1: AdvanceResult = advance(p);
    if kind_is(peek_kind(ar1.p), lex.TokenKind.Semicolon) {
      let ar2: AdvanceResult = expect(ar1.p, lex.TokenKind.Semicolon);
      return ParseStmtResult { p: ar2.p, st: ast.Stmt.Return(false, -1) };
    }
    let r2: ParseExprResult = parse_expr(ar1.p, 0);
    let ar3: AdvanceResult = expect(r2.p, lex.TokenKind.Semicolon);
    return ParseStmtResult { p: ar3.p, st: ast.Stmt.Return(true, r2.id) };
  }

  // field assignment: ident . ident = expr ;
  if kind_is(k, lex.TokenKind.Ident) &&
     kind_is(peek2_kind(p), lex.TokenKind.Dot) &&
     kind_is(peek3_kind(p), lex.TokenKind.Ident) &&
     kind_is(peek4_kind(p), lex.TokenKind.Eq) {
    let r1: ParseIdentResult = parse_ident(p);
    let ar2: AdvanceResult = expect(r1.p, lex.TokenKind.Dot);
    let r3: ParseIdentResult = parse_ident(ar2.p);
    let ar4: AdvanceResult = expect(r3.p, lex.TokenKind.Eq);
    let r5: ParseExprResult = parse_expr(ar4.p, 0);
    let ar6: AdvanceResult = expect(r5.p, lex.TokenKind.Semicolon);
    return ParseStmtResult { p: ar6.p, st: ast.Stmt.AssignField(r1.name, r3.name, r5.id) };
  }

  // assignment: ident = expr ;
  if kind_is(k, lex.TokenKind.Ident) && kind_is(peek2_kind(p), lex.TokenKind.Eq) {
    let r1: ParseIdentResult = parse_ident(p);
    let ar2: AdvanceResult = expect(r1.p, lex.TokenKind.Eq);
    let r3: ParseExprResult = parse_expr(ar2.p, 0);
    let ar4: AdvanceResult = expect(r3.p, lex.TokenKind.Semicolon);
    return ParseStmtResult { p: ar4.p, st: ast.Stmt.Assign(r1.name, r3.id) };
  }

  // expr stmt
  let r1: ParseExprResult = parse_expr(p, 0);
  let ar2: AdvanceResult = expect(r1.p, lex.TokenKind.Semicolon);
  if !ar2.p.has_err {
    return ParseStmtResult { p: ar2.p, st: ast.Stmt.Expr(r1.id) };
  }

  let mut q: Parser = p;
  let at: i32 = peek(p).start;
  q.has_err = true;
  q.err = ParseError.UnexpectedToken(lex.TokenKind.KwReturn, k, at);
  return ParseStmtResult { p: q, st: ast.Stmt.Return(false, -1) };
}

fn parse_block(p: Parser) -> ParseBlockResult {
  let ar1: AdvanceResult = expect(p, lex.TokenKind.LBrace);
  let mut q: Parser = ar1.p;
  let mut stmts: Vec[ast.Stmt] = Vec();
  while !q.has_err && !kind_is(peek_kind(q), lex.TokenKind.RBrace) && !kind_is(peek_kind(q), lex.TokenKind.Eof) {
    let r: ParseStmtResult = parse_stmt(q);
    q = r.p;
    stmts.push(r.st);
  }
  let ar2: AdvanceResult = expect(q, lex.TokenKind.RBrace);
  return ParseBlockResult { p: ar2.p, b: ast.Block { stmts: stmts } };
}

fn parse_fn_decl(p: Parser, is_pub: bool) -> ParseFnResult {
  let ar1: AdvanceResult = expect(p, lex.TokenKind.KwFn);
  let r2: ParseIdentResult = parse_ident(ar1.p);
  let mut q: Parser = r2.p;
  let mut tps: Vec[String] = Vec();
  if kind_is(peek_kind(q), lex.TokenKind.LBracket) {
    let r3: ParseTypeParamsResult = parse_type_params(q);
    q = r3.p;
    tps = r3.tps;
  }
  let _ar4: AdvanceResult = expect(q, lex.TokenKind.LParen);
  let r5: ParseParamsResult = parse_params(_ar4.p);
  let _ar6: AdvanceResult = expect(r5.p, lex.TokenKind.RParen);
  let _ar7: AdvanceResult = expect(_ar6.p, lex.TokenKind.Arrow);
  let r8: ParseTypeResult = parse_type_name(_ar7.p);
  let params: Vec[ast.Param] = r5.params;
  let r9: ParseBlockResult = parse_block(r8.p);
  return ParseFnResult { p: r9.p, f: ast.FuncDecl { file: p.file, is_pub: is_pub, name: r2.name, type_params: tps, params: params, ret: r8.ty, body: r9.b } };
}

fn parse_type_params(p: Parser) -> ParseTypeParamsResult {
  let ar1: AdvanceResult = expect(p, lex.TokenKind.LBracket);
  let mut q: Parser = ar1.p;
  let mut tps: Vec[String] = Vec();
  if kind_is(peek_kind(q), lex.TokenKind.RBracket) {
    let ar2: AdvanceResult = expect(q, lex.TokenKind.RBracket);
    return ParseTypeParamsResult { p: ar2.p, tps: tps };
  }
  while !q.has_err {
    let r1: ParseIdentResult = parse_ident(q);
    q = r1.p;
    tps.push(r1.name);
    if kind_is(peek_kind(q), lex.TokenKind.Comma) {
      let ar3: AdvanceResult = advance(q);
      q = ar3.p;
      if kind_is(peek_kind(q), lex.TokenKind.RBracket) {
        break;
      }
      continue;
    }
    break;
  }
  let ar4: AdvanceResult = expect(q, lex.TokenKind.RBracket);
  return ParseTypeParamsResult { p: ar4.p, tps: tps };
}

fn parse_field_decl(p: Parser) -> ParseFieldResult {
	  let mut q: Parser = p;
	  let mut is_pub: bool = false;
	  if kind_is(peek_kind(q), lex.TokenKind.KwPub) {
	    let ar1: AdvanceResult = advance(q);
	    q = ar1.p;
	    is_pub = true;
	  }
	  let r2: ParseIdentResult = parse_ident(q);
	  let ar3: AdvanceResult = expect(r2.p, lex.TokenKind.Colon);
	  let r4: ParseTypeResult = parse_type_name(ar3.p);
	  return ParseFieldResult { p: r4.p, f: ast.FieldDecl { is_pub: is_pub, name: r2.name, ty: r4.ty } };
}

fn parse_struct_decl(p: Parser, is_pub: bool) -> ParseStructResult {
	  let ar1: AdvanceResult = expect(p, lex.TokenKind.KwStruct);
	  let r2: ParseIdentResult = parse_ident(ar1.p);
	  let ar3: AdvanceResult = expect(r2.p, lex.TokenKind.LBrace);
	  let mut q: Parser = ar3.p;
	  let mut fields: Vec[ast.FieldDecl] = Vec();
	  if !kind_is(peek_kind(q), lex.TokenKind.RBrace) {
	    while !q.has_err {
	      let r: ParseFieldResult = parse_field_decl(q);
	      q = r.p;
	      fields.push(r.f);
	      if kind_is(peek_kind(q), lex.TokenKind.Comma) {
	        let ar4: AdvanceResult = advance(q);
	        q = ar4.p;
	        if kind_is(peek_kind(q), lex.TokenKind.RBrace) {
	          break;
	        }
	        continue;
	      }
	      break;
	    }
	  }
	  let ar5: AdvanceResult = expect(q, lex.TokenKind.RBrace);
	  return ParseStructResult { p: ar5.p, s: ast.StructDecl { file: p.file, is_pub: is_pub, name: r2.name, fields: fields } };
}

fn parse_enum_variant_decl(p: Parser) -> ParseVariantResult {
	  let r1: ParseIdentResult = parse_ident(p);
	  let mut q: Parser = r1.p;
	  let mut fields: Vec[ast.TypeName] = Vec();
	  if kind_is(peek_kind(q), lex.TokenKind.LParen) {
	    let ar2: AdvanceResult = advance(q);
	    q = ar2.p;
	    if !kind_is(peek_kind(q), lex.TokenKind.RParen) {
	      while !q.has_err {
	        let tr: ParseTypeResult = parse_type_name(q);
	        q = tr.p;
	        fields.push(tr.ty);
	        if kind_is(peek_kind(q), lex.TokenKind.Comma) {
	          let ar3: AdvanceResult = advance(q);
	          q = ar3.p;
	          if kind_is(peek_kind(q), lex.TokenKind.RParen) {
	            break;
	          }
	          continue;
	        }
	        break;
	      }
	    }
	    let ar4: AdvanceResult = expect(q, lex.TokenKind.RParen);
	    q = ar4.p;
	  }
	  return ParseVariantResult { p: q, v: ast.EnumVariantDecl { name: r1.name, fields: fields } };
}

fn parse_enum_decl(p: Parser, is_pub: bool) -> ParseEnumResult {
	  let ar1: AdvanceResult = expect(p, lex.TokenKind.KwEnum);
	  let r2: ParseIdentResult = parse_ident(ar1.p);
	  let ar3: AdvanceResult = expect(r2.p, lex.TokenKind.LBrace);
	  let mut q: Parser = ar3.p;
	  let mut vars: Vec[ast.EnumVariantDecl] = Vec();
	  if !kind_is(peek_kind(q), lex.TokenKind.RBrace) {
	    while !q.has_err {
	      let vr: ParseVariantResult = parse_enum_variant_decl(q);
	      q = vr.p;
	      vars.push(vr.v);
	      if kind_is(peek_kind(q), lex.TokenKind.Comma) {
	        let ar4: AdvanceResult = advance(q);
	        q = ar4.p;
	        if kind_is(peek_kind(q), lex.TokenKind.RBrace) {
	          break;
	        }
	        continue;
	      }
	      break;
	    }
	  }
	  let ar5: AdvanceResult = expect(q, lex.TokenKind.RBrace);
	  return ParseEnumResult { p: ar5.p, e: ast.EnumDecl { file: p.file, is_pub: is_pub, name: r2.name, variants: vars } };
}

fn parse_params(p: Parser) -> ParseParamsResult {
  let mut q: Parser = p;
  let mut params: Vec[ast.Param] = Vec();
  if kind_is(peek_kind(q), lex.TokenKind.RParen) {
    return ParseParamsResult { p: q, params: params };
  }
  while !q.has_err {
    let r1: ParseIdentResult = parse_ident(q);
    let ar2: AdvanceResult = expect(r1.p, lex.TokenKind.Colon);
    let r3: ParseTypeResult = parse_type_name(ar2.p);
    params.push(ast.Param { name: r1.name, ty: r3.ty });
    q = r3.p;
    if kind_is(peek_kind(q), lex.TokenKind.Comma) {
      let ar4: AdvanceResult = advance(q);
      q = ar4.p;
      if kind_is(peek_kind(q), lex.TokenKind.RParen) {
        break;
      }
      continue;
    }
    break;
  }
  return ParseParamsResult { p: q, params: params };
}

	fn parse_program(p: Parser) -> ParseProgramResult {
	  let mut q: Parser = p;
	  let mut imports: Vec[ast.ImportDecl] = Vec();
	  let mut structs: Vec[ast.StructDecl] = Vec();
	  let mut enums: Vec[ast.EnumDecl] = Vec();
	  let mut funcs: Vec[ast.FuncDecl] = Vec();
	  while !q.has_err && !kind_is(peek_kind(q), lex.TokenKind.Eof) {
	    if kind_is(peek_kind(q), lex.TokenKind.KwImport) {
	      let r: ParseImportResult = parse_import_decl(q);
	      q = r.p;
	      imports.push(r.imp);
	    } else {
	      // optional `pub`
	      let mut is_pub: bool = false;
	      if kind_is(peek_kind(q), lex.TokenKind.KwPub) {
	        let ar1: AdvanceResult = advance(q);
	        q = ar1.p;
	        is_pub = true;
	      }
	      let k: lex.TokenKind = peek_kind(q);
	      if kind_is(k, lex.TokenKind.KwStruct) {
	        let r: ParseStructResult = parse_struct_decl(q, is_pub);
	        q = r.p;
	        structs.push(r.s);
	      } else if kind_is(k, lex.TokenKind.KwEnum) {
	        let r: ParseEnumResult = parse_enum_decl(q, is_pub);
	        q = r.p;
	        enums.push(r.e);
	      } else {
	        let r: ParseFnResult = parse_fn_decl(q, is_pub);
	        q = r.p;
	        funcs.push(r.f);
	      }
	    }
	  }
	  return ParseProgramResult { p: q, prog: ast.Program { imports: imports, structs: structs, enums: enums, funcs: funcs, exprs: q.exprs } };
	}

	pub fn parse_text_with_path(path: String, text: String) -> ParseResult {
	  let lr: lex.LexResult = lex.lex_text(text);
	  if !lex_err_none(lr.err) {
	    return ParseResult { prog: ast.Program { imports: Vec(), structs: Vec(), enums: Vec(), funcs: Vec(), exprs: ast.expr_pool() }, err: ParseError.Lex(lr.err) };
	  }
	  let p: Parser = Parser { file: path, text: text, toks: lr.tokens, pos: 0, has_err: false, err: ParseError.None, exprs: ast.expr_pool() };
	  let r: ParseProgramResult = parse_program(p);
	  return ParseResult { prog: r.prog, err: r.p.err };
	}

	pub fn parse_text(text: String) -> ParseResult {
	  return parse_text_with_path("src/main.vox", text);
	}
