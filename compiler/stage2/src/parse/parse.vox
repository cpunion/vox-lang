import "ast" as ast
import "lex" as lex

pub enum ParseError {
  None,
  Lex(lex.LexError),
  InvalidString(i32, String), // byte offset, reason
  UnexpectedToken(lex.TokenKind, lex.TokenKind, i32), // expected, got, byte offset
}

pub struct ParseDiag {
  pub kind: i32,
  pub code: String,
  pub message: String,
  pub rendered: String,
}

pub fn parse_diag_kind_none() -> i32 { return 0; }
pub fn parse_diag_kind_parse() -> i32 { return 1; }
pub fn parse_diag_kind_lex() -> i32 { return 2; }

pub fn parse_error_to_string(e: ParseError) -> String {
  return match e {
    ParseError.None => "none",
    ParseError.Lex(le) => "lex error: ".concat(lex.lex_error_to_string(le)),
    ParseError.InvalidString(at, why) =>
      "invalid string literal at ".concat(at.to_string()).concat(": ").concat(why),
    ParseError.UnexpectedToken(exp, got, at) =>
      "unexpected token at ".concat(at.to_string())
        .concat(": expected ").concat(lex.token_kind_name(exp))
        .concat(", got ").concat(lex.token_kind_name(got)),
  };
}

fn parse_code_parse() -> String { return "E_PARSE_0001"; }
fn parse_code_lex() -> String { return "E_LEX_0001"; }

pub fn parse_error_kind(e: ParseError) -> i32 {
  return match e {
    ParseError.None => parse_diag_kind_none(),
    ParseError.Lex(_le) => parse_diag_kind_lex(),
    ParseError.InvalidString(_at, _why) => parse_diag_kind_parse(),
    ParseError.UnexpectedToken(_exp, _got, _at) => parse_diag_kind_parse(),
  };
}

pub fn parse_error_code(e: ParseError) -> String {
  return match e {
    ParseError.None => "",
    ParseError.Lex(_le) => parse_code_lex(),
    ParseError.InvalidString(_at, _why) => parse_code_parse(),
    ParseError.UnexpectedToken(_exp, _got, _at) => parse_code_parse(),
  };
}

pub fn parse_error_message(e: ParseError) -> String {
  return match e {
    ParseError.None => "parse error: none",
    ParseError.Lex(le) => "lex error: ".concat(lex.lex_error_to_string(le)),
    ParseError.InvalidString(_at, why) => "parse error: invalid string literal: ".concat(why),
    ParseError.UnexpectedToken(exp, got, _at) =>
      "parse error: unexpected token: expected ".concat(lex.token_kind_name(exp))
        .concat(", got ").concat(lex.token_kind_name(got)),
  };
}

struct LineCol { line: i32, col: i32 }

fn build_line_starts(text: String) -> Vec[i32] {
  // line_starts[i] is the byte offset of the first character of line (i+1).
  // Always contains 0 for line 1.
  let mut out: Vec[i32] = Vec();
  out.push(0);
  let mut i: i32 = 0;
  while i < text.len() {
    if text.byte_at(i) == 10 { out.push(i + 1); } // '\n'
    i = i + 1;
  }
  return out;
}

fn is_utf8_cont_byte(b: i32) -> bool {
  return b >= 128 && b <= 191;
}

fn rune_col_from_line_start(text: String, line_start: i32, at: i32) -> i32 {
  // 1-based rune column.
  if at <= line_start { return 1; }
  let mut col: i32 = 1;
  let mut i: i32 = line_start;
  while i < at {
    let b: i32 = text.byte_at(i);
    if !is_utf8_cont_byte(b) { col = col + 1; }
    i = i + 1;
  }
  return col;
}

fn pos_to_line_col(text: String, line_starts: Vec[i32], at0: i32) -> LineCol {
  let mut at: i32 = at0;
  if at < 0 { at = 0; }
  if at > text.len() { at = text.len(); }

  // Binary search for the last line start <= at.
  let mut lo: i32 = 0;
  let mut hi: i32 = line_starts.len();
  while lo + 1 < hi {
    let mid: i32 = (lo + hi) / 2;
    if line_starts.get(mid) <= at { lo = mid; } else { hi = mid; }
  }
  let line: i32 = lo + 1;
  let col: i32 = rune_col_from_line_start(text, line_starts.get(lo), at);
  return LineCol { line: line, col: col };
}

fn span_at(p: Parser, at: i32) -> ast.Span {
  let lc: LineCol = pos_to_line_col(p.text, p.line_starts, at);
  return ast.Span { file: p.file, line: lc.line, col: lc.col };
}

fn span_tok(p: Parser, t: lex.Token) -> ast.Span { return span_at(p, t.start); }

fn span_expr(exprs: ast.ExprPool, id: i32) -> ast.Span { return ast.expr_pool_span(exprs, id); }

pub fn parse_error_to_string_with_source(file: String, text: String, e: ParseError) -> String {
  return parse_error_diag(file, text, e).rendered;
}

pub fn parse_error_diag(file: String, text: String, e: ParseError) -> ParseDiag {
  return match e {
    ParseError.None => ParseDiag {
      kind: parse_diag_kind_none(),
      code: "",
      message: "parse error: none",
      rendered: file.concat(":1:1: parse error: none"),
    },
    ParseError.UnexpectedToken(exp, got, at) => ParseDiag {
      kind: parse_diag_kind_parse(),
      code: parse_code_parse(),
      message: parse_error_message(e),
      rendered: format_unexpected_token(file, text, exp, got, at),
    },
    ParseError.InvalidString(at, why) => ParseDiag {
      kind: parse_diag_kind_parse(),
      code: parse_code_parse(),
      message: parse_error_message(e),
      rendered: format_invalid_string(file, text, at, why),
    },
    ParseError.Lex(le) => ParseDiag {
      kind: parse_diag_kind_lex(),
      code: parse_code_lex(),
      message: parse_error_message(e),
      rendered: format_lex_error(file, text, le),
    },
  };
}

fn format_unexpected_token(file: String, text: String, exp: lex.TokenKind, got: lex.TokenKind, at: i32) -> String {
  let code: String = parse_code_parse();
  let lc: LineCol = pos_to_line_col(text, build_line_starts(text), at);
  return file.concat(":").concat(lc.line.to_string()).concat(":").concat(lc.col.to_string())
    .concat(": parse error: unexpected token: expected ").concat(lex.token_kind_name(exp))
    .concat(", got ").concat(lex.token_kind_name(got))
    .concat(" [").concat(code).concat("]");
}

fn format_lex_error(file: String, text: String, le: lex.LexError) -> String {
  return match le {
    lex.LexError.None => file.concat(":1:1: lex error: none"),
    lex.LexError.UnexpectedChar(at) => format_lex_unexpected_char(file, text, at),
    lex.LexError.UnterminatedString(at) => format_lex_unterminated_string(file, text, at),
  };
}

fn format_lex_unexpected_char(file: String, text: String, at: i32) -> String {
  let code: String = parse_code_lex();
  let lc: LineCol = pos_to_line_col(text, build_line_starts(text), at);
  return file.concat(":").concat(lc.line.to_string()).concat(":").concat(lc.col.to_string())
    .concat(": lex error: unexpected char [").concat(code).concat("]");
}

fn format_lex_unterminated_string(file: String, text: String, at: i32) -> String {
  let code: String = parse_code_lex();
  let lc: LineCol = pos_to_line_col(text, build_line_starts(text), at);
  return file.concat(":").concat(lc.line.to_string()).concat(":").concat(lc.col.to_string())
    .concat(": lex error: unterminated string [").concat(code).concat("]");
}

fn format_invalid_string(file: String, text: String, at: i32, why: String) -> String {
  let code: String = parse_code_parse();
  let lc: LineCol = pos_to_line_col(text, build_line_starts(text), at);
  return file.concat(":").concat(lc.line.to_string()).concat(":").concat(lc.col.to_string())
    .concat(": parse error: invalid string literal: ").concat(why)
    .concat(" [").concat(code).concat("]");
}

pub struct ParseResult {
  pub prog: ast.Program,
  pub err: ParseError,
}

struct Parser {
  file: String,
  text: String,
  line_starts: Vec[i32],
  toks: Vec[lex.Token],
  pos: i32,
  has_err: bool,
  err: ParseError,
  exprs: ast.ExprPool,
}

struct AdvanceResult { p: Parser, tok: lex.Token }
struct ParseIdentResult { p: Parser, name: String, at: i32 }
struct ParseTypeResult { p: Parser, ty: ast.TypeName }
	struct ParseExprResult { p: Parser, id: i32 }
	struct ParseStmtResult { p: Parser, st: ast.Stmt }
	struct ParseBlockResult { p: Parser, b: ast.Block }
		struct ParseFnResult { p: Parser, f: ast.FuncDecl }
		struct ParseStructResult { p: Parser, s: ast.StructDecl }
		struct ParseEnumResult { p: Parser, e: ast.EnumDecl }
		struct ParseTraitResult { p: Parser, t: ast.TraitDecl }
		struct ParseImplResult { p: Parser, i: ast.ImplDecl }
		struct ParseTraitMethodResult { p: Parser, m: ast.TraitMethodDecl }
		struct ParseTraitAssocTypeResult { p: Parser, a: ast.TraitAssocTypeDecl }
		struct ParseImplAssocTypeResult { p: Parser, a: ast.ImplAssocTypeBinding }
		struct ParseTypeAliasResult { p: Parser, t: ast.TypeAliasDecl }
		struct ParseConstResult { p: Parser, c: ast.ConstDecl }
		struct ParseProgramResult { p: Parser, prog: ast.Program }
	struct ParseImportResult { p: Parser, imp: ast.ImportDecl }
	struct ParseStringResult { p: Parser, s: String, at: i32 }
struct DecodeStringResult { ok: bool, text: String, err: String }
struct LineIndentInfo { blank: bool, has_tab_indent: bool, indent: i32 }
struct ParseImportNameResult { p: Parser, nm: ast.ImportName }
struct ParseParamsResult { p: Parser, params: Vec[ast.Param] }
struct ParseFieldResult { p: Parser, f: ast.FieldDecl }
struct ParseVariantResult { p: Parser, v: ast.EnumVariantDecl }
struct ParsePatResult { p: Parser, pat: ast.Pat }
struct ParseArmResult { p: Parser, arm: ast.MatchArm }
struct ParseTypeParamsResult { p: Parser, tps: Vec[String], tpbs: Vec[ast.TypeParamBoundsDecl] }
struct ParseFnTypeParamsResult { p: Parser, tps: Vec[String], tpps: Vec[String], cps: Vec[ast.ConstParamDecl], tpbs: Vec[ast.TypeParamBoundsDecl] }
struct ParseWhereBoundsResult { p: Parser, tpbs: Vec[ast.TypeParamBoundsDecl], cwbs: Vec[ast.ConstWhereDecl] }
struct ParseBracedExprResult { p: Parser, id: i32 }
struct ParseTypeDeclResult { p: Parser, is_union: bool, t: ast.TypeAliasDecl, e: ast.EnumDecl }
struct ParsePubResult { p: Parser, vis: i32, is_pub: bool }
struct ParseConstDefaultResult { p: Parser, ok: bool, text: String }

fn dummy_token() -> lex.Token {
  return lex.Token { kind: lex.TokenKind.Eof, start: 0, end: 0 };
}

fn lex_err_none(e: lex.LexError) -> bool {
  return match e {
    lex.LexError.None => true,
    _ => false,
  };
}

fn peek(p: Parser) -> lex.Token {
  let toks: Vec[lex.Token] = p.toks;
  if p.pos < toks.len() { return toks.get(p.pos); }
  return dummy_token();
}

fn peek_kind(p: Parser) -> lex.TokenKind {
  return peek(p).kind;
}

	fn peek2_kind(p: Parser) -> lex.TokenKind {
	  let toks: Vec[lex.Token] = p.toks;
	  let i: i32 = p.pos + 1;
	  if i < toks.len() { return toks.get(i).kind; }
	  return lex.TokenKind.Eof;
	}

fn peek3_kind(p: Parser) -> lex.TokenKind {
  let toks: Vec[lex.Token] = p.toks;
  let i: i32 = p.pos + 2;
  if i < toks.len() { return toks.get(i).kind; }
  return lex.TokenKind.Eof;
}

fn peek4_kind(p: Parser) -> lex.TokenKind {
  let toks: Vec[lex.Token] = p.toks;
  let i: i32 = p.pos + 3;
  if i < toks.len() { return toks.get(i).kind; }
  return lex.TokenKind.Eof;
}

fn peek_ident_is(p: Parser, want: String) -> bool {
  let t: lex.Token = peek(p);
  if !kind_is(t.kind, lex.TokenKind.Ident) { return false; }
  return lexeme(p, t) == want;
}

fn peek2_ident_is(p: Parser, want: String) -> bool {
  let toks: Vec[lex.Token] = p.toks;
  let i: i32 = p.pos + 1;
  if i >= toks.len() { return false; }
  let t: lex.Token = toks.get(i);
  if !kind_is(t.kind, lex.TokenKind.Ident) { return false; }
  return lexeme(p, t) == want;
}

fn kind_is(k: lex.TokenKind, want: lex.TokenKind) -> bool {
  return lex.token_kind_eq(k, want);
}

fn is_assign_op(k: lex.TokenKind) -> bool {
  return match k {
    lex.TokenKind.Eq => true,
    lex.TokenKind.PlusEq => true,
    lex.TokenKind.MinusEq => true,
    lex.TokenKind.StarEq => true,
    lex.TokenKind.SlashEq => true,
    lex.TokenKind.PercentEq => true,
    lex.TokenKind.AmpEq => true,
    lex.TokenKind.PipeEq => true,
    lex.TokenKind.CaretEq => true,
    lex.TokenKind.LtLtEq => true,
    lex.TokenKind.GtGtEq => true,
    _ => false,
  };
}

fn assign_op_to_binary(k: lex.TokenKind) -> ast.BinaryOp {
  return match k {
    lex.TokenKind.PlusEq => ast.BinaryOp.Add,
    lex.TokenKind.MinusEq => ast.BinaryOp.Sub,
    lex.TokenKind.StarEq => ast.BinaryOp.Mul,
    lex.TokenKind.SlashEq => ast.BinaryOp.Div,
    lex.TokenKind.PercentEq => ast.BinaryOp.Mod,
    lex.TokenKind.AmpEq => ast.BinaryOp.BitAnd,
    lex.TokenKind.PipeEq => ast.BinaryOp.BitOr,
    lex.TokenKind.CaretEq => ast.BinaryOp.BitXor,
    lex.TokenKind.LtLtEq => ast.BinaryOp.Shl,
    lex.TokenKind.GtGtEq => ast.BinaryOp.Shr,
    _ => ast.BinaryOp.Add,
  };
}

fn is_field_assign_start(p: Parser) -> bool {
  if !kind_is(peek_kind(p), lex.TokenKind.Ident) { return false; }
  let toks: Vec[lex.Token] = p.toks;
  let n: i32 = toks.len();
  let mut i: i32 = p.pos + 1;
  let mut saw_field: bool = false;
  while (i + 1) < n && kind_is(toks.get(i).kind, lex.TokenKind.Dot) && kind_is(toks.get(i + 1).kind, lex.TokenKind.Ident) {
    saw_field = true;
    i = i + 2;
  }
  if !saw_field { return false; }
  if i >= n { return false; }
  return is_assign_op(toks.get(i).kind);
}

fn join_field_path(parts: Vec[String]) -> String {
  let mut out: String = "";
  let mut i: i32 = 0;
  while i < parts.len() {
    if i > 0 { out = out.concat("."); }
    out = out.concat(parts.get(i));
    i = i + 1;
  }
  return out;
}

fn advance(p: Parser) -> AdvanceResult {
  let tok: lex.Token = peek(p);
  let mut q: Parser = p;
  let toks: Vec[lex.Token] = q.toks;
  if q.pos < toks.len() { q.pos = q.pos + 1; }
  return AdvanceResult { p: q, tok: tok };
}

fn expect(p: Parser, want: lex.TokenKind) -> AdvanceResult {
  if p.has_err {
    return AdvanceResult { p: p, tok: dummy_token() };
  }
  let got: lex.TokenKind = peek_kind(p);
  if kind_is(got, want) {
    return advance(p);
  }
  let mut q: Parser = p;
  let at: i32 = peek(p).start;
  q.has_err = true;
  q.err = ParseError.UnexpectedToken(want, got, at);
  return AdvanceResult { p: q, tok: dummy_token() };
}

fn lexeme(p: Parser, t: lex.Token) -> String {
  let text: String = p.text;
  return text.slice(t.start, t.end);
}

fn parse_ident(p: Parser) -> ParseIdentResult {
  let ar: AdvanceResult = expect(p, lex.TokenKind.Ident);
  let name: String = lexeme(ar.p, ar.tok);
  return ParseIdentResult { p: ar.p, name: name, at: ar.tok.start };
}

fn parse_type_name(p: Parser) -> ParseTypeResult {
  // Unit type: `()`
  if kind_is(peek_kind(p), lex.TokenKind.LParen) && kind_is(peek2_kind(p), lex.TokenKind.RParen) {
    let ar1: AdvanceResult = advance(p);
    let ar2: AdvanceResult = expect(ar1.p, lex.TokenKind.RParen);
    let mut parts: Vec[String] = Vec();
    parts.push("()");
    return ParseTypeResult { p: ar2.p, ty: ast.TypeName { parts: parts, args: Vec() } };
  }

  // Reflect type: `@field_type(T, I)`
  // Range type: `@range(lo..=hi) Base`
  if kind_is(peek_kind(p), lex.TokenKind.At) {
    let ar0: AdvanceResult = advance(p); // @
    let rkw: ParseIdentResult = parse_ident(ar0.p);
    let mut q: Parser = rkw.p;
    if rkw.name == "field_type" {
      let ar1f: AdvanceResult = expect(q, lex.TokenKind.LParen);
      let trt: ParseTypeResult = parse_type_name(ar1f.p);
      let arcf: AdvanceResult = expect(trt.p, lex.TokenKind.Comma);
      let drf: ParseConstDefaultResult = parse_const_default_text(arcf.p);
      if !drf.ok {
        let mut qerrf: Parser = drf.p;
        qerrf.has_err = true;
        qerrf.err = ParseError.UnexpectedToken(lex.TokenKind.Int, peek_kind(drf.p), peek(drf.p).start);
        return ParseTypeResult { p: qerrf, ty: ast.TypeName { parts: Vec(), args: Vec() } };
      }
      let mut qf: Parser = drf.p;
      if kind_is(peek_kind(qf), lex.TokenKind.Comma) {
        let arx: AdvanceResult = advance(qf);
        qf = arx.p;
      }
      let ar2f: AdvanceResult = expect(qf, lex.TokenKind.RParen);
      let mut partsf: Vec[String] = Vec();
      partsf.push("@field_type");
      partsf.push(drf.text);
      let mut argsf: Vec[ast.TypeName] = Vec();
      argsf.push(trt.ty);
      return ParseTypeResult { p: ar2f.p, ty: ast.TypeName { parts: partsf, args: argsf } };
    }

    if rkw.name != "range" {
      q.has_err = true;
      q.err = ParseError.UnexpectedToken(lex.TokenKind.Ident, peek_kind(q), rkw.at);
      return ParseTypeResult { p: q, ty: ast.TypeName { parts: Vec(), args: Vec() } };
    }
    let ar1: AdvanceResult = expect(q, lex.TokenKind.LParen);
    let mut q2: Parser = ar1.p;
    let mut lo_neg: bool = false;
    if kind_is(peek_kind(q2), lex.TokenKind.Minus) { lo_neg = true; let arx: AdvanceResult = advance(q2); q2 = arx.p; }
    let arlo: AdvanceResult = expect(q2, lex.TokenKind.Int);
    let mut lo_s: String = lexeme(arlo.p, arlo.tok);
    if lo_neg { lo_s = "-".concat(lo_s); }

    let ardd: AdvanceResult = expect(arlo.p, lex.TokenKind.DotDotEq);
    let mut q3: Parser = ardd.p;
    let mut hi_neg: bool = false;
    if kind_is(peek_kind(q3), lex.TokenKind.Minus) { hi_neg = true; let ary: AdvanceResult = advance(q3); q3 = ary.p; }
    let arhi: AdvanceResult = expect(q3, lex.TokenKind.Int);
    let mut hi_s: String = lexeme(arhi.p, arhi.tok);
    if hi_neg { hi_s = "-".concat(hi_s); }
    let ar2: AdvanceResult = expect(arhi.p, lex.TokenKind.RParen);
    let trb: ParseTypeResult = parse_type_name(ar2.p);
    let mut parts: Vec[String] = Vec();
    parts.push("@range");
    parts.push(lo_s);
    parts.push(hi_s);
    let mut args: Vec[ast.TypeName] = Vec();
    args.push(trb.ty);
    return ParseTypeResult { p: trb.p, ty: ast.TypeName { parts: parts, args: args } };
  }

  let r0: ParseIdentResult = parse_ident(p);
  let mut q: Parser = r0.p;
  let mut parts: Vec[String] = Vec();
  parts.push(r0.name);
  while kind_is(peek_kind(q), lex.TokenKind.Dot) && !q.has_err {
    let ar1: AdvanceResult = advance(q);
    let r2: ParseIdentResult = parse_ident(ar1.p);
    q = r2.p;
    parts.push(r2.name);
  }

  let mut args: Vec[ast.TypeName] = Vec();
  if kind_is(peek_kind(q), lex.TokenKind.LBracket) {
    let ar3: AdvanceResult = advance(q);
    q = ar3.p;
    if !kind_is(peek_kind(q), lex.TokenKind.RBracket) {
      while !q.has_err {
        let tr: ParseTypeResult = parse_type_name(q);
        q = tr.p;
        args.push(tr.ty);
        if kind_is(peek_kind(q), lex.TokenKind.Comma) {
          let ar4: AdvanceResult = advance(q);
          q = ar4.p;
          if kind_is(peek_kind(q), lex.TokenKind.RBracket) {
            break;
          }
          continue;
        }
        break;
      }
    }
    let ar5: AdvanceResult = expect(q, lex.TokenKind.RBracket);
    q = ar5.p;
  }
  return ParseTypeResult { p: q, ty: ast.TypeName { parts: parts, args: args } };
}

fn add_expr(p: Parser, sp: ast.Span, node: ast.ExprNode) -> ParseExprResult {
  let r: ast.AddExprResult = ast.expr_pool_add(p.exprs, node, sp);
  let mut q: Parser = p;
  q.exprs = r.pool;
  return ParseExprResult { p: q, id: r.id };
}

fn str_is_triple_quoted(lit: String) -> bool {
  return lit.len() >= 6 && lit.slice(0, 3) == "\"\"\"" && lit.slice(lit.len() - 3, lit.len()) == "\"\"\"";
}

fn normalize_newlines(s0: String) -> String {
  let mut out: String = "";
  let mut i: i32 = 0;
  while i < s0.len() {
    let b: i32 = s0.byte_at(i);
    if b == 13 { // \r
      if (i + 1) < s0.len() && s0.byte_at(i + 1) == 10 {
        i = i + 2;
      } else {
        i = i + 1;
      }
      out = out.concat("\n");
      continue;
    }
    out = out.concat(s0.slice(i, i + 1));
    i = i + 1;
  }
  return out;
}

fn split_lines_keep_empty(s: String) -> Vec[String] {
  let mut out: Vec[String] = Vec();
  let mut cur: String = "";
  let mut i: i32 = 0;
  while i < s.len() {
    let b: i32 = s.byte_at(i);
    if b == 10 {
      out.push(cur);
      cur = "";
      i = i + 1;
      continue;
    }
    cur = cur.concat(s.slice(i, i + 1));
    i = i + 1;
  }
  out.push(cur);
  return out;
}

fn join_lines(ls: Vec[String]) -> String {
  let mut out: String = "";
  let mut i: i32 = 0;
  while i < ls.len() {
    if i > 0 { out = out.concat("\n"); }
    out = out.concat(ls.get(i));
    i = i + 1;
  }
  return out;
}

fn trim_one_trailing_empty_line(ls: Vec[String]) -> Vec[String] {
  if ls.len() == 0 { return ls; }
  if ls.get(ls.len() - 1) != "" { return ls; }
  let mut out: Vec[String] = Vec();
  let mut i: i32 = 0;
  while i < (ls.len() - 1) {
    out.push(ls.get(i));
    i = i + 1;
  }
  return out;
}

fn line_indent_info(line: String) -> LineIndentInfo {
  let mut i: i32 = 0;
  while i < line.len() {
    let b: i32 = line.byte_at(i);
    if b == 32 { // space
      i = i + 1;
      continue;
    }
    if b == 9 { // tab
      return LineIndentInfo { blank: false, has_tab_indent: true, indent: i };
    }
    return LineIndentInfo { blank: false, has_tab_indent: false, indent: i };
  }
  return LineIndentInfo { blank: true, has_tab_indent: false, indent: 0 };
}

fn unescape_relaxed(s: String) -> DecodeStringResult {
  let mut out: String = "";
  let mut i: i32 = 0;
  while i < s.len() {
    let b: i32 = s.byte_at(i);
    if b == 92 { // '\\'
      if (i + 1) < s.len() {
        let nb: i32 = s.byte_at(i + 1);
        if nb == 110 { out = out.concat("\n"); i = i + 2; continue; } // n
        if nb == 114 { out = out.concat("\r"); i = i + 2; continue; } // r
        if nb == 116 { out = out.concat("\t"); i = i + 2; continue; } // t
        if nb == 34 { out = out.concat("\""); i = i + 2; continue; }  // "
        if nb == 92 { out = out.concat("\\"); i = i + 2; continue; }  // \
        // Backward-compatible: unknown escape drops '\' and keeps char.
        out = out.concat(s.slice(i + 1, i + 2));
        i = i + 2;
        continue;
      }
      out = out.concat("\\");
      i = i + 1;
      continue;
    }
    out = out.concat(s.slice(i, i + 1));
    i = i + 1;
  }
  return DecodeStringResult { ok: true, text: out, err: "" };
}

fn decode_string_lit(lit: String) -> DecodeStringResult {
  if !str_is_triple_quoted(lit) {
    let mut s0: String = lit;
    let n0: i32 = s0.len();
    if n0 >= 2 { s0 = s0.slice(1, n0 - 1); }
    return unescape_relaxed(s0);
  }

  let mut body: String = lit.slice(3, lit.len() - 3);
  body = normalize_newlines(body);
  if body.len() > 0 && body.byte_at(0) == 10 {
    body = body.slice(1, body.len());
  }

  let mut lines: Vec[String] = split_lines_keep_empty(body);
  lines = trim_one_trailing_empty_line(lines);

  let mut min_indent: i32 = -1;
  let mut i: i32 = 0;
  while i < lines.len() {
    let inf: LineIndentInfo = line_indent_info(lines.get(i));
    if inf.has_tab_indent {
      return DecodeStringResult { ok: false, text: "", err: "tab indentation is not allowed in multiline string" };
    }
    if !inf.blank {
      if min_indent == -1 || inf.indent < min_indent { min_indent = inf.indent; }
    }
    i = i + 1;
  }
  if min_indent < 0 {
    return DecodeStringResult { ok: true, text: "", err: "" };
  }

  let mut norm: Vec[String] = Vec();
  let mut j: i32 = 0;
  while j < lines.len() {
    let ln: String = lines.get(j);
    let inf2: LineIndentInfo = line_indent_info(ln);
    if inf2.has_tab_indent {
      return DecodeStringResult { ok: false, text: "", err: "tab indentation is not allowed in multiline string" };
    }
    if inf2.blank {
      norm.push("");
    } else if ln.len() <= min_indent {
      norm.push("");
    } else {
      norm.push(ln.slice(min_indent, ln.len()));
    }
    j = j + 1;
  }

  return unescape_relaxed(join_lines(norm));
}

fn parse_string_inner(p: Parser) -> ParseStringResult {
  let ar: AdvanceResult = expect(p, lex.TokenKind.Str);
  let at: i32 = ar.tok.start;
  let d: DecodeStringResult = decode_string_lit(lexeme(ar.p, ar.tok));
  if !d.ok {
    let mut q: Parser = ar.p;
    q.has_err = true;
    q.err = ParseError.InvalidString(at, d.err);
    return ParseStringResult { p: q, s: "", at: at };
  }
  return ParseStringResult { p: ar.p, s: d.text, at: at };
}

fn parse_import_name(p: Parser) -> ParseImportNameResult {
  let r0: ParseIdentResult = parse_ident(p);
  let mut q: Parser = r0.p;
  let mut alias: String = "";
  if kind_is(peek_kind(q), lex.TokenKind.KwAs) {
    let ar1: AdvanceResult = advance(q);
    let r2: ParseIdentResult = parse_ident(ar1.p);
    q = r2.p;
    alias = r2.name;
  }
  return ParseImportNameResult { p: q, nm: ast.ImportName { name: r0.name, alias: alias, sp: span_at(p, r0.at) } };
}

fn parse_import_decl(p: Parser) -> ParseImportResult {
  let ar1: AdvanceResult = expect(p, lex.TokenKind.KwImport);
  let dsp: ast.Span = span_tok(p, ar1.tok);

  // Named imports: `import { a, b as c } from "path"`
  if kind_is(peek_kind(ar1.p), lex.TokenKind.LBrace) {
    let ar2: AdvanceResult = advance(ar1.p);
    let mut q: Parser = ar2.p;
    let mut names: Vec[ast.ImportName] = Vec();
    if !kind_is(peek_kind(q), lex.TokenKind.RBrace) {
      while !q.has_err {
        let nr: ParseImportNameResult = parse_import_name(q);
        q = nr.p;
        names.push(nr.nm);
        if kind_is(peek_kind(q), lex.TokenKind.Comma) {
          let ar3: AdvanceResult = advance(q);
          q = ar3.p;
          if kind_is(peek_kind(q), lex.TokenKind.RBrace) {
            break;
          }
          continue;
        }
        break;
      }
    }
    let ar4: AdvanceResult = expect(q, lex.TokenKind.RBrace);
    let ar5: AdvanceResult = expect(ar4.p, lex.TokenKind.KwFrom);
    let r6: ParseStringResult = parse_string_inner(ar5.p);
    return ParseImportResult { p: r6.p, imp: ast.ImportDecl { file: p.file, sp: dsp, path: r6.s, alias: "", names: names } };
  }

  // Module import: `import "path" as alias`
  let r2: ParseStringResult = parse_string_inner(ar1.p);
  let mut q: Parser = r2.p;
  let path: String = r2.s;
  let mut alias: String = "";
  if kind_is(peek_kind(q), lex.TokenKind.KwAs) {
    let ar3: AdvanceResult = advance(q);
    let r4: ParseIdentResult = parse_ident(ar3.p);
    q = r4.p;
    alias = r4.name;
  }
  return ParseImportResult { p: q, imp: ast.ImportDecl { file: p.file, sp: dsp, path: path, alias: alias, names: Vec() } };
}

fn parse_braced_expr(p: Parser) -> ParseBracedExprResult {
  // Back-compat helper used by if-expr parsing; now parses a full block expression.
  let r: ParseExprResult = parse_expr_block(p);
  return ParseBracedExprResult { p: r.p, id: r.id };
}

fn if_expr_has_else_ahead(p: Parser) -> bool {
  // Look ahead to see if this `if` is syntactically an if-expression (has an `else`
  // immediately after its then-branch). This is used to disambiguate `if` inside
  // expression blocks so `{ if cond { a } else { b } }` parses as a block tail expression,
  // while still allowing statement `if` without `else`.
  if !kind_is(peek_kind(p), lex.TokenKind.KwIf) { return false; }
  let toks: Vec[lex.Token] = p.toks;
  let mut i: i32 = p.pos + 1;
  let mut dp: i32 = 0; // ()
  let mut db: i32 = 0; // []
  let mut dc: i32 = 0; // {} inside condition
  let mut then_i: i32 = -1;

  while i < toks.len() {
    let k: lex.TokenKind = toks.get(i).kind;
    if kind_is(k, lex.TokenKind.Eof) { return false; }
    if kind_is(k, lex.TokenKind.LParen) { dp = dp + 1; }
    else if kind_is(k, lex.TokenKind.RParen) { if dp > 0 { dp = dp - 1; } }
    else if kind_is(k, lex.TokenKind.LBracket) { db = db + 1; }
    else if kind_is(k, lex.TokenKind.RBracket) { if db > 0 { db = db - 1; } }
    else if kind_is(k, lex.TokenKind.LBrace) {
      if dp == 0 && db == 0 && dc == 0 { then_i = i; break; }
      dc = dc + 1;
    } else if kind_is(k, lex.TokenKind.RBrace) {
      if dc > 0 { dc = dc - 1; }
    }
    i = i + 1;
  }
  if then_i == -1 { return false; }

  // Match the then-branch `{ ... }`.
  i = then_i + 1;
  let mut brace: i32 = 1;
  while i < toks.len() {
    let k2: lex.TokenKind = toks.get(i).kind;
    if kind_is(k2, lex.TokenKind.Eof) { return false; }
    if kind_is(k2, lex.TokenKind.LBrace) { brace = brace + 1; }
    else if kind_is(k2, lex.TokenKind.RBrace) {
      brace = brace - 1;
      if brace == 0 { i = i + 1; break; }
    }
    i = i + 1;
  }
  if brace != 0 { return false; }
  return i < toks.len() && kind_is(toks.get(i).kind, lex.TokenKind.KwElse);
}

fn parse_expr_block(p: Parser) -> ParseExprResult {
  // `{ stmt*; tailExpr }` where tailExpr is optional (missing => unit).
  let ar1: AdvanceResult = expect(p, lex.TokenKind.LBrace);
  let mut q: Parser = ar1.p;
  let sp0: ast.Span = span_tok(p, ar1.tok);
  let mut stmts: Vec[ast.Stmt] = Vec();
  let mut has_tail: bool = false;
  let mut tail: i32 = -1;

  while !q.has_err && !kind_is(peek_kind(q), lex.TokenKind.RBrace) && !kind_is(peek_kind(q), lex.TokenKind.Eof) {
    let k: lex.TokenKind = peek_kind(q);

    let is_stmt: bool =
      kind_is(k, lex.TokenKind.KwLet) ||
      (kind_is(k, lex.TokenKind.KwIf) && !if_expr_has_else_ahead(q)) ||
      kind_is(k, lex.TokenKind.KwWhile) ||
      kind_is(k, lex.TokenKind.KwBreak) ||
      kind_is(k, lex.TokenKind.KwContinue) ||
      kind_is(k, lex.TokenKind.KwReturn) ||
      // assignment: ident <assign-op> ...
      (kind_is(k, lex.TokenKind.Ident) && is_assign_op(peek2_kind(q))) ||
      // field assignment: ident(.ident)+ <assign-op> ...
      is_field_assign_start(q);

    if is_stmt {
      let sr: ParseStmtResult = parse_stmt(q);
      q = sr.p;
      stmts.push(sr.st);
      continue;
    }

    let er: ParseExprResult = parse_expr(q, 0);
    q = er.p;
    if q.has_err {
      return ParseExprResult { p: q, id: -1 };
    }
    if kind_is(peek_kind(q), lex.TokenKind.Semicolon) {
      let ar2: AdvanceResult = advance(q);
      q = ar2.p;
      stmts.push(ast.Stmt.ExprStmt(span_expr(q.exprs, er.id), er.id));
      continue;
    }
    has_tail = true;
    tail = er.id;
    break;
  }

  let ar3: AdvanceResult = expect(q, lex.TokenKind.RBrace);
  let b: ast.ExprBlock = ast.ExprBlock { stmts: stmts, has_tail: has_tail, tail: tail };
  return add_expr(ar3.p, sp0, ast.ExprNode.Block(b));
}

fn parse_if_expr(p: Parser) -> ParseExprResult {
  // if <cond> { <expr> } else { <expr> }
  let ar1: AdvanceResult = expect(p, lex.TokenKind.KwIf);
  let sp0: ast.Span = span_tok(p, ar1.tok);
  let r2: ParseExprResult = parse_expr(ar1.p, 0);
  let br1: ParseBracedExprResult = parse_braced_expr(r2.p);
  let ar3: AdvanceResult = expect(br1.p, lex.TokenKind.KwElse);

  // else if ...  ==> else { if ... } (AST nests If)
  if kind_is(peek_kind(ar3.p), lex.TokenKind.KwIf) {
    let r4: ParseExprResult = parse_if_expr(ar3.p);
    return add_expr(r4.p, sp0, ast.ExprNode.If(r2.id, br1.id, r4.id));
  }
  let br2: ParseBracedExprResult = parse_braced_expr(ar3.p);
  return add_expr(br2.p, sp0, ast.ExprNode.If(r2.id, br1.id, br2.id));
}

fn is_reflect_intrinsic_name(iname: String, is_compile_error: bool) -> bool {
  return is_compile_error ||
    iname == "size_of" ||
    iname == "align_of" ||
    iname == "type" ||
    iname == "type_name" ||
    iname == "field_count" ||
    iname == "field_name" ||
    iname == "field_type" ||
    iname == "field_type_id" ||
    iname == "same_type" ||
    iname == "assignable_to" ||
    iname == "castable_to" ||
    iname == "eq_comparable_with" ||
    iname == "ordered_with" ||
    iname == "same_layout" ||
    iname == "bitcastable" ||
    iname == "is_integer" ||
    iname == "is_signed_int" ||
    iname == "is_unsigned_int" ||
    iname == "is_float" ||
    iname == "is_bool" ||
    iname == "is_string" ||
    iname == "is_struct" ||
    iname == "is_enum" ||
    iname == "is_vec" ||
    iname == "is_range" ||
    iname == "is_eq_comparable" ||
    iname == "is_ordered" ||
    iname == "is_unit" ||
    iname == "is_numeric" ||
    iname == "is_zero_sized";
}

fn parse_reflect_intrinsic_primary(p: Parser) -> ParseExprResult {
  let ar0: AdvanceResult = expect(p, lex.TokenKind.At);
  let sp0: ast.Span = span_tok(p, ar0.tok);
  let mut qname: Parser = ar0.p;
  let mut iname: String = "";
  let mut iname_at: i32 = peek(qname).start;
  if kind_is(peek_kind(qname), lex.TokenKind.Ident) {
    let rname: ParseIdentResult = parse_ident(qname);
    qname = rname.p;
    iname = rname.name;
    iname_at = rname.at;
  } else if kind_is(peek_kind(qname), lex.TokenKind.KwType) {
    let ar_kw: AdvanceResult = advance(qname);
    qname = ar_kw.p;
    iname = "type";
    iname_at = ar_kw.tok.start;
  } else {
    let mut qerr0: Parser = qname;
    qerr0.has_err = true;
    qerr0.err = ParseError.UnexpectedToken(lex.TokenKind.Ident, peek_kind(qname), peek(qname).start);
    return ParseExprResult { p: qerr0, id: -1 };
  }

  let is_compile_error: bool = iname == "compile_error";
  if !is_reflect_intrinsic_name(iname, is_compile_error) {
    let mut q0: Parser = qname;
    q0.has_err = true;
    q0.err = ParseError.UnexpectedToken(lex.TokenKind.Ident, peek_kind(qname), iname_at);
    return ParseExprResult { p: q0, id: -1 };
  }

  let ar1: AdvanceResult = expect(qname, lex.TokenKind.LParen);
  if is_compile_error {
    let er: ParseExprResult = parse_expr(ar1.p, 0);
    if er.p.has_err { return er; }
    let mut q2c: Parser = er.p;
    if kind_is(peek_kind(q2c), lex.TokenKind.Comma) {
      let arx: AdvanceResult = advance(q2c);
      q2c = arx.p;
    }
    let ar2c: AdvanceResult = expect(q2c, lex.TokenKind.RParen);
    let idc: ParseExprResult = add_expr(ar2c.p, sp0, ast.ExprNode.Ident("@".concat(iname)));
    if idc.p.has_err { return idc; }
    let mut args0: Vec[i32] = Vec();
    args0.push(er.id);
    return add_expr(idc.p, sp0, ast.ExprNode.Call(idc.id, Vec(), args0));
  }

  let tr: ParseTypeResult = parse_type_name(ar1.p);
  let mut q2: Parser = tr.p;
  let mut targs: Vec[ast.TypeName] = Vec();
  targs.push(tr.ty);
  if iname == "field_name" || iname == "field_type" || iname == "field_type_id" {
    let arx: AdvanceResult = expect(q2, lex.TokenKind.Comma);
    q2 = arx.p;
    let dr: ParseConstDefaultResult = parse_const_default_text(q2);
    if !dr.ok {
      let mut qerr: Parser = dr.p;
      qerr.has_err = true;
      qerr.err = ParseError.UnexpectedToken(lex.TokenKind.Int, peek_kind(dr.p), peek(dr.p).start);
      return ParseExprResult { p: qerr, id: -1 };
    }
    q2 = dr.p;
    targs.push(const_generic_arg_tn(dr.text));
  } else if iname == "same_type" || iname == "assignable_to" || iname == "castable_to" || iname == "eq_comparable_with" || iname == "ordered_with" || iname == "same_layout" || iname == "bitcastable" {
    let arx2: AdvanceResult = expect(q2, lex.TokenKind.Comma);
    q2 = arx2.p;
    let tr2: ParseTypeResult = parse_type_name(q2);
    q2 = tr2.p;
    targs.push(tr2.ty);
  }
  if kind_is(peek_kind(q2), lex.TokenKind.Comma) {
    let arx3: AdvanceResult = advance(q2);
    q2 = arx3.p;
  }
  let ar2: AdvanceResult = expect(q2, lex.TokenKind.RParen);

  let idr: ParseExprResult = add_expr(ar2.p, sp0, ast.ExprNode.Ident("@".concat(iname)));
  if idr.p.has_err { return idr; }
  return add_expr(idr.p, sp0, ast.ExprNode.Call(idr.id, targs, Vec()));
}

fn parse_quote_expr_primary(p: Parser) -> ParseExprResult {
  // `quote expr { ... }` is surface sugar lowered to `quote!(...)`.
  let ar0: AdvanceResult = expect(p, lex.TokenKind.Ident); // quote
  let sp0: ast.Span = span_tok(p, ar0.tok);
  let ar1: AdvanceResult = expect(ar0.p, lex.TokenKind.Ident); // expr
  let ar2: AdvanceResult = expect(ar1.p, lex.TokenKind.LBrace);
  let er: ParseExprResult = parse_expr(ar2.p, 0);
  if er.p.has_err { return er; }
  let ar3: AdvanceResult = expect(er.p, lex.TokenKind.RBrace);
  let idq: ParseExprResult = add_expr(ar3.p, sp0, ast.ExprNode.Ident("quote"));
  if idq.p.has_err { return idq; }
  let mut args: Vec[i32] = Vec();
  args.push(er.id);
  return add_expr(idq.p, sp0, ast.ExprNode.MacroCall(idq.id, Vec(), args));
}

fn parse_primary(p: Parser) -> ParseExprResult {
  if p.has_err {
    return ParseExprResult { p: p, id: -1 };
  }
  let k: lex.TokenKind = peek_kind(p);

  if kind_is(k, lex.TokenKind.Int) {
    let ar: AdvanceResult = advance(p);
    let tok: lex.Token = ar.tok;
    return add_expr(ar.p, span_tok(p, tok), ast.ExprNode.Int(lexeme(ar.p, tok)));
  }

  if kind_is(k, lex.TokenKind.Float) {
    let ar: AdvanceResult = advance(p);
    let tok: lex.Token = ar.tok;
    return add_expr(ar.p, span_tok(p, tok), ast.ExprNode.Float(lexeme(ar.p, tok)));
  }

  if kind_is(k, lex.TokenKind.KwTrue) {
    let ar: AdvanceResult = advance(p);
    return add_expr(ar.p, span_tok(p, ar.tok), ast.ExprNode.Bool(true));
  }
  if kind_is(k, lex.TokenKind.KwFalse) {
    let ar: AdvanceResult = advance(p);
    return add_expr(ar.p, span_tok(p, ar.tok), ast.ExprNode.Bool(false));
  }

  // Surface quote syntax:
  //   quote expr { ... }
  if kind_is(k, lex.TokenKind.Ident) &&
    peek_ident_is(p, "quote") &&
    peek2_ident_is(p, "expr") &&
    kind_is(peek3_kind(p), lex.TokenKind.LBrace) {
    return parse_quote_expr_primary(p);
  }

  if kind_is(k, lex.TokenKind.Ident) {
    let r: ParseIdentResult = parse_ident(p);
    return add_expr(r.p, span_at(p, r.at), ast.ExprNode.Ident(r.name));
  }

  if kind_is(k, lex.TokenKind.At) {
    return parse_reflect_intrinsic_primary(p);
  }

  // Enum variant shorthand: `.Variant`
  if kind_is(k, lex.TokenKind.Dot) {
    let ar: AdvanceResult = advance(p);
    let sp0: ast.Span = span_tok(p, ar.tok);
    let r: ParseIdentResult = parse_ident(ar.p);
    return add_expr(r.p, sp0, ast.ExprNode.DotIdent(r.name));
  }

		  if kind_is(k, lex.TokenKind.Str) {
		    let r: ParseStringResult = parse_string_inner(p);
		    return add_expr(r.p, span_at(p, r.at), ast.ExprNode.Str(r.s));
		  }

	if kind_is(k, lex.TokenKind.KwMatch) {
    let ar1: AdvanceResult = advance(p);
    let sp0: ast.Span = span_tok(p, ar1.tok);
    let r2: ParseExprResult = parse_expr(ar1.p, 0);
    let ar3: AdvanceResult = expect(r2.p, lex.TokenKind.LBrace);
    let mut q: Parser = ar3.p;
    let mut arms: Vec[ast.MatchArm] = Vec();
    while !q.has_err && !kind_is(peek_kind(q), lex.TokenKind.RBrace) && !kind_is(peek_kind(q), lex.TokenKind.Eof) {
      let pr: ParsePatResult = parse_pat(q);
      let ar4: AdvanceResult = expect(pr.p, lex.TokenKind.FatArrow);
      let er: ParseExprResult = parse_expr(ar4.p, 0);
      q = er.p;
      arms.push(ast.MatchArm { pat: pr.pat, expr: er.id });
      if kind_is(peek_kind(q), lex.TokenKind.Comma) {
        let ar5: AdvanceResult = advance(q);
        q = ar5.p;
        continue;
      }
      break;
    }
    let ar6: AdvanceResult = expect(q, lex.TokenKind.RBrace);
    return add_expr(ar6.p, sp0, ast.ExprNode.Match(r2.id, arms));
  }

  if kind_is(k, lex.TokenKind.KwIf) {
    return parse_if_expr(p);
  }

  if kind_is(k, lex.TokenKind.KwTry) {
    let ar1: AdvanceResult = advance(p);
    if !kind_is(peek_kind(ar1.p), lex.TokenKind.LBrace) {
      let mut q: Parser = ar1.p;
      q.has_err = true;
      q.err = ParseError.UnexpectedToken(lex.TokenKind.LBrace, peek_kind(ar1.p), peek(ar1.p).start);
      return ParseExprResult { p: q, id: -1 };
    }
    let br: ParseExprResult = parse_expr_block(ar1.p);
    if br.p.has_err { return br; }
    let sp0: ast.Span = span_tok(p, ar1.tok);
    return add_expr(br.p, sp0, ast.ExprNode.TryBlock(br.id));
  }

  if kind_is(k, lex.TokenKind.LBrace) {
    return parse_expr_block(p);
  }

  let mut q: Parser = p;
  let at: i32 = peek(p).start;
  q.has_err = true;
  q.err = ParseError.UnexpectedToken(lex.TokenKind.Ident, k, at);
  return ParseExprResult { p: q, id: -1 };
}

fn const_generic_arg_tn(text: String) -> ast.TypeName {
  let mut parts: Vec[String] = Vec();
  parts.push("@const");
  parts.push(text);
  return ast.TypeName { parts: parts, args: Vec() };
}

fn parse_const_default_text(p: Parser) -> ParseConstDefaultResult {
  if kind_is(peek_kind(p), lex.TokenKind.Minus) && kind_is(peek2_kind(p), lex.TokenKind.Int) {
    let ar0: AdvanceResult = advance(p);
    let ar1: AdvanceResult = expect(ar0.p, lex.TokenKind.Int);
    return ParseConstDefaultResult { p: ar1.p, ok: true, text: "-".concat(lexeme(ar1.p, ar1.tok)) };
  }
  if kind_is(peek_kind(p), lex.TokenKind.Int) {
    let ar0: AdvanceResult = advance(p);
    return ParseConstDefaultResult { p: ar0.p, ok: true, text: lexeme(ar0.p, ar0.tok) };
  }
  return ParseConstDefaultResult { p: p, ok: false, text: "" };
}

fn parse_generic_call_arg(p: Parser) -> ParseTypeResult {
  // Generic call args support:
  // - type args: `T`, `Vec[i32]`, ...
  // - const int args: `3`, `-5` (encoded as pseudo type `@const`)
  if kind_is(peek_kind(p), lex.TokenKind.Minus) && kind_is(peek2_kind(p), lex.TokenKind.Int) {
    let ar0: AdvanceResult = advance(p);
    let ar1: AdvanceResult = expect(ar0.p, lex.TokenKind.Int);
    let text: String = "-".concat(lexeme(ar1.p, ar1.tok));
    return ParseTypeResult { p: ar1.p, ty: const_generic_arg_tn(text) };
  }
  if kind_is(peek_kind(p), lex.TokenKind.Int) {
    let ar0: AdvanceResult = advance(p);
    let text: String = lexeme(ar0.p, ar0.tok);
    return ParseTypeResult { p: ar0.p, ty: const_generic_arg_tn(text) };
  }
  return parse_type_name(p);
}

fn parse_postfix(p: Parser, base: i32) -> ParseExprResult {
		  let mut q: Parser = p;
		  let mut cur: i32 = base;
		  let mut pending_targs: Vec[ast.TypeName] = Vec();
		  while !q.has_err {
	    // Struct literal: `TypePath { field: expr, ... }`
	    //
	    // Ambiguity note: blocks also start with `{`. We only parse a struct literal
	    // when the first field looks like `ident :` (i.e. `{ Ident Colon ... }`).
	    if kind_is(peek_kind(q), lex.TokenKind.LBrace) &&
	      kind_is(peek2_kind(q), lex.TokenKind.Ident) &&
	      kind_is(peek3_kind(q), lex.TokenKind.Colon) {
	      if pending_targs.len() != 0 {
	        let sp_t: ast.Span = span_expr(q.exprs, cur);
	        let r_t: ParseExprResult = add_expr(q, sp_t, ast.ExprNode.Call(cur, pending_targs, Vec()));
	        q = r_t.p;
	        cur = r_t.id;
	        pending_targs = Vec();
	      }
	      let sp0: ast.Span = span_expr(q.exprs, cur);
	      let ar1: AdvanceResult = advance(q);
	      let mut r: Parser = ar1.p;
	      let mut fields: Vec[ast.StructLitField] = Vec();
	      while !r.has_err && !kind_is(peek_kind(r), lex.TokenKind.RBrace) && !kind_is(peek_kind(r), lex.TokenKind.Eof) {
	        let fr: ParseIdentResult = parse_ident(r);
	        let ar2: AdvanceResult = expect(fr.p, lex.TokenKind.Colon);
	        let er: ParseExprResult = parse_expr(ar2.p, 0);
	        r = er.p;
	        fields.push(ast.StructLitField { name: fr.name, expr: er.id });
	        if kind_is(peek_kind(r), lex.TokenKind.Comma) {
	          let ar3: AdvanceResult = advance(r);
	          r = ar3.p;
	          if kind_is(peek_kind(r), lex.TokenKind.RBrace) {
	            break;
	          }
	          continue;
	        }
	        break;
	      }
	      let ar4: AdvanceResult = expect(r, lex.TokenKind.RBrace);
	      let r5: ParseExprResult = add_expr(ar4.p, sp0, ast.ExprNode.StructLit(cur, fields));
	      q = r5.p;
	      cur = r5.id;
	      continue;
	    }
		    if kind_is(peek_kind(q), lex.TokenKind.Dot) {
		      let sp0: ast.Span = span_expr(q.exprs, cur);
		      if pending_targs.len() != 0 {
		        let r_t: ParseExprResult = add_expr(q, sp0, ast.ExprNode.Call(cur, pending_targs, Vec()));
		        q = r_t.p;
		        cur = r_t.id;
		        pending_targs = Vec();
		      }
		      let ar1: AdvanceResult = advance(q);
		      let r2: ParseIdentResult = parse_ident(ar1.p);
		      let r3: ParseExprResult = add_expr(r2.p, sp0, ast.ExprNode.Member(cur, r2.name));
	      q = r3.p;
	      cur = r3.id;
	      continue;
	    }
	    if kind_is(peek_kind(q), lex.TokenKind.KwAs) {
	      if pending_targs.len() != 0 {
	        let mut qq: Parser = q;
	        let at: i32 = peek(q).start;
	        qq.has_err = true;
	        qq.err = ParseError.UnexpectedToken(lex.TokenKind.LParen, lex.TokenKind.KwAs, at);
	        return ParseExprResult { p: qq, id: cur };
	      }
	      let sp0: ast.Span = span_expr(q.exprs, cur);
	      let ar1: AdvanceResult = advance(q);
	      let tr: ParseTypeResult = parse_type_name(ar1.p);
	      let r2: ParseExprResult = add_expr(tr.p, sp0, ast.ExprNode.As(cur, tr.ty));
	      q = r2.p;
	      cur = r2.id;
	      continue;
	    }
	    if kind_is(peek_kind(q), lex.TokenKind.LBracket) {
	      if pending_targs.len() != 0 {
	        let mut qq: Parser = q;
	        let at: i32 = peek(q).start;
	        qq.has_err = true;
	        qq.err = ParseError.UnexpectedToken(lex.TokenKind.LBracket, lex.TokenKind.LBracket, at);
	        return ParseExprResult { p: qq, id: cur };
	      }
	      let ar0: AdvanceResult = advance(q);
	      let mut r: Parser = ar0.p;
	      if !kind_is(peek_kind(r), lex.TokenKind.RBracket) {
	        while !r.has_err {
	          let tr: ParseTypeResult = parse_generic_call_arg(r);
	          r = tr.p;
	          pending_targs.push(tr.ty);
	          if kind_is(peek_kind(r), lex.TokenKind.Comma) {
	            let arx: AdvanceResult = advance(r);
	            r = arx.p;
	            if kind_is(peek_kind(r), lex.TokenKind.RBracket) {
	              break;
	            }
	            continue;
	          }
	          break;
	        }
	      }
	      let ar1: AdvanceResult = expect(r, lex.TokenKind.RBracket);
	      q = ar1.p;
	      continue;
	    }
    if kind_is(peek_kind(q), lex.TokenKind.Not) {
      let sp0: ast.Span = span_expr(q.exprs, cur);
      let bang: AdvanceResult = advance(q);
      let ar1: AdvanceResult = expect(bang.p, lex.TokenKind.LParen);
      let mut r: Parser = ar1.p;
      let mut args: Vec[i32] = Vec();
      if !kind_is(peek_kind(r), lex.TokenKind.RParen) {
        while !r.has_err {
          let er: ParseExprResult = parse_expr(r, 0);
          r = er.p;
          args.push(er.id);
          if kind_is(peek_kind(r), lex.TokenKind.Comma) {
            let ar2: AdvanceResult = advance(r);
            r = ar2.p;
            if kind_is(peek_kind(r), lex.TokenKind.RParen) {
              break;
            }
            continue;
          }
          break;
        }
      }
      let ar3: AdvanceResult = expect(r, lex.TokenKind.RParen);
      let r4: ParseExprResult = add_expr(ar3.p, sp0, ast.ExprNode.MacroCall(cur, pending_targs, args));
      q = r4.p;
      cur = r4.id;
      pending_targs = Vec();
      continue;
    }
	    if kind_is(peek_kind(q), lex.TokenKind.LParen) {
	      let sp0: ast.Span = span_expr(q.exprs, cur);
	      let ar1: AdvanceResult = advance(q);
	      let mut r: Parser = ar1.p;
	      let mut args: Vec[i32] = Vec();
      if !kind_is(peek_kind(r), lex.TokenKind.RParen) {
        while !r.has_err {
          let er: ParseExprResult = parse_expr(r, 0);
          r = er.p;
          args.push(er.id);
          if kind_is(peek_kind(r), lex.TokenKind.Comma) {
            let ar2: AdvanceResult = advance(r);
            r = ar2.p;
            if kind_is(peek_kind(r), lex.TokenKind.RParen) {
              break;
            }
            continue;
          }
          break;
        }
	      }
	      let ar3: AdvanceResult = expect(r, lex.TokenKind.RParen);
	      let r4: ParseExprResult = add_expr(ar3.p, sp0, ast.ExprNode.Call(cur, pending_targs, args));
	      q = r4.p;
	      cur = r4.id;
	      pending_targs = Vec();
	      continue;
	    }
      if kind_is(peek_kind(q), lex.TokenKind.Question) {
        if pending_targs.len() != 0 {
          let mut qq: Parser = q;
          let at: i32 = peek(q).start;
          qq.has_err = true;
          qq.err = ParseError.UnexpectedToken(lex.TokenKind.LParen, lex.TokenKind.Question, at);
          return ParseExprResult { p: qq, id: cur };
        }
        let arq: AdvanceResult = advance(q);
        let spq: ast.Span = span_expr(arq.p.exprs, cur);
        let rq: ParseExprResult = add_expr(arq.p, spq, ast.ExprNode.Try(cur));
        q = rq.p;
        cur = rq.id;
        continue;
      }
	    break;
	  }
	  if pending_targs.len() != 0 {
	    let mut qq: Parser = q;
	    let at: i32 = peek(q).start;
	    qq.has_err = true;
	    qq.err = ParseError.UnexpectedToken(lex.TokenKind.LParen, peek_kind(q), at);
	    return ParseExprResult { p: qq, id: cur };
	  }
		  return ParseExprResult { p: q, id: cur };
		}

fn parse_pat(p: Parser) -> ParsePatResult {
  let sp0: ast.Span = span_at(p, peek(p).start);
  let k: lex.TokenKind = peek_kind(p);
  // Negative integer pattern: `-123`
  if kind_is(k, lex.TokenKind.Minus) && kind_is(peek2_kind(p), lex.TokenKind.Int) {
    let ar0: AdvanceResult = advance(p);
    let ar1: AdvanceResult = expect(ar0.p, lex.TokenKind.Int);
    let tok: lex.Token = ar1.tok;
    let text: String = "-".concat(lexeme(ar1.p, tok));
    return ParsePatResult { p: ar1.p, pat: ast.Pat.Int(sp0, text) };
  }
  if kind_is(k, lex.TokenKind.Int) {
    let ar1: AdvanceResult = advance(p);
    let tok: lex.Token = ar1.tok;
    return ParsePatResult { p: ar1.p, pat: ast.Pat.Int(sp0, lexeme(ar1.p, tok)) };
  }
  if kind_is(k, lex.TokenKind.Str) {
    let r: ParseStringResult = parse_string_inner(p);
    return ParsePatResult { p: r.p, pat: ast.Pat.Str(sp0, r.s) };
  }
  if kind_is(k, lex.TokenKind.KwTrue) {
    let ar1: AdvanceResult = advance(p);
    return ParsePatResult { p: ar1.p, pat: ast.Pat.Bool(sp0, true) };
  }
  if kind_is(k, lex.TokenKind.KwFalse) {
    let ar1: AdvanceResult = advance(p);
    return ParsePatResult { p: ar1.p, pat: ast.Pat.Bool(sp0, false) };
  }

  // Enum variant shorthand pattern: `.Variant(x, y, ...)`
  if kind_is(k, lex.TokenKind.Dot) {
    let ar0: AdvanceResult = advance(p);
    let r0: ParseIdentResult = parse_ident(ar0.p);
    let mut q: Parser = r0.p;
    let mut args: Vec[ast.Pat] = Vec();
    if kind_is(peek_kind(q), lex.TokenKind.LParen) {
      let ar3: AdvanceResult = advance(q);
      q = ar3.p;
      if !kind_is(peek_kind(q), lex.TokenKind.RParen) {
        while !q.has_err {
          let pr: ParsePatResult = parse_pat(q);
          q = pr.p;
          args.push(pr.pat);
          if kind_is(peek_kind(q), lex.TokenKind.Comma) {
            let ar4: AdvanceResult = advance(q);
            q = ar4.p;
            if kind_is(peek_kind(q), lex.TokenKind.RParen) { break; }
            continue;
          }
          break;
        }
      }
      let ar5: AdvanceResult = expect(q, lex.TokenKind.RParen);
      q = ar5.p;
    }
    return ParsePatResult { p: q, pat: ast.Pat.EnumVariant(sp0, Vec(), r0.name, args) };
  }

  // Wildcard: `_`
  if kind_is(k, lex.TokenKind.Ident) {
    let r0: ParseIdentResult = parse_ident(p);
    if r0.name == "_" {
      return ParsePatResult { p: r0.p, pat: ast.Pat.Wild(sp0) };
    }

    // path: a.b.c
    let mut q: Parser = r0.p;
    let mut parts: Vec[String] = Vec();
    parts.push(r0.name);
    while kind_is(peek_kind(q), lex.TokenKind.Dot) && !q.has_err {
      let ar1: AdvanceResult = advance(q);
      let r2: ParseIdentResult = parse_ident(ar1.p);
      q = r2.p;
      parts.push(r2.name);
    }

    // optional payload patterns: (p0, p1, ...)
    let mut args: Vec[ast.Pat] = Vec();
    if kind_is(peek_kind(q), lex.TokenKind.LParen) {
      let ar3: AdvanceResult = advance(q);
      q = ar3.p;
      if !kind_is(peek_kind(q), lex.TokenKind.RParen) {
        while !q.has_err {
          let pr: ParsePatResult = parse_pat(q);
          q = pr.p;
          args.push(pr.pat);
          if kind_is(peek_kind(q), lex.TokenKind.Comma) {
            let ar4: AdvanceResult = advance(q);
            q = ar4.p;
            if kind_is(peek_kind(q), lex.TokenKind.RParen) {
              break;
            }
            continue;
          }
          break;
        }
      }
      let ar5: AdvanceResult = expect(q, lex.TokenKind.RParen);
      q = ar5.p;
    }

    if parts.len() >= 2 {
      let n: i32 = parts.len();
      let variant: String = parts.get(n - 1);
      let mut enum_parts: Vec[String] = Vec();
      let mut i: i32 = 0;
      while i < n - 1 {
        enum_parts.push(parts.get(i));
        i = i + 1;
      }
      return ParsePatResult { p: q, pat: ast.Pat.EnumVariant(sp0, enum_parts, variant, args) };
    }

    if args.len() != 0 {
      // `x(...)` with no path doesn't exist in this subset.
      let mut qq: Parser = q;
      let at: i32 = peek(p).start;
      qq.has_err = true;
      qq.err = ParseError.UnexpectedToken(lex.TokenKind.FatArrow, lex.TokenKind.LParen, at);
      return ParsePatResult { p: qq, pat: ast.Pat.Wild(sp0) };
    }
    return ParsePatResult { p: q, pat: ast.Pat.Bind(sp0, parts.get(0)) };
  }

  let mut q: Parser = p;
  let at: i32 = peek(p).start;
  q.has_err = true;
  q.err = ParseError.UnexpectedToken(lex.TokenKind.Ident, k, at);
  return ParsePatResult { p: q, pat: ast.Pat.Wild(sp0) };
}

fn parse_prefix(p: Parser) -> ParseExprResult {
  let k: lex.TokenKind = peek_kind(p);
  if kind_is(k, lex.TokenKind.Dollar) {
    // `$x` is surface sugar lowered to `unquote!(x)`.
    let ar0: AdvanceResult = advance(p);
    let sp0: ast.Span = span_tok(p, ar0.tok);
    let er: ParseExprResult = parse_expr(ar0.p, 11);
    if er.p.has_err { return er; }
    let idu: ParseExprResult = add_expr(er.p, sp0, ast.ExprNode.Ident("unquote"));
    if idu.p.has_err { return idu; }
    let mut args: Vec[i32] = Vec();
    args.push(er.id);
    return add_expr(idu.p, sp0, ast.ExprNode.MacroCall(idu.id, Vec(), args));
  }
  if kind_is(k, lex.TokenKind.Plus) {
    let ar: AdvanceResult = advance(p);
    let r: ParseExprResult = parse_expr(ar.p, 11);
    if r.p.has_err { return r; }
    return add_expr(r.p, span_tok(p, ar.tok), ast.ExprNode.Unary(ast.UnaryOp.Pos, r.id));
  }
  if kind_is(k, lex.TokenKind.Minus) {
    let ar: AdvanceResult = advance(p);
    let r: ParseExprResult = parse_expr(ar.p, 11);
    if r.p.has_err { return r; }
    return add_expr(r.p, span_tok(p, ar.tok), ast.ExprNode.Unary(ast.UnaryOp.Neg, r.id));
  }
  if kind_is(k, lex.TokenKind.Not) {
    let ar: AdvanceResult = advance(p);
    let r: ParseExprResult = parse_expr(ar.p, 11);
    if r.p.has_err { return r; }
    return add_expr(r.p, span_tok(p, ar.tok), ast.ExprNode.Unary(ast.UnaryOp.Not, r.id));
  }
  if kind_is(k, lex.TokenKind.LParen) {
    let ar1: AdvanceResult = advance(p);
    let r2: ParseExprResult = parse_expr(ar1.p, 0);
    let ar3: AdvanceResult = expect(r2.p, lex.TokenKind.RParen);
    // Allow postfix ops on parenthesized expressions: `(expr).method(...)`.
    return parse_postfix(ar3.p, r2.id);
  }
  let r0: ParseExprResult = parse_primary(p);
  return parse_postfix(r0.p, r0.id);
}

fn infix_prec(k: lex.TokenKind) -> i32 {
  return match k {
    lex.TokenKind.OrOr => 1,
    lex.TokenKind.AndAnd => 2,
    lex.TokenKind.Pipe => 3,
    lex.TokenKind.Caret => 4,
    lex.TokenKind.Amp => 5,
    lex.TokenKind.EqEq => 6,
    lex.TokenKind.Ne => 6,
    lex.TokenKind.Lt => 7,
    lex.TokenKind.Le => 7,
    lex.TokenKind.Gt => 7,
    lex.TokenKind.Ge => 7,
    lex.TokenKind.LtLt => 8,
    lex.TokenKind.GtGt => 8,
    lex.TokenKind.Plus => 9,
    lex.TokenKind.Minus => 9,
    lex.TokenKind.Star => 10,
    lex.TokenKind.Slash => 10,
    lex.TokenKind.Percent => 10,
    _ => 0,
  };
}

fn infix_op(k: lex.TokenKind) -> ast.BinaryOp {
  return match k {
    lex.TokenKind.Plus => ast.BinaryOp.Add,
    lex.TokenKind.Minus => ast.BinaryOp.Sub,
    lex.TokenKind.Star => ast.BinaryOp.Mul,
    lex.TokenKind.Slash => ast.BinaryOp.Div,
    lex.TokenKind.Percent => ast.BinaryOp.Mod,
    lex.TokenKind.Amp => ast.BinaryOp.BitAnd,
    lex.TokenKind.Pipe => ast.BinaryOp.BitOr,
    lex.TokenKind.Caret => ast.BinaryOp.BitXor,
    lex.TokenKind.LtLt => ast.BinaryOp.Shl,
    lex.TokenKind.GtGt => ast.BinaryOp.Shr,
    lex.TokenKind.EqEq => ast.BinaryOp.Eq,
    lex.TokenKind.Ne => ast.BinaryOp.Ne,
    lex.TokenKind.Lt => ast.BinaryOp.Lt,
    lex.TokenKind.Le => ast.BinaryOp.Le,
    lex.TokenKind.Gt => ast.BinaryOp.Gt,
    lex.TokenKind.Ge => ast.BinaryOp.Ge,
    lex.TokenKind.AndAnd => ast.BinaryOp.AndAnd,
    lex.TokenKind.OrOr => ast.BinaryOp.OrOr,
    _ => ast.BinaryOp.Add,
  };
}

fn parse_expr(p: Parser, min_prec: i32) -> ParseExprResult {
  let r0: ParseExprResult = parse_prefix(p);
  let mut q: Parser = r0.p;
  let mut left: i32 = r0.id;
  while !q.has_err {
    let k: lex.TokenKind = peek_kind(q);
    let prec: i32 = infix_prec(k);
    if prec < min_prec || prec == 0 {
      break;
    }
    let ar1: AdvanceResult = advance(q);
    let op: ast.BinaryOp = infix_op(k);
    let r2: ParseExprResult = parse_expr(ar1.p, prec + 1);
    let sp0: ast.Span = span_expr(r2.p.exprs, left);
    let r3: ParseExprResult = add_expr(r2.p, sp0, ast.ExprNode.Binary(op, left, r2.id));
    q = r3.p;
    left = r3.id;
  }
  return ParseExprResult { p: q, id: left };
}

fn parse_stmt(p: Parser) -> ParseStmtResult {
  let sp0: ast.Span = span_at(p, peek(p).start);
  let k: lex.TokenKind = peek_kind(p);
  if kind_is(k, lex.TokenKind.KwLet) {
    let ar1: AdvanceResult = advance(p);
    let mut q: Parser = ar1.p;

    // optional `mut`
    let mut is_mut: bool = false;
    if kind_is(peek_kind(q), lex.TokenKind.KwMut) {
      let ar2: AdvanceResult = advance(q);
      q = ar2.p;
      is_mut = true;
    }

    let r3: ParseIdentResult = parse_ident(q);
    q = r3.p;
    let name: String = r3.name;

    // optional type annotation: : Type
    let mut has_ann: bool = false;
    let mut ann: ast.TypeName = ast.TypeName { parts: Vec(), args: Vec() };
    if kind_is(peek_kind(q), lex.TokenKind.Colon) {
      let ar4: AdvanceResult = advance(q);
      let r5: ParseTypeResult = parse_type_name(ar4.p);
      q = r5.p;
      has_ann = true;
      ann = r5.ty;
    }

    let ar6: AdvanceResult = expect(q, lex.TokenKind.Eq);
    let r7: ParseExprResult = parse_expr(ar6.p, 0);
    let ar8: AdvanceResult = expect(r7.p, lex.TokenKind.Semicolon);
    return ParseStmtResult { p: ar8.p, st: ast.Stmt.Let(sp0, is_mut, name, has_ann, ann, r7.id) };
  }
  if kind_is(k, lex.TokenKind.KwIf) {
    let ar1: AdvanceResult = advance(p);
    let r2: ParseExprResult = parse_expr(ar1.p, 0);
    let r3: ParseBlockResult = parse_block(r2.p);
    let mut q: Parser = r3.p;
    let mut has_else: bool = false;
    let mut else_b: ast.Block = ast.Block { stmts: Vec() };
    if kind_is(peek_kind(q), lex.TokenKind.KwElse) {
      let ar4: AdvanceResult = advance(q);
      has_else = true;
      if kind_is(peek_kind(ar4.p), lex.TokenKind.KwIf) {
        // else if ... ; lower into else { if ... }
        let r5: ParseStmtResult = parse_stmt(ar4.p);
        let mut ss: Vec[ast.Stmt] = Vec();
        ss.push(r5.st);
        q = r5.p;
        else_b = ast.Block { stmts: ss };
      } else {
        let r5: ParseBlockResult = parse_block(ar4.p);
        q = r5.p;
        else_b = r5.b;
      }
    }
    return ParseStmtResult { p: q, st: ast.Stmt.IfStmt(sp0, r2.id, r3.b, has_else, else_b) };
  }
  if kind_is(k, lex.TokenKind.KwWhile) {
    let ar1: AdvanceResult = advance(p);
    let r2: ParseExprResult = parse_expr(ar1.p, 0);
    let r3: ParseBlockResult = parse_block(r2.p);
    return ParseStmtResult { p: r3.p, st: ast.Stmt.WhileStmt(sp0, r2.id, r3.b) };
  }
  if kind_is(k, lex.TokenKind.KwBreak) {
    let ar1: AdvanceResult = advance(p);
    let ar2: AdvanceResult = expect(ar1.p, lex.TokenKind.Semicolon);
    return ParseStmtResult { p: ar2.p, st: ast.Stmt.Break(sp0) };
  }
  if kind_is(k, lex.TokenKind.KwContinue) {
    let ar1: AdvanceResult = advance(p);
    let ar2: AdvanceResult = expect(ar1.p, lex.TokenKind.Semicolon);
    return ParseStmtResult { p: ar2.p, st: ast.Stmt.Continue(sp0) };
  }
  if kind_is(k, lex.TokenKind.KwReturn) {
    let ar1: AdvanceResult = advance(p);
    if kind_is(peek_kind(ar1.p), lex.TokenKind.Semicolon) {
      let ar2: AdvanceResult = expect(ar1.p, lex.TokenKind.Semicolon);
      return ParseStmtResult { p: ar2.p, st: ast.Stmt.ReturnStmt(sp0, false, -1) };
    }
    let r2: ParseExprResult = parse_expr(ar1.p, 0);
    let ar3: AdvanceResult = expect(r2.p, lex.TokenKind.Semicolon);
    return ParseStmtResult { p: ar3.p, st: ast.Stmt.ReturnStmt(sp0, true, r2.id) };
  }

  // field assignment: ident(.ident)+ <assign-op> expr ;
  if is_field_assign_start(p) {
    let r1: ParseIdentResult = parse_ident(p);
    let mut ql: Parser = r1.p;
    let mut fields: Vec[String] = Vec();
    while kind_is(peek_kind(ql), lex.TokenKind.Dot) && kind_is(peek2_kind(ql), lex.TokenKind.Ident) {
      let ard: AdvanceResult = expect(ql, lex.TokenKind.Dot);
      let rf: ParseIdentResult = parse_ident(ard.p);
      ql = rf.p;
      fields.push(rf.name);
    }

    let op_tok: lex.Token = peek(ql);
    let ar4: AdvanceResult = advance(ql);
    let r5: ParseExprResult = parse_expr(ar4.p, 0);
    let mut q: Parser = r5.p;
    let mut rhs_id: i32 = r5.id;
    if !kind_is(op_tok.kind, lex.TokenKind.Eq) {
      let lhs_add0: ast.AddExprResult = ast.expr_pool_add(
        q.exprs,
        ast.ExprNode.Ident(r1.name),
        span_at(q, op_tok.start)
      );
      let mut lhs_id: i32 = lhs_add0.id;
      let mut q2: Parser = q;
      q2.exprs = lhs_add0.pool;
      let mut fi: i32 = 0;
      while fi < fields.len() {
        let lhs_next: ast.AddExprResult = ast.expr_pool_add(
          q2.exprs,
          ast.ExprNode.Member(lhs_id, fields.get(fi)),
          span_at(q2, op_tok.start)
        );
        lhs_id = lhs_next.id;
        q2.exprs = lhs_next.pool;
        fi = fi + 1;
      }
      let bop: ast.BinaryOp = assign_op_to_binary(op_tok.kind);
      let addb: ast.AddExprResult = ast.expr_pool_add(
        q2.exprs,
        ast.ExprNode.Binary(bop, lhs_id, rhs_id),
        span_at(q2, op_tok.start)
      );
      q = q2;
      q.exprs = addb.pool;
      rhs_id = addb.id;
    }
    let ar6: AdvanceResult = expect(q, lex.TokenKind.Semicolon);
    return ParseStmtResult { p: ar6.p, st: ast.Stmt.AssignField(sp0, r1.name, join_field_path(fields), rhs_id) };
  }

  // assignment: ident <assign-op> expr ;
  if kind_is(k, lex.TokenKind.Ident) && is_assign_op(peek2_kind(p)) {
    let r1: ParseIdentResult = parse_ident(p);
    let op_tok: lex.Token = peek(r1.p);
    let ar2: AdvanceResult = advance(r1.p);
    let r3: ParseExprResult = parse_expr(ar2.p, 0);
    let mut q: Parser = r3.p;
    let mut rhs_id: i32 = r3.id;
    if !kind_is(op_tok.kind, lex.TokenKind.Eq) {
      let lhs_add: ast.AddExprResult = ast.expr_pool_add(
        q.exprs,
        ast.ExprNode.Ident(r1.name),
        span_at(q, op_tok.start)
      );
      let bop: ast.BinaryOp = assign_op_to_binary(op_tok.kind);
      let bin_add: ast.AddExprResult = ast.expr_pool_add(
        lhs_add.pool,
        ast.ExprNode.Binary(bop, lhs_add.id, rhs_id),
        span_at(q, op_tok.start)
      );
      q.exprs = bin_add.pool;
      rhs_id = bin_add.id;
    }
    let ar4: AdvanceResult = expect(q, lex.TokenKind.Semicolon);
    return ParseStmtResult { p: ar4.p, st: ast.Stmt.Assign(sp0, r1.name, rhs_id) };
  }

  // expr stmt
  let r1: ParseExprResult = parse_expr(p, 0);
  let ar2: AdvanceResult = expect(r1.p, lex.TokenKind.Semicolon);
  if !ar2.p.has_err {
    return ParseStmtResult { p: ar2.p, st: ast.Stmt.ExprStmt(span_expr(ar2.p.exprs, r1.id), r1.id) };
  }

  let mut q: Parser = p;
  let at: i32 = peek(p).start;
  q.has_err = true;
  q.err = ParseError.UnexpectedToken(lex.TokenKind.KwReturn, k, at);
  return ParseStmtResult { p: q, st: ast.Stmt.ReturnStmt(sp0, false, -1) };
}

fn parse_block(p: Parser) -> ParseBlockResult {
  let ar1: AdvanceResult = expect(p, lex.TokenKind.LBrace);
  let mut q: Parser = ar1.p;
  let mut stmts: Vec[ast.Stmt] = Vec();
  while !q.has_err && !kind_is(peek_kind(q), lex.TokenKind.RBrace) && !kind_is(peek_kind(q), lex.TokenKind.Eof) {
    let r: ParseStmtResult = parse_stmt(q);
    q = r.p;
    stmts.push(r.st);
  }
  let ar2: AdvanceResult = expect(q, lex.TokenKind.RBrace);
  return ParseBlockResult { p: ar2.p, b: ast.Block { stmts: stmts } };
}

fn parse_fn_decl(p: Parser, vis: i32, is_pub: bool) -> ParseFnResult {
  let ar1: AdvanceResult = expect(p, lex.TokenKind.KwFn);
  let r2: ParseIdentResult = parse_ident(ar1.p);
  let mut q: Parser = r2.p;
  let mut tps: Vec[String] = Vec();
  let mut tpps: Vec[String] = Vec();
  let mut cps: Vec[ast.ConstParamDecl] = Vec();
  let mut tpbs: Vec[ast.TypeParamBoundsDecl] = Vec();
  let mut cwbs: Vec[ast.ConstWhereDecl] = Vec();
  if kind_is(peek_kind(q), lex.TokenKind.LBracket) {
    let r3: ParseFnTypeParamsResult = parse_fn_type_params(q);
    q = r3.p;
    tps = r3.tps;
    tpps = r3.tpps;
    cps = r3.cps;
    tpbs = r3.tpbs;
  }
  let _ar4: AdvanceResult = expect(q, lex.TokenKind.LParen);
  let r5: ParseParamsResult = parse_params(_ar4.p);
  let _ar6: AdvanceResult = expect(r5.p, lex.TokenKind.RParen);
  let _ar7: AdvanceResult = expect(_ar6.p, lex.TokenKind.Arrow);
  let r8: ParseTypeResult = parse_type_name(_ar7.p);
  let mut q2: Parser = r8.p;
  let mut tpbs2: Vec[ast.TypeParamBoundsDecl] = tpbs;
  let mut cwbs2: Vec[ast.ConstWhereDecl] = cwbs;
  if kind_is(peek_kind(q2), lex.TokenKind.KwWhere) {
    let wr: ParseWhereBoundsResult = parse_where_bounds(q2);
    q2 = wr.p;
    let mut wi: i32 = 0;
    while wi < wr.tpbs.len() {
      tpbs2.push(wr.tpbs.get(wi));
      wi = wi + 1;
    }
    wi = 0;
    while wi < wr.cwbs.len() {
      cwbs2.push(wr.cwbs.get(wi));
      wi = wi + 1;
    }
  }
  let params: Vec[ast.Param] = r5.params;
  let r9: ParseBlockResult = parse_block(q2);
  return ParseFnResult {
    p: r9.p,
    f: ast.FuncDecl {
      file: p.file,
      sp: span_tok(p, ar1.tok),
      vis: vis,
      is_pub: is_pub,
      name: r2.name,
      type_params: tps,
      type_param_packs: tpps,
      const_params: cps,
      type_param_bounds: tpbs2,
      const_where_bounds: cwbs2,
      params: params,
      ret: r8.ty,
      body: r9.b,
    },
  };
}

fn parse_fn_type_params(p: Parser) -> ParseFnTypeParamsResult {
  let ar1: AdvanceResult = expect(p, lex.TokenKind.LBracket);
  let mut q: Parser = ar1.p;
  let mut tps: Vec[String] = Vec();
  let mut tpps: Vec[String] = Vec();
  let mut cps: Vec[ast.ConstParamDecl] = Vec();
  let mut tpbs: Vec[ast.TypeParamBoundsDecl] = Vec();
  let mut seen_const: bool = false;
  let mut seen_const_default: bool = false;
  if kind_is(peek_kind(q), lex.TokenKind.RBracket) {
    let ar2: AdvanceResult = expect(q, lex.TokenKind.RBracket);
    return ParseFnTypeParamsResult { p: ar2.p, tps: tps, tpps: tpps, cps: cps, tpbs: tpbs };
  }
  while !q.has_err {
    if kind_is(peek_kind(q), lex.TokenKind.KwConst) {
      seen_const = true;
      let ar2: AdvanceResult = advance(q);
      let r1: ParseIdentResult = parse_ident(ar2.p);
      let ar3: AdvanceResult = expect(r1.p, lex.TokenKind.Colon);
      let tr: ParseTypeResult = parse_type_name(ar3.p);
      q = tr.p;
      let mut has_default: bool = false;
      let mut default_text: String = "";
      if kind_is(peek_kind(q), lex.TokenKind.Eq) {
        let ar4: AdvanceResult = advance(q);
        let dr: ParseConstDefaultResult = parse_const_default_text(ar4.p);
        if !dr.ok {
          let mut qerr: Parser = dr.p;
          qerr.has_err = true;
          qerr.err = ParseError.UnexpectedToken(lex.TokenKind.Int, peek_kind(dr.p), peek(dr.p).start);
          return ParseFnTypeParamsResult { p: qerr, tps: tps, tpps: tpps, cps: cps, tpbs: tpbs };
        }
        q = dr.p;
        has_default = true;
        default_text = dr.text;
        seen_const_default = true;
      } else if seen_const_default {
        let mut qerr2: Parser = q;
        qerr2.has_err = true;
        qerr2.err = ParseError.UnexpectedToken(lex.TokenKind.Eq, peek_kind(q), peek(q).start);
        return ParseFnTypeParamsResult { p: qerr2, tps: tps, tpps: tpps, cps: cps, tpbs: tpbs };
      }
      cps.push(ast.ConstParamDecl { name: r1.name, ty: tr.ty, has_default: has_default, default_text: default_text });
    } else {
      if seen_const {
        let mut qerr: Parser = q;
        qerr.has_err = true;
        qerr.err = ParseError.UnexpectedToken(lex.TokenKind.KwConst, peek_kind(q), peek(q).start);
        return ParseFnTypeParamsResult { p: qerr, tps: tps, tpps: tpps, cps: cps, tpbs: tpbs };
      }
      let r1: ParseIdentResult = parse_ident(q);
      q = r1.p;
      if kind_is(peek_kind(q), lex.TokenKind.DotDotDot) {
        let arp: AdvanceResult = advance(q);
        q = arp.p;
        tpps.push(r1.name);
      }
      tps.push(r1.name);

      let mut bounds: Vec[ast.TypeName] = Vec();
      if kind_is(peek_kind(q), lex.TokenKind.Colon) {
        let ar4: AdvanceResult = advance(q);
        q = ar4.p;
        while !q.has_err {
          let tr2: ParseTypeResult = parse_type_name(q);
          q = tr2.p;
          bounds.push(tr2.ty);
          if kind_is(peek_kind(q), lex.TokenKind.Plus) {
            let ar5: AdvanceResult = advance(q);
            q = ar5.p;
            continue;
          }
          break;
        }
      }
      if bounds.len() != 0 {
        tpbs.push(ast.TypeParamBoundsDecl { name: r1.name, bounds: bounds });
      }
    }

    if kind_is(peek_kind(q), lex.TokenKind.Comma) {
      let ar6: AdvanceResult = advance(q);
      q = ar6.p;
      if kind_is(peek_kind(q), lex.TokenKind.RBracket) {
        break;
      }
      continue;
    }
    break;
  }
  let ar7: AdvanceResult = expect(q, lex.TokenKind.RBracket);
  return ParseFnTypeParamsResult { p: ar7.p, tps: tps, tpps: tpps, cps: cps, tpbs: tpbs };
}

fn parse_type_params(p: Parser) -> ParseTypeParamsResult {
  let ar1: AdvanceResult = expect(p, lex.TokenKind.LBracket);
  let mut q: Parser = ar1.p;
  let mut tps: Vec[String] = Vec();
  let mut tpbs: Vec[ast.TypeParamBoundsDecl] = Vec();
  if kind_is(peek_kind(q), lex.TokenKind.RBracket) {
    let ar2: AdvanceResult = expect(q, lex.TokenKind.RBracket);
    return ParseTypeParamsResult { p: ar2.p, tps: tps, tpbs: tpbs };
  }
  while !q.has_err {
    let r1: ParseIdentResult = parse_ident(q);
    q = r1.p;
    tps.push(r1.name);

    let mut bounds: Vec[ast.TypeName] = Vec();
    if kind_is(peek_kind(q), lex.TokenKind.Colon) {
      let ar2: AdvanceResult = advance(q);
      q = ar2.p;
      while !q.has_err {
        let tr: ParseTypeResult = parse_type_name(q);
        q = tr.p;
        bounds.push(tr.ty);
        if kind_is(peek_kind(q), lex.TokenKind.Plus) {
          let ar3: AdvanceResult = advance(q);
          q = ar3.p;
          continue;
        }
        break;
      }
    }
    if bounds.len() != 0 {
      tpbs.push(ast.TypeParamBoundsDecl { name: r1.name, bounds: bounds });
    }

    if kind_is(peek_kind(q), lex.TokenKind.Comma) {
      let ar4: AdvanceResult = advance(q);
      q = ar4.p;
      if kind_is(peek_kind(q), lex.TokenKind.RBracket) {
        break;
      }
      continue;
    }
    break;
  }
  let ar5: AdvanceResult = expect(q, lex.TokenKind.RBracket);
  return ParseTypeParamsResult { p: ar5.p, tps: tps, tpbs: tpbs };
}

fn parse_where_bounds(p: Parser) -> ParseWhereBoundsResult {
  let ar1: AdvanceResult = expect(p, lex.TokenKind.KwWhere);
  let mut q: Parser = ar1.p;
  let mut out: Vec[ast.TypeParamBoundsDecl] = Vec();
  let mut cwbs: Vec[ast.ConstWhereDecl] = Vec();
  while !q.has_err {
    if kind_is(peek_kind(q), lex.TokenKind.KwComptime) {
      let ar0: AdvanceResult = advance(q);
      let mut qlhs: Parser = ar0.p;
      let mut lhs_kind: i32 = ast.comptime_where_lhs_const_param();
      let mut lhs_name: String = "";
      if kind_is(peek_kind(qlhs), lex.TokenKind.At) {
        let ar_at: AdvanceResult = advance(qlhs);
        qlhs = ar_at.p;
        let rname: ParseIdentResult = parse_ident(qlhs);
        qlhs = rname.p;
        if rname.name == "size_of" {
          lhs_kind = ast.comptime_where_lhs_size_of();
        } else if rname.name == "align_of" {
          lhs_kind = ast.comptime_where_lhs_align_of();
        } else if rname.name == "field_count" {
          lhs_kind = ast.comptime_where_lhs_field_count();
        } else {
          let mut qerr_name: Parser = qlhs;
          qerr_name.has_err = true;
          qerr_name.err = ParseError.UnexpectedToken(lex.TokenKind.Ident, lex.TokenKind.Ident, rname.at);
          return ParseWhereBoundsResult { p: qerr_name, tpbs: out, cwbs: cwbs };
        }
        let ar_l: AdvanceResult = expect(qlhs, lex.TokenKind.LParen);
        let rtp: ParseIdentResult = parse_ident(ar_l.p);
        let ar_r: AdvanceResult = expect(rtp.p, lex.TokenKind.RParen);
        qlhs = ar_r.p;
        lhs_name = rtp.name;
      } else {
        let r1: ParseIdentResult = parse_ident(qlhs);
        qlhs = r1.p;
        lhs_name = r1.name;
      }
      let opk: lex.TokenKind = peek_kind(qlhs);
      let is_cmp: bool =
        kind_is(opk, lex.TokenKind.EqEq) ||
        kind_is(opk, lex.TokenKind.Ne) ||
        kind_is(opk, lex.TokenKind.Lt) ||
        kind_is(opk, lex.TokenKind.Le) ||
        kind_is(opk, lex.TokenKind.Gt) ||
        kind_is(opk, lex.TokenKind.Ge);
      if !is_cmp {
        let mut qerr0: Parser = qlhs;
        qerr0.has_err = true;
        qerr0.err = ParseError.UnexpectedToken(lex.TokenKind.Lt, opk, peek(qlhs).start);
        return ParseWhereBoundsResult { p: qerr0, tpbs: out, cwbs: cwbs };
      }
      let op: ast.BinaryOp =
        if kind_is(opk, lex.TokenKind.EqEq) { ast.BinaryOp.Eq } else
        if kind_is(opk, lex.TokenKind.Ne) { ast.BinaryOp.Ne } else
        if kind_is(opk, lex.TokenKind.Lt) { ast.BinaryOp.Lt } else
        if kind_is(opk, lex.TokenKind.Le) { ast.BinaryOp.Le } else
        if kind_is(opk, lex.TokenKind.Gt) { ast.BinaryOp.Gt } else { ast.BinaryOp.Ge };
      let ar2: AdvanceResult = advance(qlhs);
      let mut qrhs: Parser = ar2.p;
      if kind_is(peek_kind(qrhs), lex.TokenKind.Ident) {
        let rr: ParseIdentResult = parse_ident(qrhs);
        qrhs = rr.p;
        cwbs.push(ast.ConstWhereDecl {
          lhs_kind: lhs_kind,
          name: lhs_name,
          op: op,
          rhs_is_param: true,
          rhs_param: rr.name,
          rhs_text: rr.name,
        });
      } else {
        let dr: ParseConstDefaultResult = parse_const_default_text(qrhs);
        if !dr.ok {
          let mut qerr1: Parser = dr.p;
          qerr1.has_err = true;
          qerr1.err = ParseError.UnexpectedToken(lex.TokenKind.Int, peek_kind(dr.p), peek(dr.p).start);
          return ParseWhereBoundsResult { p: qerr1, tpbs: out, cwbs: cwbs };
        }
        qrhs = dr.p;
        cwbs.push(ast.ConstWhereDecl {
          lhs_kind: lhs_kind,
          name: lhs_name,
          op: op,
          rhs_is_param: false,
          rhs_param: "",
          rhs_text: dr.text,
        });
      }
      q = qrhs;
    } else {
      let r1: ParseIdentResult = parse_ident(q);
      q = r1.p;
      let ar2: AdvanceResult = expect(q, lex.TokenKind.Colon);
      q = ar2.p;

      let mut bounds: Vec[ast.TypeName] = Vec();
      while !q.has_err {
        let tr: ParseTypeResult = parse_type_name(q);
        q = tr.p;
        bounds.push(tr.ty);
        if kind_is(peek_kind(q), lex.TokenKind.Plus) {
          let ar3: AdvanceResult = advance(q);
          q = ar3.p;
          continue;
        }
        break;
      }
      out.push(ast.TypeParamBoundsDecl { name: r1.name, bounds: bounds });
    }

    if kind_is(peek_kind(q), lex.TokenKind.Comma) {
      let ar4: AdvanceResult = advance(q);
      q = ar4.p;
      // allow trailing comma before block/semicolon
      if kind_is(peek_kind(q), lex.TokenKind.LBrace) || kind_is(peek_kind(q), lex.TokenKind.Semicolon) { break; }
      continue;
    }
    break;
  }
  return ParseWhereBoundsResult { p: q, tpbs: out, cwbs: cwbs };
}

fn parse_field_decl(p: Parser) -> ParseFieldResult {
	  let mut q: Parser = p;
	  let mut is_pub: bool = false;
  let mut vis: i32 = ast.vis_private();
	  let pr: ParsePubResult = parse_pub_marker(q);
	  q = pr.p;
	  is_pub = pr.is_pub;
  vis = pr.vis;
	  let r2: ParseIdentResult = parse_ident(q);
	  let ar3: AdvanceResult = expect(r2.p, lex.TokenKind.Colon);
	  let r4: ParseTypeResult = parse_type_name(ar3.p);
	  return ParseFieldResult { p: r4.p, f: ast.FieldDecl { vis: vis, is_pub: is_pub, name: r2.name, ty: r4.ty } };
}

fn parse_struct_decl(p: Parser, vis: i32, is_pub: bool) -> ParseStructResult {
	  let ar1: AdvanceResult = expect(p, lex.TokenKind.KwStruct);
	  let r2: ParseIdentResult = parse_ident(ar1.p);
	  let mut q0: Parser = r2.p;
	  let mut tps: Vec[String] = Vec();
	  let mut tpbs: Vec[ast.TypeParamBoundsDecl] = Vec();
	  let mut cwbs: Vec[ast.ConstWhereDecl] = Vec();
	  if kind_is(peek_kind(q0), lex.TokenKind.LBracket) {
	    let rtp: ParseTypeParamsResult = parse_type_params(q0);
	    q0 = rtp.p;
	    tps = rtp.tps;
	    tpbs = rtp.tpbs;
	  }
	  if kind_is(peek_kind(q0), lex.TokenKind.KwWhere) {
	    let wr: ParseWhereBoundsResult = parse_where_bounds(q0);
	    q0 = wr.p;
	    let mut wi: i32 = 0;
	    while wi < wr.tpbs.len() {
	      tpbs.push(wr.tpbs.get(wi));
	      wi = wi + 1;
	    }
	    wi = 0;
	    while wi < wr.cwbs.len() {
	      cwbs.push(wr.cwbs.get(wi));
	      wi = wi + 1;
	    }
	  }
	  let ar3: AdvanceResult = expect(q0, lex.TokenKind.LBrace);
	  let mut q: Parser = ar3.p;
	  let mut fields: Vec[ast.FieldDecl] = Vec();
	  if !kind_is(peek_kind(q), lex.TokenKind.RBrace) {
	    while !q.has_err {
	      let r: ParseFieldResult = parse_field_decl(q);
	      q = r.p;
	      fields.push(r.f);
	      if kind_is(peek_kind(q), lex.TokenKind.Comma) {
	        let ar4: AdvanceResult = advance(q);
	        q = ar4.p;
	        if kind_is(peek_kind(q), lex.TokenKind.RBrace) {
	          break;
	        }
	        continue;
	      }
	      break;
	    }
	  }
	  let ar5: AdvanceResult = expect(q, lex.TokenKind.RBrace);
	  return ParseStructResult {
	    p: ar5.p,
	    s: ast.StructDecl {
	      file: p.file,
        sp: span_tok(p, ar1.tok),
	      vis: vis,
	      is_pub: is_pub,
	      name: r2.name,
	      type_params: tps,
	      type_param_bounds: tpbs,
	      const_where_bounds: cwbs,
	      fields: fields,
	    },
	  };
}

fn parse_enum_variant_decl(p: Parser) -> ParseVariantResult {
	  let r1: ParseIdentResult = parse_ident(p);
	  let mut q: Parser = r1.p;
	  let mut fields: Vec[ast.TypeName] = Vec();
	  if kind_is(peek_kind(q), lex.TokenKind.LParen) {
	    let ar2: AdvanceResult = advance(q);
	    q = ar2.p;
	    if !kind_is(peek_kind(q), lex.TokenKind.RParen) {
	      while !q.has_err {
	        let tr: ParseTypeResult = parse_type_name(q);
	        q = tr.p;
	        fields.push(tr.ty);
	        if kind_is(peek_kind(q), lex.TokenKind.Comma) {
	          let ar3: AdvanceResult = advance(q);
	          q = ar3.p;
	          if kind_is(peek_kind(q), lex.TokenKind.RParen) {
	            break;
	          }
	          continue;
	        }
	        break;
	      }
	    }
	    let ar4: AdvanceResult = expect(q, lex.TokenKind.RParen);
	    q = ar4.p;
	  }
	  return ParseVariantResult { p: q, v: ast.EnumVariantDecl { name: r1.name, fields: fields } };
}

fn parse_enum_decl(p: Parser, vis: i32, is_pub: bool) -> ParseEnumResult {
	  let ar1: AdvanceResult = expect(p, lex.TokenKind.KwEnum);
	  let r2: ParseIdentResult = parse_ident(ar1.p);
	  let mut q0: Parser = r2.p;
	  let mut tps: Vec[String] = Vec();
	  let mut tpbs: Vec[ast.TypeParamBoundsDecl] = Vec();
	  let mut cwbs: Vec[ast.ConstWhereDecl] = Vec();
	  if kind_is(peek_kind(q0), lex.TokenKind.LBracket) {
	    let rtp: ParseTypeParamsResult = parse_type_params(q0);
	    q0 = rtp.p;
	    tps = rtp.tps;
	    tpbs = rtp.tpbs;
	  }
	  if kind_is(peek_kind(q0), lex.TokenKind.KwWhere) {
	    let wr: ParseWhereBoundsResult = parse_where_bounds(q0);
	    q0 = wr.p;
	    let mut wi: i32 = 0;
	    while wi < wr.tpbs.len() {
	      tpbs.push(wr.tpbs.get(wi));
	      wi = wi + 1;
	    }
	    wi = 0;
	    while wi < wr.cwbs.len() {
	      cwbs.push(wr.cwbs.get(wi));
	      wi = wi + 1;
	    }
	  }
	  let ar3: AdvanceResult = expect(q0, lex.TokenKind.LBrace);
	  let mut q: Parser = ar3.p;
	  let mut vars: Vec[ast.EnumVariantDecl] = Vec();
	  if !kind_is(peek_kind(q), lex.TokenKind.RBrace) {
	    while !q.has_err {
	      let vr: ParseVariantResult = parse_enum_variant_decl(q);
	      q = vr.p;
	      vars.push(vr.v);
	      if kind_is(peek_kind(q), lex.TokenKind.Comma) {
	        let ar4: AdvanceResult = advance(q);
	        q = ar4.p;
	        if kind_is(peek_kind(q), lex.TokenKind.RBrace) {
	          break;
	        }
	        continue;
	      }
	      break;
	    }
	  }
	  let ar5: AdvanceResult = expect(q, lex.TokenKind.RBrace);
	  return ParseEnumResult {
	    p: ar5.p,
	    e: ast.EnumDecl {
	      file: p.file,
        sp: span_tok(p, ar1.tok),
	      vis: vis,
	      is_pub: is_pub,
	      name: r2.name,
	      type_params: tps,
	      type_param_bounds: tpbs,
	      const_where_bounds: cwbs,
	      variants: vars,
	    },
	  };
}

fn parse_trait_method_decl(p: Parser) -> ParseTraitMethodResult {
  let ar1: AdvanceResult = expect(p, lex.TokenKind.KwFn);
  let r2: ParseIdentResult = parse_ident(ar1.p);
  let mut q0: Parser = r2.p;
  let mut tps: Vec[String] = Vec();
  let mut tpps: Vec[String] = Vec();
  let mut cps: Vec[ast.ConstParamDecl] = Vec();
  let mut tpbs: Vec[ast.TypeParamBoundsDecl] = Vec();
  let mut cwbs: Vec[ast.ConstWhereDecl] = Vec();
  if kind_is(peek_kind(q0), lex.TokenKind.LBracket) {
    let rtp: ParseFnTypeParamsResult = parse_fn_type_params(q0);
    q0 = rtp.p;
    tps = rtp.tps;
    tpps = rtp.tpps;
    cps = rtp.cps;
    tpbs = rtp.tpbs;
  }
  let ar3: AdvanceResult = expect(q0, lex.TokenKind.LParen);
  let r4: ParseParamsResult = parse_params(ar3.p);
  let ar5: AdvanceResult = expect(r4.p, lex.TokenKind.RParen);
  let ar6: AdvanceResult = expect(ar5.p, lex.TokenKind.Arrow);
  let r7: ParseTypeResult = parse_type_name(ar6.p);
  let mut q: Parser = r7.p;
  let mut tpbs2: Vec[ast.TypeParamBoundsDecl] = tpbs;
  let mut cwbs2: Vec[ast.ConstWhereDecl] = cwbs;
  if kind_is(peek_kind(q), lex.TokenKind.KwWhere) {
    let wr: ParseWhereBoundsResult = parse_where_bounds(q);
    q = wr.p;
    let mut wi: i32 = 0;
    while wi < wr.tpbs.len() {
      tpbs2.push(wr.tpbs.get(wi));
      wi = wi + 1;
    }
    wi = 0;
    while wi < wr.cwbs.len() {
      cwbs2.push(wr.cwbs.get(wi));
      wi = wi + 1;
    }
  }
  let mut has_body: bool = false;
  let mut body: ast.Block = ast.Block { stmts: Vec() };
  if kind_is(peek_kind(q), lex.TokenKind.LBrace) {
    let br: ParseBlockResult = parse_block(q);
    q = br.p;
    has_body = true;
    body = br.b;
  } else
  if kind_is(peek_kind(q), lex.TokenKind.Semicolon) {
    let ar8: AdvanceResult = advance(q);
    q = ar8.p;
  } else {
    let mut qq: Parser = q;
    let at: i32 = peek(q).start;
    qq.has_err = true;
    qq.err = ParseError.UnexpectedToken(lex.TokenKind.Semicolon, peek_kind(q), at);
    q = qq;
  }
  return ParseTraitMethodResult {
    p: q,
    m: ast.TraitMethodDecl {
      sp: span_tok(p, ar1.tok),
      name: r2.name,
      type_params: tps,
      type_param_packs: tpps,
      const_params: cps,
      type_param_bounds: tpbs2,
      const_where_bounds: cwbs2,
      params: r4.params,
      ret: r7.ty,
      has_body: has_body,
      body: body,
    },
  };
}

fn parse_trait_assoc_type_decl(p: Parser) -> ParseTraitAssocTypeResult {
  let ar1: AdvanceResult = expect(p, lex.TokenKind.KwType);
  let r2: ParseIdentResult = parse_ident(ar1.p);
  let mut q: Parser = r2.p;
  if kind_is(peek_kind(q), lex.TokenKind.Semicolon) {
    let ar3: AdvanceResult = advance(q);
    q = ar3.p;
  } else {
    let mut qq: Parser = q;
    let at: i32 = peek(q).start;
    qq.has_err = true;
    qq.err = ParseError.UnexpectedToken(lex.TokenKind.Semicolon, peek_kind(q), at);
    q = qq;
  }
  return ParseTraitAssocTypeResult { p: q, a: ast.TraitAssocTypeDecl { sp: span_tok(p, ar1.tok), name: r2.name } };
}

fn parse_impl_assoc_type_binding(p: Parser) -> ParseImplAssocTypeResult {
  let ar1: AdvanceResult = expect(p, lex.TokenKind.KwType);
  let r2: ParseIdentResult = parse_ident(ar1.p);
  let ar3: AdvanceResult = expect(r2.p, lex.TokenKind.Eq);
  let r4: ParseTypeResult = parse_type_name(ar3.p);
  let mut q: Parser = r4.p;
  if kind_is(peek_kind(q), lex.TokenKind.Semicolon) {
    let ar5: AdvanceResult = advance(q);
    q = ar5.p;
  } else {
    let mut qq: Parser = q;
    let at: i32 = peek(q).start;
    qq.has_err = true;
    qq.err = ParseError.UnexpectedToken(lex.TokenKind.Semicolon, peek_kind(q), at);
    q = qq;
  }
  return ParseImplAssocTypeResult { p: q, a: ast.ImplAssocTypeBinding { sp: span_tok(p, ar1.tok), name: r2.name, ty: r4.ty } };
}

fn parse_trait_decl(p: Parser, vis: i32, is_pub: bool) -> ParseTraitResult {
  let ar1: AdvanceResult = expect(p, lex.TokenKind.KwTrait);
  let r2: ParseIdentResult = parse_ident(ar1.p);
  let mut q0: Parser = r2.p;
  let mut supers: Vec[ast.TypeName] = Vec();
  if kind_is(peek_kind(q0), lex.TokenKind.Colon) {
    let arx: AdvanceResult = advance(q0);
    q0 = arx.p;
    while !q0.has_err {
      let tr: ParseTypeResult = parse_type_name(q0);
      q0 = tr.p;
      supers.push(tr.ty);
      if kind_is(peek_kind(q0), lex.TokenKind.Plus) {
        let ary: AdvanceResult = advance(q0);
        q0 = ary.p;
        continue;
      }
      break;
    }
  }
  let ar3: AdvanceResult = expect(q0, lex.TokenKind.LBrace);
  let mut q: Parser = ar3.p;
  let mut assocs: Vec[ast.TraitAssocTypeDecl] = Vec();
  let mut ms: Vec[ast.TraitMethodDecl] = Vec();
  if !kind_is(peek_kind(q), lex.TokenKind.RBrace) {
    while !q.has_err {
      if kind_is(peek_kind(q), lex.TokenKind.KwType) {
        let ar: ParseTraitAssocTypeResult = parse_trait_assoc_type_decl(q);
        q = ar.p;
        assocs.push(ar.a);
      } else {
        let mr: ParseTraitMethodResult = parse_trait_method_decl(q);
        q = mr.p;
        ms.push(mr.m);
      }
      if kind_is(peek_kind(q), lex.TokenKind.Comma) {
        let ar4: AdvanceResult = advance(q);
        q = ar4.p;
        if kind_is(peek_kind(q), lex.TokenKind.RBrace) { break; }
        continue;
      }
      if kind_is(peek_kind(q), lex.TokenKind.RBrace) { break; }
      continue;
    }
  }
  let ar5: AdvanceResult = expect(q, lex.TokenKind.RBrace);
  return ParseTraitResult {
    p: ar5.p,
    t: ast.TraitDecl { file: p.file, sp: span_tok(p, ar1.tok), vis: vis, is_pub: is_pub, name: r2.name, supers: supers, assoc_types: assocs, methods: ms },
  };
}

fn parse_impl_decl(p: Parser) -> ParseImplResult {
  let ar1: AdvanceResult = expect(p, lex.TokenKind.KwImpl);
  let mut q0: Parser = ar1.p;
  let mut tps: Vec[String] = Vec();
  let mut tpbs: Vec[ast.TypeParamBoundsDecl] = Vec();
  if kind_is(peek_kind(q0), lex.TokenKind.LBracket) {
    let rtp: ParseTypeParamsResult = parse_type_params(q0);
    q0 = rtp.p;
    tps = rtp.tps;
    tpbs = rtp.tpbs;
  }
  let tr: ParseTypeResult = parse_type_name(q0);
  let ar2: AdvanceResult = expect(tr.p, lex.TokenKind.KwFor);
  let fr: ParseTypeResult = parse_type_name(ar2.p);
  let ar3: AdvanceResult = expect(fr.p, lex.TokenKind.LBrace);
  let mut q: Parser = ar3.p;
  let mut assoc_types: Vec[ast.ImplAssocTypeBinding] = Vec();
  let mut methods: Vec[ast.FuncDecl] = Vec();
  while !q.has_err && !kind_is(peek_kind(q), lex.TokenKind.RBrace) && !kind_is(peek_kind(q), lex.TokenKind.Eof) {
    if kind_is(peek_kind(q), lex.TokenKind.KwType) {
      let ar: ParseImplAssocTypeResult = parse_impl_assoc_type_binding(q);
      q = ar.p;
      assoc_types.push(ar.a);
    } else {
      let r: ParseFnResult = parse_fn_decl(q, ast.vis_private(), false);
      q = r.p;
      methods.push(r.f);
    }
  }
  let ar4: AdvanceResult = expect(q, lex.TokenKind.RBrace);
  return ParseImplResult {
    p: ar4.p,
    i: ast.ImplDecl {
      file: p.file,
      sp: span_tok(p, ar1.tok),
      type_params: tps,
      type_param_bounds: tpbs,
      trait_name: tr.ty,
      for_ty: fr.ty,
      assoc_types: assoc_types,
      methods: methods,
    },
  };
}

fn parse_type_alias_decl(p: Parser, vis: i32, is_pub: bool) -> ParseTypeAliasResult {
  // `type Name = Type;` (semicolon optional)
  let ar0: AdvanceResult = expect(p, lex.TokenKind.KwType);
  let r1: ParseIdentResult = parse_ident(ar0.p);
  let ar2: AdvanceResult = expect(r1.p, lex.TokenKind.Eq);
  let r3: ParseTypeResult = parse_type_name(ar2.p);
  let mut q: Parser = r3.p;
  if kind_is(peek_kind(q), lex.TokenKind.Semicolon) {
    let ar4: AdvanceResult = advance(q);
    q = ar4.p;
  }
  return ParseTypeAliasResult { p: q, t: ast.TypeAliasDecl { file: p.file, sp: span_tok(p, ar0.tok), vis: vis, is_pub: is_pub, name: r1.name, ty: r3.ty } };
}

fn parse_const_decl(p: Parser, vis: i32, is_pub: bool) -> ParseConstResult {
  // `const Name: Type = Expr;` (semicolon optional)
  let ar0: AdvanceResult = expect(p, lex.TokenKind.KwConst);
  let r1: ParseIdentResult = parse_ident(ar0.p);
  let ar2: AdvanceResult = expect(r1.p, lex.TokenKind.Colon);
  let r3: ParseTypeResult = parse_type_name(ar2.p);
  let ar4: AdvanceResult = expect(r3.p, lex.TokenKind.Eq);
  let r5: ParseExprResult = parse_expr(ar4.p, 0);
  let mut q: Parser = r5.p;
  if kind_is(peek_kind(q), lex.TokenKind.Semicolon) {
    let ar6: AdvanceResult = advance(q);
    q = ar6.p;
  }
  return ParseConstResult { p: q, c: ast.ConstDecl { file: p.file, sp: span_tok(p, ar0.tok), vis: vis, is_pub: is_pub, name: r1.name, ty: r3.ty, init: r5.id } };
}

fn parse_type_decl(p: Parser, vis: i32, is_pub: bool) -> ParseTypeDeclResult {
  // Either:
  // - type alias: `type Name = TypeName;`
  // - union type decl (tagged union): `type Name = A: TA | B: TB;` (stage1 v0 only labeled form)
  let ar0: AdvanceResult = expect(p, lex.TokenKind.KwType);
  let r1: ParseIdentResult = parse_ident(ar0.p);
  let ar2: AdvanceResult = expect(r1.p, lex.TokenKind.Eq);

  // Disambiguation: union uses labeled arms `Ident :`.
  if kind_is(peek_kind(ar2.p), lex.TokenKind.Ident) && kind_is(peek2_kind(ar2.p), lex.TokenKind.Colon) {
    let mut q: Parser = ar2.p;
    let mut vars: Vec[ast.EnumVariantDecl] = Vec();
    while !q.has_err {
      let rlbl: ParseIdentResult = parse_ident(q);
      let arcol: AdvanceResult = expect(rlbl.p, lex.TokenKind.Colon);
      let rty: ParseTypeResult = parse_type_name(arcol.p);
      vars.push(ast.EnumVariantDecl { name: rlbl.name, fields: vec1_type(rty.ty) });
      q = rty.p;
      if kind_is(peek_kind(q), lex.TokenKind.Pipe) {
        let arbar: AdvanceResult = advance(q);
        q = arbar.p;
        continue;
      }
      break;
    }
    if kind_is(peek_kind(q), lex.TokenKind.Semicolon) {
      let arsemi: AdvanceResult = advance(q);
      q = arsemi.p;
    }
    return ParseTypeDeclResult {
      p: q,
      is_union: true,
      t: ast.TypeAliasDecl { file: "", sp: ast.span0(), vis: ast.vis_private(), is_pub: false, name: "", ty: ast.TypeName { parts: Vec(), args: Vec() } },
      e: ast.EnumDecl { file: p.file, sp: span_tok(p, ar0.tok), vis: vis, is_pub: is_pub, name: r1.name, type_params: Vec(), type_param_bounds: Vec(), const_where_bounds: Vec(), variants: vars },
    };
  }

  // Alias fallback.
  let r3: ParseTypeResult = parse_type_name(ar2.p);
  let mut q2: Parser = r3.p;
  if kind_is(peek_kind(q2), lex.TokenKind.Semicolon) {
    let ar4: AdvanceResult = advance(q2);
    q2 = ar4.p;
  }
  return ParseTypeDeclResult {
    p: q2,
    is_union: false,
    t: ast.TypeAliasDecl { file: p.file, sp: span_tok(p, ar0.tok), vis: vis, is_pub: is_pub, name: r1.name, ty: r3.ty },
    e: ast.EnumDecl { file: "", sp: ast.span0(), vis: ast.vis_private(), is_pub: false, name: "", type_params: Vec(), type_param_bounds: Vec(), const_where_bounds: Vec(), variants: Vec() },
  };
}

fn vec1_type(x: ast.TypeName) -> Vec[ast.TypeName] {
  let mut v: Vec[ast.TypeName] = Vec();
  v.push(x);
  return v;
}

fn parse_params(p: Parser) -> ParseParamsResult {
  let mut q: Parser = p;
  let mut params: Vec[ast.Param] = Vec();
  if kind_is(peek_kind(q), lex.TokenKind.RParen) {
    return ParseParamsResult { p: q, params: params };
  }
  while !q.has_err {
    let r1: ParseIdentResult = parse_ident(q);
    let ar2: AdvanceResult = expect(r1.p, lex.TokenKind.Colon);
    let r3: ParseTypeResult = parse_type_name(ar2.p);
    let mut pty: ast.TypeName = r3.ty;
    let mut q1: Parser = r3.p;
    if kind_is(peek_kind(q1), lex.TokenKind.DotDotDot) {
      let ar_pack: AdvanceResult = advance(q1);
      q1 = ar_pack.p;
      let mut pparts: Vec[String] = Vec();
      pparts.push("@pack");
      let mut pargs: Vec[ast.TypeName] = Vec();
      pargs.push(pty);
      pty = ast.TypeName { parts: pparts, args: pargs };
    }
    params.push(ast.Param { name: r1.name, ty: pty });
    q = q1;
    if kind_is(peek_kind(q), lex.TokenKind.Comma) {
      let ar4: AdvanceResult = advance(q);
      q = ar4.p;
      if kind_is(peek_kind(q), lex.TokenKind.RParen) {
        break;
      }
      continue;
    }
    break;
  }
  return ParseParamsResult { p: q, params: params };
}

fn parse_pub_marker(p: Parser) -> ParsePubResult {
  if !kind_is(peek_kind(p), lex.TokenKind.KwPub) {
    return ParsePubResult { p: p, vis: ast.vis_private(), is_pub: false };
  }
  let ar1: AdvanceResult = advance(p);
  let mut q: Parser = ar1.p;
  let mut vis: i32 = ast.vis_pub();
  if kind_is(peek_kind(q), lex.TokenKind.LParen) {
    let ar2: AdvanceResult = advance(q);
    let r3: ParseIdentResult = parse_ident(ar2.p);
    q = r3.p;
    if r3.name == "crate" {
      vis = ast.vis_crate();
    } else if r3.name == "super" {
      vis = ast.vis_super();
    } else {
      let mut qq: Parser = q;
      let at: i32 = peek(q).start;
      qq.has_err = true;
      qq.err = ParseError.UnexpectedToken(lex.TokenKind.Ident, peek_kind(q), at);
      q = qq;
    }
    let ar4: AdvanceResult = expect(q, lex.TokenKind.RParen);
    q = ar4.p;
  }
  return ParsePubResult { p: q, vis: vis, is_pub: true };
}

		fn parse_program(p: Parser) -> ParseProgramResult {
		  let mut q: Parser = p;
		  let mut imports: Vec[ast.ImportDecl] = Vec();
		  let mut types: Vec[ast.TypeAliasDecl] = Vec();
		  let mut consts: Vec[ast.ConstDecl] = Vec();
		  let mut structs: Vec[ast.StructDecl] = Vec();
		  let mut enums: Vec[ast.EnumDecl] = Vec();
		  let mut traits: Vec[ast.TraitDecl] = Vec();
		  let mut impls: Vec[ast.ImplDecl] = Vec();
		  let mut funcs: Vec[ast.FuncDecl] = Vec();
	  while !q.has_err && !kind_is(peek_kind(q), lex.TokenKind.Eof) {
	    if kind_is(peek_kind(q), lex.TokenKind.KwImport) {
	      let r: ParseImportResult = parse_import_decl(q);
	      q = r.p;
	      imports.push(r.imp);
	    } else {
	      // optional `pub`
	      let mut is_pub: bool = false;
      let mut vis: i32 = ast.vis_private();
	      let pr: ParsePubResult = parse_pub_marker(q);
	      q = pr.p;
	      is_pub = pr.is_pub;
      vis = pr.vis;
	      let k: lex.TokenKind = peek_kind(q);
	      if kind_is(k, lex.TokenKind.KwType) {
	        let r: ParseTypeDeclResult = parse_type_decl(q, vis, is_pub);
	        q = r.p;
	        if r.is_union {
	          enums.push(r.e);
	        } else {
	          types.push(r.t);
	        }
	      } else if kind_is(k, lex.TokenKind.KwConst) {
	        let r: ParseConstResult = parse_const_decl(q, vis, is_pub);
	        q = r.p;
	        consts.push(r.c);
	      } else if kind_is(k, lex.TokenKind.KwStruct) {
	        let r: ParseStructResult = parse_struct_decl(q, vis, is_pub);
	        q = r.p;
	        structs.push(r.s);
		      } else if kind_is(k, lex.TokenKind.KwEnum) {
		        let r: ParseEnumResult = parse_enum_decl(q, vis, is_pub);
		        q = r.p;
		        enums.push(r.e);
		      } else if kind_is(k, lex.TokenKind.KwTrait) {
		        let r: ParseTraitResult = parse_trait_decl(q, vis, is_pub);
		        q = r.p;
		        traits.push(r.t);
		      } else if kind_is(k, lex.TokenKind.KwImpl) {
		        let r: ParseImplResult = parse_impl_decl(q);
		        q = r.p;
		        impls.push(r.i);
		      } else {
		        let r: ParseFnResult = parse_fn_decl(q, vis, is_pub);
		        q = r.p;
		        funcs.push(r.f);
		      }
		    }
		  }
		  return ParseProgramResult { p: q, prog: ast.Program { imports: imports, types: types, consts: consts, structs: structs, enums: enums, traits: traits, impls: impls, funcs: funcs, exprs: q.exprs } };
		}

	pub fn parse_text_with_path(path: String, text: String) -> ParseResult {
	  let lr: lex.LexResult = lex.lex_text(text);
	  if !lex_err_none(lr.err) {
	    return ParseResult { prog: ast.Program { imports: Vec(), types: Vec(), consts: Vec(), structs: Vec(), enums: Vec(), traits: Vec(), impls: Vec(), funcs: Vec(), exprs: ast.expr_pool() }, err: ParseError.Lex(lr.err) };
	  }
	  let p: Parser = Parser { file: path, text: text, line_starts: build_line_starts(text), toks: lr.tokens, pos: 0, has_err: false, err: ParseError.None, exprs: ast.expr_pool() };
	  let r: ParseProgramResult = parse_program(p);
	  return ParseResult { prog: r.prog, err: r.p.err };
	}

	pub fn parse_text(text: String) -> ParseResult {
	  return parse_text_with_path("src/main.vox", text);
	}
