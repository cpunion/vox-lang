// std/async: pull-based async core contracts.
//
// This module defines the minimal type-level contract used by D03:
// - Future state progresses only when polled by executor.
// - push-style systems can bridge via Sink.

import "std/time" as tm
import "std/runtime" as rti

pub enum Poll[T] {
  Pending,
  Ready(T),
}

pub struct Waker {
  pub token: i64,
}

pub struct Context {
  pub waker: Waker,
}

pub struct CancelHint {
  pub state: i32,
  pub spins: i32,
  pub token: i64,
  pub reclaim: i32,
}

// Coarse reclaim levels for cancel/drop hooks.
// Hosts may map these to allocator/runtime-specific policies.
pub fn cancel_reclaim_keep() -> i32 { return 0; }
pub fn cancel_reclaim_shallow() -> i32 { return 1; }
pub fn cancel_reclaim_deep() -> i32 { return 2; }

pub fn cancel_reclaim_from_state_spins(state: i32, spins: i32) -> i32 {
  if state <= 0 { return cancel_reclaim_keep(); }
  if spins < 8 { return cancel_reclaim_shallow(); }
  return cancel_reclaim_deep();
}

pub fn cancel_reclaim_is_deep(h: CancelHint) -> bool {
  return h.reclaim == cancel_reclaim_deep();
}

pub trait Future {
  type Output;
  fn poll(x: &mut Self, cx: &Context) -> Poll[Self.Output];
}

// Runtime abstraction for pending scheduling and cancellation polling.
//
// v0 exposes a minimal but pluggable contract:
// - pending_wait: scheduler wait/yield hook
// - park_until_wake: optional evented wait (default falls back to pending_wait)
// - cancel_requested: optional cancellation poll hook (default false)
//
// Different runtimes (tight-loop, evented, epoll-backed, etc.) can provide
// their own impls and be threaded through *_with helpers.
pub trait Runtime {
  fn pending_wait(rt: Self, i: i32, c: Context) -> ();
  fn park_until_wake(rt: Self, i: i32, c: Context) -> bool {
    Runtime.pending_wait(rt, i, c);
    return false;
  }
  fn cancel_requested(rt: Self, c: Context) -> bool {
    rt;
    c;
    return false;
  }
}

pub struct SpinRuntime {
  pub marker: i32,
}

pub struct EventRuntime {
  pub timeout_ms: i32,
}

pub struct ReadyPoll {
  pub ready: bool,
  pub token: i64,
}

pub struct ReadyMany {
  pub ready: bool,
  pub index: i32,
  pub token: i64,
}

pub struct ReadyQueue {
  pub tokens: Vec[i64],
  pub head: i32,
}

pub struct ReadyPop {
  pub ok: bool,
  pub token: i64,
  pub q: ReadyQueue,
}

// Event source abstraction used by runtime-specific backends (epoll/kqueue/IOCP).
// v0 baseline keeps a minimal "wait once" contract and feeds a token queue.
pub trait EventSource {
  fn wait(src: Self, timeout_ms: i32, c: Context) -> ReadyPoll;
  fn wait_many(src: Self, timeout_ms: i32, cs: Vec[Context]) -> i32 {
    return wait_many_scan(src, timeout_ms, cs);
  }
}

impl Runtime for SpinRuntime {
  fn pending_wait(rt: SpinRuntime, i: i32, c: Context) -> () {
    rt;
    c;
    spin_wait(i);
    return;
  }
}

fn normalized_timeout_ms(ms: i32) -> i32 {
  if ms <= 0 { return 1; }
  return ms;
}

fn rt_api() -> rti.Runtime {
  return rti.runtime();
}

fn context_tokens(cs: Vec[Context]) -> Vec[i64] {
  let mut out: Vec[i64] = Vec();
  let mut i: i32 = 0;
  while i < cs.len() {
    out.push(cs.get(i).waker.token);
    i = i + 1;
  }
  return out;
}

fn wait_many_scan[S: EventSource](src: S, timeout_ms: i32, cs: Vec[Context]) -> i32 {
  let mut i: i32 = 0;
  while i < cs.len() {
    let ms: i32 = if i == 0 { timeout_ms } else { 0 };
    if poll_ready_with(src, ms, cs.get(i)).ready { return i; }
    i = i + 1;
  }
  return -1;
}

impl EventSource for EventRuntime {
  fn wait(rt: EventRuntime, timeout_ms: i32, c: Context) -> ReadyPoll {
    let ms: i32 = if timeout_ms > 0 { normalized_timeout_ms(timeout_ms) } else { normalized_timeout_ms(rt.timeout_ms) };
    let ok: bool = rt_api().wake_wait(c.waker.token, ms);
    return ReadyPoll { ready: ok, token: c.waker.token };
  }
  fn wait_many(rt: EventRuntime, timeout_ms: i32, cs: Vec[Context]) -> i32 {
    if cs.len() == 0 { return -1; }
    let ms: i32 = if timeout_ms > 0 { normalized_timeout_ms(timeout_ms) } else { normalized_timeout_ms(rt.timeout_ms) };
    let api: rti.Runtime = rt_api();
    if api.has_cap(rti.IntrinsicCap.WakeWaitAny) {
      return api.wake_wait_any(context_tokens(cs), ms);
    }
    return wait_many_scan(rt, ms, cs);
  }
}

impl Runtime for EventRuntime {
  fn pending_wait(rt: EventRuntime, i: i32, c: Context) -> () {
    i;
    rt_api().wake_wait(c.waker.token, normalized_timeout_ms(rt.timeout_ms));
    return;
  }
  fn park_until_wake(rt: EventRuntime, i: i32, c: Context) -> bool {
    i;
    return rt_api().wake_wait(c.waker.token, normalized_timeout_ms(rt.timeout_ms));
  }
}

// Push boundary adapter contract: external event sources can push values into
// a sink that later wakes and feeds a pull-driven Future/Stream.
pub trait Sink {
  type Item;
  fn push(x: &mut Self, v: Self.Item) -> bool;
  fn close(x: &mut Self) -> ();
}

pub fn is_pending[T](p: Poll[T]) -> bool {
  return match p {
    Poll.Pending => true,
    _ => false,
  };
}

pub fn is_ready[T](p: Poll[T]) -> bool {
  return match p {
    Poll.Ready(_v) => true,
    _ => false,
  };
}

pub fn waker(token: i64) -> Waker {
  return Waker { token: token };
}

pub fn context(w: Waker) -> Context {
  return Context { waker: w };
}

pub fn ready_queue() -> ReadyQueue {
  return ReadyQueue { tokens: Vec(), head: 0 };
}

impl ReadyQueue {
  fn len(q: ReadyQueue) -> i32 { return q.tokens.len() - q.head; }

  fn is_empty(q: ReadyQueue) -> bool { return q.tokens.len() == q.head; }

  fn push(q: ReadyQueue, token: i64) -> ReadyQueue {
    let mut out: ReadyQueue = q;
    out.tokens.push(token);
    return out;
  }

  fn pop(q: ReadyQueue) -> ReadyPop {
    if q.tokens.len() == q.head {
      return ReadyPop { ok: false, token: 0, q: q };
    }
    let mut out: ReadyQueue = q;
    let tok: i64 = out.tokens.get(out.head);
    out.head = out.head + 1;
    if out.head > 0 && out.head * 2 >= out.tokens.len() {
      let mut compact: Vec[i64] = Vec();
      let mut i: i32 = out.head;
      while i < out.tokens.len() {
        compact.push(out.tokens.get(i));
        i = i + 1;
      }
      out.tokens = compact;
      out.head = 0;
    }
    return ReadyPop { ok: true, token: tok, q: out };
  }
}

pub fn spin_runtime() -> SpinRuntime {
  return SpinRuntime { marker: 0 };
}

pub fn event_runtime(timeout_ms: i32) -> EventRuntime {
  return EventRuntime { timeout_ms: normalized_timeout_ms(timeout_ms) };
}

pub fn poll_ready_with[S: EventSource](src: S, timeout_ms: i32, c: Context) -> ReadyPoll {
  return EventSource.wait(src, timeout_ms, c);
}

pub fn wait_many_with[S: EventSource](src: S, timeout_ms: i32, cs: Vec[Context]) -> ReadyMany {
  if cs.len() == 0 {
    return ReadyMany { ready: false, index: -1, token: 0 };
  }
  let idx: i32 = EventSource.wait_many(src, timeout_ms, cs);
  if idx < 0 || idx >= cs.len() {
    return ReadyMany { ready: false, index: -1, token: 0 };
  }
  return ReadyMany { ready: true, index: idx, token: cs.get(idx).waker.token };
}

pub fn wait_many(timeout_ms: i32, cs: Vec[Context]) -> ReadyMany {
  return wait_many_with(default_runtime(), timeout_ms, cs);
}

pub fn enqueue_ready(q: ReadyQueue, p: ReadyPoll) -> ReadyQueue {
  if p.ready { return q.push(p.token); }
  return q;
}

// Poll all provided contexts once and enqueue every ready token.
// Phase-B: use wait_many for the blocking wait point, then run a non-blocking
// single pass to collect the remaining ready contexts.
pub fn drain_ready_once[S: EventSource](src: S, timeout_ms: i32, cs: Vec[Context], q0: ReadyQueue) -> ReadyQueue {
  let mut q: ReadyQueue = q0;
  let first: ReadyMany = wait_many_with(src, timeout_ms, cs);
  if !first.ready { return q; }
  q = q.push(first.token);
  let mut i: i32 = 0;
  while i < cs.len() {
    if i != first.index {
      q = enqueue_ready(q, poll_ready_with(src, 0, cs.get(i)));
    }
    i = i + 1;
  }
  return q;
}

pub fn io_runtime() -> EventRuntime {
  return event_runtime(1);
}

// Default runtime used by compiler-generated async entry/test wrappers.
pub fn default_runtime() -> EventRuntime {
  return io_runtime();
}

// Minimal wake hook. Evented runtimes may use token -> task mapping.
pub fn wake(c: Context) -> () {
  rt_api().wake_notify(c.waker.token);
  return;
}

// v0 executor hook for async entry wrappers.
// Current implementation is intentionally a no-op; hosts/runtimes can provide
// stronger scheduling behavior in later stages.
pub fn spin_wait(i: i32) -> () {
  i;
  tm.yield_now();
  return;
}

pub fn pending_wait_with[R: Runtime](rt: R, i: i32, c: Context) -> () {
  Runtime.pending_wait(rt, i, c);
  return;
}

pub fn park_with[R: Runtime](rt: R, i: i32, c: Context) -> () {
  pending_wait_with(rt, i, c);
  return;
}

// Enhanced pending hook: runtimes may block until an external wake-up source.
// Return value indicates whether wake-up was observed before returning.
pub fn park_until_wake_with[R: Runtime](rt: R, i: i32, c: Context) -> bool {
  return Runtime.park_until_wake(rt, i, c);
}

// Preferred pending hook used by generated async entry wrappers.
pub fn park(i: i32, c: Context) -> () {
  park_with(default_runtime(), i, c);
  return;
}

pub fn park_until_wake(i: i32, c: Context) -> bool {
  return park_until_wake_with(default_runtime(), i, c);
}

// Cancellation polling hook for generated async wrappers.
// Hosts can override this in their own std/async module implementation.
//
// Optional return-propagation hooks recognized by compiler wrappers:
// - cancel_hint(cx, state, spins) -> CancelHint
// - cancel_drop_hint_with(rt, cx, hint, f)
// - cancel_drop_state_with(rt, cx, state, f)
// - cancel_drop_with(rt, cx, f)
// - cancel_drop_hint(cx, hint, f)
// - cancel_drop_state(cx, state, f)
// - cancel_drop(cx, f)
// - cancel_cleanup_hint_with(rt, cx, hint)
// - cancel_cleanup_state_with(rt, cx, state)
// - cancel_cleanup_with(rt, cx)
// - cancel_cleanup_hint(cx, hint)
// - cancel_cleanup_state(cx, state)
// - cancel_cleanup(cx)
// - cancel_return_hint_with(rt, cx, hint)
// - cancel_return_with(rt, cx)
// - cancel_return_hint(cx, hint)
// - cancel_return(cx)
// If absent, wrapper falls back to default return values.
pub fn cancel_requested_with[R: Runtime](rt: R, c: Context) -> bool {
  return Runtime.cancel_requested(rt, c);
}

pub fn cancel_requested(c: Context) -> bool {
  return cancel_requested_with(spin_runtime(), c);
}

pub fn cancel_hint(c: Context, state: i32, spins: i32) -> CancelHint {
  return CancelHint {
    state: state,
    spins: spins,
    token: c.waker.token,
    reclaim: cancel_reclaim_from_state_spins(state, spins),
  };
}

// Optional frame cleanup/rebind hooks for cancel paths.
// Wrappers call these before cancel_cleanup/cancel_return when present.
pub fn cancel_drop_hint_with[R, F](rt: R, c: Context, h: CancelHint, f: F) -> F {
  rt;
  c;
  h;
  return cancel_drop_state_with(rt, c, h.state, f);
}

pub fn cancel_drop_state_with[R, F](rt: R, c: Context, state: i32, f: F) -> F {
  rt;
  c;
  state;
  return f;
}

pub fn cancel_drop_with[R, F](rt: R, c: Context, f: F) -> F {
  rt;
  c;
  return f;
}

pub fn cancel_drop_hint[F](c: Context, h: CancelHint, f: F) -> F {
  c;
  h;
  return cancel_drop_state(c, h.state, f);
}

pub fn cancel_drop_state[F](c: Context, state: i32, f: F) -> F {
  c;
  state;
  return f;
}

pub fn cancel_drop[F](c: Context, f: F) -> F {
  c;
  return f;
}

pub fn cancel_cleanup_hint_with[R](rt: R, c: Context, h: CancelHint) -> () {
  rt;
  c;
  h;
  cancel_cleanup_state_with(rt, c, h.state);
  return;
}

pub fn cancel_cleanup_hint(c: Context, h: CancelHint) -> () {
  c;
  h;
  cancel_cleanup_state(c, h.state);
  return;
}

pub fn cancel_cleanup_state_with[R](rt: R, c: Context, state: i32) -> () {
  rt;
  c;
  state;
  cancel_cleanup_with(rt, c);
  return;
}

pub fn cancel_cleanup_with[R](rt: R, c: Context) -> () {
  rt;
  c;
  return;
}

pub fn cancel_cleanup_state(c: Context, state: i32) -> () {
  c;
  state;
  cancel_cleanup(c);
  return;
}

pub fn cancel_cleanup(c: Context) -> () {
  c;
  return;
}

// Default pending hook used by generated async entry wrappers.
// Future runtimes can replace this with real wake/park integration.
pub fn pending_wait(i: i32, c: Context) -> () {
  park(i, c);
  return;
}
