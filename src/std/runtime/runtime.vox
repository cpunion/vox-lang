// std/runtime: low-level runtime capability adapter boundary.
//
// Public std modules should call this layer instead of touching low-level FFI
// symbols directly. This keeps std API stable when runtime mappings evolve.

import "std/time" as tm

pub fn intrinsic_abi() -> i32 { return 1; }

// Event loop: Vox-driven wake table with C-stored handles + platform poller.
@ffi_import("c", "vox_impl_el_init")
fn el_init_raw() -> ();

fn el_n_slots() -> i32 { return 256; }

@ffi_import("c", "vox_impl_el_token_handle")
fn el_token_handle(idx: i32) -> isize;

@ffi_import("c", "vox_impl_el_pending_handle")
fn el_pending_handle(idx: i32) -> isize;

@ffi_import("c", "vox_impl_el_poller_wake")
fn el_poller_wake() -> ();

@ffi_import("c", "vox_impl_el_poller_wait")
fn el_poller_wait(timeout_ms: i32) -> ();

@ffi_import("c", "vox_impl_atomic_i32_new")
fn rt_atomic_i32_new_raw(v: i32) -> isize;

@ffi_import("c", "vox_impl_atomic_i32_load")
fn rt_atomic_i32_load_raw(handle: isize) -> i32;

@ffi_import("c", "vox_impl_atomic_i32_store")
fn rt_atomic_i32_store_raw(handle: isize, v: i32) -> ();

@ffi_import("c", "vox_impl_atomic_i32_fetch_add")
fn rt_atomic_i32_fetch_add_raw(handle: isize, delta: i32) -> i32;

@ffi_import("c", "vox_impl_atomic_i32_swap")
fn rt_atomic_i32_swap_raw(handle: isize, v: i32) -> i32;

@ffi_import("c", "vox_impl_atomic_i32_cas")
fn rt_atomic_i32_cas_raw(handle: isize, expected: i32, desired: i32) -> bool;

@ffi_import("c", "vox_impl_atomic_i32_drop")
fn rt_atomic_i32_drop_raw(handle: isize) -> ();

@ffi_import("c", "vox_impl_atomic_i64_new")
fn rt_atomic_i64_new_raw(v: i64) -> isize;

@ffi_import("c", "vox_impl_atomic_i64_load")
fn rt_atomic_i64_load_raw(handle: isize) -> i64;

@ffi_import("c", "vox_impl_atomic_i64_store")
fn rt_atomic_i64_store_raw(handle: isize, v: i64) -> ();

@ffi_import("c", "vox_impl_atomic_i64_fetch_add")
fn rt_atomic_i64_fetch_add_raw(handle: isize, delta: i64) -> i64;

@ffi_import("c", "vox_impl_atomic_i64_swap")
fn rt_atomic_i64_swap_raw(handle: isize, v: i64) -> i64;

@ffi_import("c", "vox_impl_atomic_i64_cas")
fn rt_atomic_i64_cas_raw(handle: isize, expected: i64, desired: i64) -> bool;

@ffi_import("c", "vox_impl_atomic_i64_drop")
fn rt_atomic_i64_drop_raw(handle: isize) -> ();

// Compatibility probe kept for older std code.
// Runtime capabilities are no longer exposed as reserved `__*` intrinsics.
pub fn has_intrinsic(name: String) -> bool {
  name;
  return false;
}

// Pure Vox wake table algorithm using C-stored atomic handles.
fn el_slot_index(token: i64) -> i32 {
  let n: i32 = el_n_slots();
  let mut probe: i32 = 0;
  while probe < n {
    let raw: i64 = (token + (probe as i64)) % (n as i64);
    let idx: i32 = if raw < 0 { (raw + (n as i64)) as i32 } else { raw as i32 };
    let th: isize = el_token_handle(idx);
    let seen: i64 = atomic_i64_load(th);
    if seen == token { return idx; }
    if seen == 0 {
      if atomic_i64_cas(th, 0, token) { return idx; }
      let after: i64 = atomic_i64_load(th);
      if after == token { return idx; }
    }
    probe = probe + 1;
  }
  return -1;
}

fn el_try_consume(token: i64) -> bool {
  let idx: i32 = el_slot_index(token);
  if idx < 0 { return false; }
  let ph: isize = el_pending_handle(idx);
  while true {
    let cur: i32 = atomic_i32_load(ph);
    if cur <= 0 { return false; }
    if atomic_i32_cas(ph, cur, cur - 1) { return true; }
  }
  return false;
}

pub fn wake_notify(token: i64) -> () {
  el_init_raw();
  let idx: i32 = el_slot_index(token);
  if idx < 0 { return; }
  let old: i32 = atomic_i32_fetch_add(el_pending_handle(idx), 1);
  old;
  el_poller_wake();
  return;
}

pub fn wake_wait(token: i64, timeout_ms: i32) -> bool {
  el_init_raw();
  if el_try_consume(token) { return true; }
  if timeout_ms <= 0 { return el_try_consume(token); }
  let deadline: i64 = tm.now_ns() + ((timeout_ms as i64) * (1000 as i64) * (1000 as i64));
  while true {
    if el_try_consume(token) { return true; }
    let rem_ns: i64 = deadline - tm.now_ns();
    if rem_ns <= 0 { return el_try_consume(token); }
    let mut rem_ms: i32 = (rem_ns / ((1000 as i64) * (1000 as i64))) as i32;
    if rem_ms <= 0 { rem_ms = 1; }
    el_poller_wait(rem_ms);
  }
  return el_try_consume(token);
}

pub fn wake_wait_any(tokens: Vec[i64], timeout_ms: i32) -> i32 {
  el_init_raw();
  let n: i32 = tokens.len();
  if n == 0 { return -1; }

  // Non-blocking scan first.
  let mut i: i32 = 0;
  while i < n {
    if el_try_consume(tokens.get(i)) { return i; }
    i = i + 1;
  }
  if timeout_ms <= 0 { return -1; }

  let deadline: i64 = tm.now_ns() + ((timeout_ms as i64) * (1000 as i64) * (1000 as i64));
  while true {
    let rem_ns: i64 = deadline - tm.now_ns();
    if rem_ns <= 0 { return -1; }
    let mut rem_ms: i32 = (rem_ns / ((1000 as i64) * (1000 as i64))) as i32;
    if rem_ms <= 0 { rem_ms = 1; }
    el_poller_wait(rem_ms);

    // Re-scan all tokens after blocking wait.
    let mut j: i32 = 0;
    while j < n {
      if el_try_consume(tokens.get(j)) { return j; }
      j = j + 1;
    }
  }
  return -1;
}

pub fn atomic_i32_new(v: i32) -> isize { return rt_atomic_i32_new_raw(v); }

pub fn atomic_i32_load(handle: isize) -> i32 { return rt_atomic_i32_load_raw(handle); }

pub fn atomic_i32_store(handle: isize, v: i32) -> () {
  rt_atomic_i32_store_raw(handle, v);
  return;
}

pub fn atomic_i32_fetch_add(handle: isize, delta: i32) -> i32 {
  return rt_atomic_i32_fetch_add_raw(handle, delta);
}

pub fn atomic_i32_swap(handle: isize, v: i32) -> i32 {
  return rt_atomic_i32_swap_raw(handle, v);
}

pub fn atomic_i32_cas(handle: isize, expected: i32, desired: i32) -> bool {
  return rt_atomic_i32_cas_raw(handle, expected, desired);
}

pub fn atomic_i32_drop(handle: isize) -> () {
  rt_atomic_i32_drop_raw(handle);
  return;
}

pub fn atomic_i64_new(v: i64) -> isize { return rt_atomic_i64_new_raw(v); }

pub fn atomic_i64_load(handle: isize) -> i64 { return rt_atomic_i64_load_raw(handle); }

pub fn atomic_i64_store(handle: isize, v: i64) -> () {
  rt_atomic_i64_store_raw(handle, v);
  return;
}

pub fn atomic_i64_fetch_add(handle: isize, delta: i64) -> i64 {
  return rt_atomic_i64_fetch_add_raw(handle, delta);
}

pub fn atomic_i64_swap(handle: isize, v: i64) -> i64 {
  return rt_atomic_i64_swap_raw(handle, v);
}

pub fn atomic_i64_cas(handle: isize, expected: i64, desired: i64) -> bool {
  return rt_atomic_i64_cas_raw(handle, expected, desired);
}

pub fn atomic_i64_drop(handle: isize) -> () {
  rt_atomic_i64_drop_raw(handle);
  return;
}
