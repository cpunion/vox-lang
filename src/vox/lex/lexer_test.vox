import "std/testing" as t
import "vox/lex" as l

fn is_none(e: l.LexError) -> bool {
  return match e {
    l.LexError.None => true,
    _ => false,
  };
}

fn test_lex_smoke_keywords_and_punct() -> () {
  let r: l.LexResult = l.lex_text("fn main() -> i32 { return 0; }");
  t.assert(is_none(r.err));

  let toks: Vec[l.Token] = r.tokens;
  t.assert(toks.len() > 0);

  // fn
  t.assert(match toks.get(0).kind { l.TokenKind.KwFn => true, _ => false });
  // main
  t.assert(match toks.get(1).kind { l.TokenKind.Ident => true, _ => false });
  // (
  t.assert(match toks.get(2).kind { l.TokenKind.LParen => true, _ => false });
  // )
  t.assert(match toks.get(3).kind { l.TokenKind.RParen => true, _ => false });
  // ->
  t.assert(match toks.get(4).kind { l.TokenKind.Arrow => true, _ => false });
  // i32
  t.assert(match toks.get(5).kind { l.TokenKind.Ident => true, _ => false });
  // {
  t.assert(match toks.get(6).kind { l.TokenKind.LBrace => true, _ => false });
  // return
  t.assert(match toks.get(7).kind { l.TokenKind.KwReturn => true, _ => false });
  // 0
  t.assert(match toks.get(8).kind { l.TokenKind.Int => true, _ => false });
  // ;
  t.assert(match toks.get(9).kind { l.TokenKind.Semicolon => true, _ => false });
  // }
  t.assert(match toks.get(10).kind { l.TokenKind.RBrace => true, _ => false });
  // eof
  t.assert(match toks.get(11).kind { l.TokenKind.Eof => true, _ => false });
}

fn test_lex_skips_line_comment() -> () {
  let r: l.LexResult = l.lex_text("fn main() -> i32 { // hi\n return 0; }");
  t.assert(is_none(r.err));
  let toks: Vec[l.Token] = r.tokens;
  // Ensure we still see `return` after the comment.
  let mut saw_return: bool = false;
  let mut i: i32 = 0;
  while i < toks.len() {
    if match toks.get(i).kind { l.TokenKind.KwReturn => true, _ => false } {
      saw_return = true;
      break;
    }
    i = i + 1;
  }
  t.assert(saw_return);
}

fn test_lex_unterminated_string_is_error() -> () {
  let r: l.LexResult = l.lex_text("\"abc");
  t.assert(match r.err { l.LexError.UnterminatedString(_) => true, _ => false });
}

fn test_lex_triple_quoted_string_token() -> () {
  let r: l.LexResult = l.lex_text("fn main() -> i32 { print(\"\"\"\n  a\n\"\"\"); return 0; }");
  t.assert(is_none(r.err));
  let mut saw: bool = false;
  let mut i: i32 = 0;
  while i < r.tokens.len() {
    if match r.tokens.get(i).kind { l.TokenKind.Str => true, _ => false } {
      saw = true;
      i = r.tokens.len();
    } else {
      i = i + 1;
    }
  }
  t.assert(saw);
}

fn test_lex_unterminated_triple_quoted_string_is_error() -> () {
  let r: l.LexResult = l.lex_text("\"\"\"\nabc");
  t.assert(match r.err { l.LexError.UnterminatedString(_) => true, _ => false });
}

fn test_lex_unexpected_char_is_error() -> () {
  let r: l.LexResult = l.lex_text("@");
  t.assert(is_none(r.err));
  let toks: Vec[l.Token] = r.tokens;
  t.assert(match toks.get(0).kind { l.TokenKind.At => true, _ => false });
  t.assert(match toks.get(1).kind { l.TokenKind.Eof => true, _ => false });
}

fn test_lex_dotdot_tokens() -> () {
  let r: l.LexResult = l.lex_text(".. ... ..= .");
  t.assert(is_none(r.err));
  let toks: Vec[l.Token] = r.tokens;
  t.assert(match toks.get(0).kind { l.TokenKind.DotDot => true, _ => false });
  t.assert(match toks.get(1).kind { l.TokenKind.DotDotDot => true, _ => false });
  t.assert(match toks.get(2).kind { l.TokenKind.DotDotEq => true, _ => false });
  t.assert(match toks.get(3).kind { l.TokenKind.Dot => true, _ => false });
}

fn test_lex_true_false_are_keywords() -> () {
  let r: l.LexResult = l.lex_text("true false");
  t.assert(is_none(r.err));
  let toks: Vec[l.Token] = r.tokens;
  t.assert(match toks.get(0).kind { l.TokenKind.KwTrue => true, _ => false });
  t.assert(match toks.get(1).kind { l.TokenKind.KwFalse => true, _ => false });
  t.assert(match toks.get(2).kind { l.TokenKind.Eof => true, _ => false });
}

fn test_lex_where_is_keyword() -> () {
  let r: l.LexResult = l.lex_text("where");
  t.assert(is_none(r.err));
  let toks: Vec[l.Token] = r.tokens;
  t.assert(match toks.get(0).kind { l.TokenKind.KwWhere => true, _ => false });
  t.assert(match toks.get(1).kind { l.TokenKind.Eof => true, _ => false });
}

fn test_lex_comptime_is_keyword() -> () {
  let r: l.LexResult = l.lex_text("comptime");
  t.assert(is_none(r.err));
  let toks: Vec[l.Token] = r.tokens;
  t.assert(match toks.get(0).kind { l.TokenKind.KwComptime => true, _ => false });
  t.assert(match toks.get(1).kind { l.TokenKind.Eof => true, _ => false });
}

fn test_lex_pipe_token() -> () {
  let r: l.LexResult = l.lex_text("& | ^ && || << >>");
  t.assert(is_none(r.err));
  let toks: Vec[l.Token] = r.tokens;
  t.assert(match toks.get(0).kind { l.TokenKind.Amp => true, _ => false });
  t.assert(match toks.get(1).kind { l.TokenKind.Pipe => true, _ => false });
  t.assert(match toks.get(2).kind { l.TokenKind.Caret => true, _ => false });
  t.assert(match toks.get(3).kind { l.TokenKind.AndAnd => true, _ => false });
  t.assert(match toks.get(4).kind { l.TokenKind.OrOr => true, _ => false });
  t.assert(match toks.get(5).kind { l.TokenKind.LtLt => true, _ => false });
  t.assert(match toks.get(6).kind { l.TokenKind.GtGt => true, _ => false });
  t.assert(match toks.get(7).kind { l.TokenKind.Eof => true, _ => false });
}

fn test_lex_compound_assign_tokens() -> () {
  let r: l.LexResult = l.lex_text("+= -= *= /= %= &= |= ^= <<= >>=");
  t.assert(is_none(r.err));
  let toks: Vec[l.Token] = r.tokens;
  t.assert(match toks.get(0).kind { l.TokenKind.PlusEq => true, _ => false });
  t.assert(match toks.get(1).kind { l.TokenKind.MinusEq => true, _ => false });
  t.assert(match toks.get(2).kind { l.TokenKind.StarEq => true, _ => false });
  t.assert(match toks.get(3).kind { l.TokenKind.SlashEq => true, _ => false });
  t.assert(match toks.get(4).kind { l.TokenKind.PercentEq => true, _ => false });
  t.assert(match toks.get(5).kind { l.TokenKind.AmpEq => true, _ => false });
  t.assert(match toks.get(6).kind { l.TokenKind.PipeEq => true, _ => false });
  t.assert(match toks.get(7).kind { l.TokenKind.CaretEq => true, _ => false });
  t.assert(match toks.get(8).kind { l.TokenKind.LtLtEq => true, _ => false });
  t.assert(match toks.get(9).kind { l.TokenKind.GtGtEq => true, _ => false });
  t.assert(match toks.get(10).kind { l.TokenKind.Eof => true, _ => false });
}

fn test_lex_float_literals_and_range_disambiguation() -> () {
  let r: l.LexResult = l.lex_text("1.0 42 3..4 5.25");
  t.assert(is_none(r.err));
  let toks: Vec[l.Token] = r.tokens;
  t.assert(match toks.get(0).kind { l.TokenKind.Float => true, _ => false });
  t.assert(match toks.get(1).kind { l.TokenKind.Int => true, _ => false });
  // `3..4` must remain `Int DotDot Int` (not float).
  t.assert(match toks.get(2).kind { l.TokenKind.Int => true, _ => false });
  t.assert(match toks.get(3).kind { l.TokenKind.DotDot => true, _ => false });
  t.assert(match toks.get(4).kind { l.TokenKind.Int => true, _ => false });
  t.assert(match toks.get(5).kind { l.TokenKind.Float => true, _ => false });
  t.assert(match toks.get(6).kind { l.TokenKind.Eof => true, _ => false });
}

fn test_lex_float_scientific_and_suffix_forms() -> () {
  let r: l.LexResult = l.lex_text("1e3 2.5e-2 3f32 4.0f64 5..6");
  t.assert(is_none(r.err));
  let toks: Vec[l.Token] = r.tokens;
  t.assert(match toks.get(0).kind { l.TokenKind.Float => true, _ => false });
  t.assert(match toks.get(1).kind { l.TokenKind.Float => true, _ => false });
  t.assert(match toks.get(2).kind { l.TokenKind.Float => true, _ => false });
  t.assert(match toks.get(3).kind { l.TokenKind.Float => true, _ => false });
  t.assert(match toks.get(4).kind { l.TokenKind.Int => true, _ => false });
  t.assert(match toks.get(5).kind { l.TokenKind.DotDot => true, _ => false });
  t.assert(match toks.get(6).kind { l.TokenKind.Int => true, _ => false });
  t.assert(match toks.get(7).kind { l.TokenKind.Eof => true, _ => false });
}

fn test_lex_try_keyword_and_question_token() -> () {
  let r: l.LexResult = l.lex_text("try x?");
  t.assert(is_none(r.err));
  let toks: Vec[l.Token] = r.tokens;
  t.assert(match toks.get(0).kind { l.TokenKind.KwTry => true, _ => false });
  t.assert(match toks.get(1).kind { l.TokenKind.Ident => true, _ => false });
  t.assert(match toks.get(2).kind { l.TokenKind.Question => true, _ => false });
  t.assert(match toks.get(3).kind { l.TokenKind.Eof => true, _ => false });
}

fn test_lex_dollar_token() -> () {
  let r: l.LexResult = l.lex_text("$x");
  t.assert(is_none(r.err));
  let toks: Vec[l.Token] = r.tokens;
  t.assert(match toks.get(0).kind { l.TokenKind.Dollar => true, _ => false });
  t.assert(match toks.get(1).kind { l.TokenKind.Ident => true, _ => false });
  t.assert(match toks.get(2).kind { l.TokenKind.Eof => true, _ => false });
}

fn test_lex_tick_token() -> () {
  let r: l.LexResult = l.lex_text("'static");
  t.assert(is_none(r.err));
  let toks: Vec[l.Token] = r.tokens;
  t.assert(match toks.get(0).kind { l.TokenKind.Tick => true, _ => false });
  t.assert(match toks.get(1).kind { l.TokenKind.Ident => true, _ => false });
  t.assert(match toks.get(2).kind { l.TokenKind.Eof => true, _ => false });
}

fn test_lex_async_await_are_keywords() -> () {
  let r: l.LexResult = l.lex_text("async await");
  t.assert(is_none(r.err));
  let toks: Vec[l.Token] = r.tokens;
  t.assert(match toks.get(0).kind { l.TokenKind.KwAsync => true, _ => false });
  t.assert(match toks.get(1).kind { l.TokenKind.KwAwait => true, _ => false });
  t.assert(match toks.get(2).kind { l.TokenKind.Eof => true, _ => false });
}
