// Stability: Stable module API (vox/parse).
// Migration: Backward-compatible within minor releases; breaking changes require migration notes.

import "vox/ast" as ast
import "vox/lex" as lex

pub enum ParseError {
  None,
  Lex(lex.LexError),
  InvalidString(i32, String), // byte offset, reason
  InvalidType(i32, String), // byte offset, reason
  UnexpectedToken(lex.TokenKind, lex.TokenKind, i32), // expected, got, byte offset
}

pub struct ParseDiag {
  pub kind: i32,
  pub code: String,
  pub message: String,
  pub rendered: String,
}

pub fn parse_diag_kind_none() -> i32 { return 0; }
pub fn parse_diag_kind_parse() -> i32 { return 1; }
pub fn parse_diag_kind_lex() -> i32 { return 2; }

pub fn parse_error_to_string(e: ParseError) -> String {
  return match e {
    ParseError.None => "none",
    ParseError.Lex(le) => "lex error: ".concat(lex.lex_error_to_string(le)),
    ParseError.InvalidString(at, why) =>
      "invalid string literal at ".concat(at.to_string()).concat(": ").concat(why),
    ParseError.InvalidType(at, why) =>
      "invalid type syntax at ".concat(at.to_string()).concat(": ").concat(why),
    ParseError.UnexpectedToken(exp, got, at) =>
      "unexpected token at ".concat(at.to_string())
        .concat(": expected ").concat(lex.token_kind_name(exp))
        .concat(", got ").concat(lex.token_kind_name(got)),
  };
}

fn parse_code_parse() -> String { return "E_PARSE_0001"; }
fn parse_code_lex() -> String { return "E_LEX_0001"; }

pub fn parse_error_kind(e: ParseError) -> i32 {
  return match e {
    ParseError.None => parse_diag_kind_none(),
    ParseError.Lex(_le) => parse_diag_kind_lex(),
    ParseError.InvalidString(_at, _why) => parse_diag_kind_parse(),
    ParseError.InvalidType(_at, _why) => parse_diag_kind_parse(),
    ParseError.UnexpectedToken(_exp, _got, _at) => parse_diag_kind_parse(),
  };
}

pub fn parse_error_code(e: ParseError) -> String {
  return match e {
    ParseError.None => "",
    ParseError.Lex(_le) => parse_code_lex(),
    ParseError.InvalidString(_at, _why) => parse_code_parse(),
    ParseError.InvalidType(_at, _why) => parse_code_parse(),
    ParseError.UnexpectedToken(_exp, _got, _at) => parse_code_parse(),
  };
}

pub fn parse_error_message(e: ParseError) -> String {
  return match e {
    ParseError.None => "parse error: none",
    ParseError.Lex(le) => "lex error: ".concat(lex.lex_error_to_string(le)),
    ParseError.InvalidString(_at, why) => "parse error: invalid string literal: ".concat(why),
    ParseError.InvalidType(_at, why) => "parse error: invalid type syntax: ".concat(why),
    ParseError.UnexpectedToken(exp, got, _at) =>
      "parse error: unexpected token: expected ".concat(lex.token_kind_name(exp))
        .concat(", got ").concat(lex.token_kind_name(got)),
  };
}

struct LineCol { line: i32, col: i32 }

fn build_line_starts(text: String) -> Vec[i32] {
  // line_starts[i] is the byte offset of the first character of line (i+1).
  // Always contains 0 for line 1.
  let mut out: Vec[i32] = Vec();
  out.push(0);
  let mut i: i32 = 0;
  while i < text.len() {
    if text.byte_at(i) == 10 { out.push(i + 1); } // '\n'
    i = i + 1;
  }
  return out;
}

fn is_utf8_cont_byte(b: i32) -> bool {
  return b >= 128 && b <= 191;
}

fn rune_col_from_line_start(text: String, line_start: i32, at: i32) -> i32 {
  // 1-based rune column.
  if at <= line_start { return 1; }
  let mut col: i32 = 1;
  let mut i: i32 = line_start;
  while i < at {
    let b: i32 = text.byte_at(i);
    if !is_utf8_cont_byte(b) { col = col + 1; }
    i = i + 1;
  }
  return col;
}

fn pos_to_line_col(text: String, line_starts: Vec[i32], at0: i32) -> LineCol {
  let mut at: i32 = at0;
  if at < 0 { at = 0; }
  if at > text.len() { at = text.len(); }

  // Binary search for the last line start <= at.
  let mut lo: i32 = 0;
  let mut hi: i32 = line_starts.len();
  while lo + 1 < hi {
    let mid: i32 = (lo + hi) / 2;
    if line_starts.get(mid) <= at { lo = mid; } else { hi = mid; }
  }
  let line: i32 = lo + 1;
  let col: i32 = rune_col_from_line_start(text, line_starts.get(lo), at);
  return LineCol { line: line, col: col };
}

fn span_tok(p: Parser, t: lex.Token) -> ast.Span {
  return ast.Span { file: p.file, line: t.line, col: t.col };
}

fn span_expr(exprs: ast.ExprPool, id: i32) -> ast.Span { return ast.expr_pool_span(exprs, id); }

pub fn parse_error_to_string_with_source(file: String, text: String, e: ParseError) -> String {
  return parse_error_diag(file, text, e).rendered;
}

pub fn parse_error_diag(file: String, text: String, e: ParseError) -> ParseDiag {
  return match e {
    ParseError.None => ParseDiag {
      kind: parse_diag_kind_none(),
      code: "",
      message: "parse error: none",
      rendered: file.concat(":1:1: parse error: none"),
    },
    ParseError.UnexpectedToken(exp, got, at) => ParseDiag {
      kind: parse_diag_kind_parse(),
      code: parse_code_parse(),
      message: parse_error_message(e),
      rendered: format_unexpected_token(file, text, exp, got, at),
    },
    ParseError.InvalidType(at, why) => ParseDiag {
      kind: parse_diag_kind_parse(),
      code: parse_code_parse(),
      message: parse_error_message(e),
      rendered: format_invalid_type(file, text, at, why),
    },
    ParseError.InvalidString(at, why) => ParseDiag {
      kind: parse_diag_kind_parse(),
      code: parse_code_parse(),
      message: parse_error_message(e),
      rendered: format_invalid_string(file, text, at, why),
    },
    ParseError.Lex(le) => ParseDiag {
      kind: parse_diag_kind_lex(),
      code: parse_code_lex(),
      message: parse_error_message(e),
      rendered: format_lex_error(file, text, le),
    },
  };
}

fn format_unexpected_token(file: String, text: String, exp: lex.TokenKind, got: lex.TokenKind, at: i32) -> String {
  let code: String = parse_code_parse();
  let lc: LineCol = pos_to_line_col(text, build_line_starts(text), at);
  return file.concat(":").concat(lc.line.to_string()).concat(":").concat(lc.col.to_string())
    .concat(": parse error: unexpected token: expected ").concat(lex.token_kind_name(exp))
    .concat(", got ").concat(lex.token_kind_name(got))
    .concat(" [").concat(code).concat("]");
}

fn format_lex_error(file: String, text: String, le: lex.LexError) -> String {
  return match le {
    lex.LexError.None => file.concat(":1:1: lex error: none"),
    lex.LexError.UnexpectedChar(at) => format_lex_unexpected_char(file, text, at),
    lex.LexError.UnterminatedString(at) => format_lex_unterminated_string(file, text, at),
  };
}

fn format_lex_unexpected_char(file: String, text: String, at: i32) -> String {
  let code: String = parse_code_lex();
  let lc: LineCol = pos_to_line_col(text, build_line_starts(text), at);
  return file.concat(":").concat(lc.line.to_string()).concat(":").concat(lc.col.to_string())
    .concat(": lex error: unexpected char [").concat(code).concat("]");
}

fn format_lex_unterminated_string(file: String, text: String, at: i32) -> String {
  let code: String = parse_code_lex();
  let lc: LineCol = pos_to_line_col(text, build_line_starts(text), at);
  return file.concat(":").concat(lc.line.to_string()).concat(":").concat(lc.col.to_string())
    .concat(": lex error: unterminated string [").concat(code).concat("]");
}

fn format_invalid_string(file: String, text: String, at: i32, why: String) -> String {
  let code: String = parse_code_parse();
  let lc: LineCol = pos_to_line_col(text, build_line_starts(text), at);
  return file.concat(":").concat(lc.line.to_string()).concat(":").concat(lc.col.to_string())
    .concat(": parse error: invalid string literal: ").concat(why)
    .concat(" [").concat(code).concat("]");
}

fn format_invalid_type(file: String, text: String, at: i32, why: String) -> String {
  let code: String = parse_code_parse();
  let lc: LineCol = pos_to_line_col(text, build_line_starts(text), at);
  return file.concat(":").concat(lc.line.to_string()).concat(":").concat(lc.col.to_string())
    .concat(": parse error: invalid type syntax: ").concat(why)
    .concat(" [").concat(code).concat("]");
}

pub struct ParseResult {
  pub prog: ast.Program,
  pub err: ParseError,
}

struct Parser {
  file: String,
  text: String,
  toks: Vec[lex.Token],
  pos: i32,
  has_err: bool,
  err: ParseError,
  exprs: ast.ExprPool,
}

struct AdvanceResult { p: Parser, tok: lex.Token }
struct ParseIdentResult { p: Parser, name: String, at: i32 }
struct ParseTypeResult { p: Parser, ty: ast.TypeName }
struct ParseExprResult { p: Parser, id: i32 }
struct ParseStmtResult { p: Parser, st: ast.Stmt }
struct ParseBlockResult { p: Parser, b: ast.Block }
struct ParseFnResult { p: Parser, f: ast.FuncDecl }
struct ParseStructResult { p: Parser, s: ast.StructDecl }
struct ParseEnumResult { p: Parser, e: ast.EnumDecl }
struct ParseTraitResult { p: Parser, t: ast.TraitDecl }
struct ParseImplResult { p: Parser, i: ast.ImplDecl }
struct ParseTraitMethodResult { p: Parser, m: ast.TraitMethodDecl }
struct ParseTraitAssocTypeResult { p: Parser, a: ast.TraitAssocTypeDecl }
struct ParseImplAssocTypeResult { p: Parser, a: ast.ImplAssocTypeBinding }
struct ParseTypeAliasResult { p: Parser, t: ast.TypeAliasDecl }
struct ParseConstResult { p: Parser, c: ast.ConstDecl }
struct ParseProgramResult { p: Parser, prog: ast.Program }
struct ParseImportResult { p: Parser, imp: ast.ImportDecl }
struct ParseStringResult { p: Parser, s: String, at: i32 }
struct ParseCharResult { p: Parser, text: String, at: i32 }
struct DecodeStringResult { ok: bool, text: String, err: String }
struct LineIndentInfo { blank: bool, has_tab_indent: bool, indent: i32 }
struct ParseImportNameResult { p: Parser, nm: ast.ImportName }
struct ParseParamsResult { p: Parser, params: Vec[ast.Param] }
struct ParseFieldResult { p: Parser, f: ast.FieldDecl }
struct ParseVariantResult { p: Parser, v: ast.EnumVariantDecl }
struct ParsePatResult { p: Parser, pat: ast.Pat }
struct ParseArmResult { p: Parser, arm: ast.MatchArm }
struct ParseTypeParamsResult { p: Parser, tps: Vec[String], tpbs: Vec[ast.TypeParamBoundsDecl] }
struct ParseFnTypeParamsResult { p: Parser, tps: Vec[String], tpps: Vec[String], cps: Vec[ast.ConstParamDecl], tpbs: Vec[ast.TypeParamBoundsDecl] }
struct ParseWhereBoundsResult { p: Parser, tpbs: Vec[ast.TypeParamBoundsDecl], cwbs: Vec[ast.ConstWhereDecl] }
struct ParseBracedExprResult { p: Parser, id: i32 }
struct ParseTypeDeclResult { p: Parser, is_union: bool, t: ast.TypeAliasDecl, e: ast.EnumDecl }
struct ParsePubResult { p: Parser, vis: i32, is_pub: bool }
struct ParseConstDefaultResult { p: Parser, ok: bool, text: String }
struct ParseTopFnAttrsResult {
  p: Parser,
  ffi_imports: Vec[ast.FfiImportAttr],
  ffi_exports: Vec[ast.FfiExportAttr],
  effects: Vec[ast.EffectAttr],
  resources: Vec[ast.ResourceAttr],
  cfgs: Vec[ast.CfgAttr],
  track_caller: bool,
  deprecated_message: String
}

fn dummy_token() -> lex.Token {
  return lex.Token { kind: lex.TokenKind.Eof, start: 0, end: 0, line: 1, col: 1 };
}

fn lex_err_none(e: lex.LexError) -> bool {
  return match e {
    lex.LexError.None => true,
    _ => false,
  };
}

fn peek(p: Parser) -> lex.Token {
  let toks: Vec[lex.Token] = p.toks;
  if p.pos < toks.len() { return toks.get(p.pos); }
  return dummy_token();
}

fn peek_kind(p: Parser) -> lex.TokenKind {
  return peek(p).kind;
}

fn peek2_kind(p: Parser) -> lex.TokenKind {
  let toks: Vec[lex.Token] = p.toks;
  let i: i32 = p.pos + 1;
  if i < toks.len() { return toks.get(i).kind; }
  return lex.TokenKind.Eof;
}

fn peek3_kind(p: Parser) -> lex.TokenKind {
  let toks: Vec[lex.Token] = p.toks;
  let i: i32 = p.pos + 2;
  if i < toks.len() { return toks.get(i).kind; }
  return lex.TokenKind.Eof;
}

fn peek4_kind(p: Parser) -> lex.TokenKind {
  let toks: Vec[lex.Token] = p.toks;
  let i: i32 = p.pos + 3;
  if i < toks.len() { return toks.get(i).kind; }
  return lex.TokenKind.Eof;
}

fn peek_ident_is(p: Parser, want: String) -> bool {
  let t: lex.Token = peek(p);
  if !kind_is(t.kind, lex.TokenKind.Ident) { return false; }
  return lexeme(p, t) == want;
}

fn peek2_ident_is(p: Parser, want: String) -> bool {
  let toks: Vec[lex.Token] = p.toks;
  let i: i32 = p.pos + 1;
  if i >= toks.len() { return false; }
  let t: lex.Token = toks.get(i);
  if !kind_is(t.kind, lex.TokenKind.Ident) { return false; }
  return lexeme(p, t) == want;
}

fn kind_is(k: lex.TokenKind, want: lex.TokenKind) -> bool {
  return lex.token_kind_eq(k, want);
}

fn is_assign_op(k: lex.TokenKind) -> bool {
  return match k {
    lex.TokenKind.Eq => true,
    lex.TokenKind.PlusEq => true,
    lex.TokenKind.MinusEq => true,
    lex.TokenKind.StarEq => true,
    lex.TokenKind.SlashEq => true,
    lex.TokenKind.PercentEq => true,
    lex.TokenKind.AmpEq => true,
    lex.TokenKind.PipeEq => true,
    lex.TokenKind.CaretEq => true,
    lex.TokenKind.LtLtEq => true,
    lex.TokenKind.GtGtEq => true,
    _ => false,
  };
}

fn assign_op_to_binary(k: lex.TokenKind) -> ast.BinaryOp {
  return match k {
    lex.TokenKind.PlusEq => ast.BinaryOp.Add,
    lex.TokenKind.MinusEq => ast.BinaryOp.Sub,
    lex.TokenKind.StarEq => ast.BinaryOp.Mul,
    lex.TokenKind.SlashEq => ast.BinaryOp.Div,
    lex.TokenKind.PercentEq => ast.BinaryOp.Mod,
    lex.TokenKind.AmpEq => ast.BinaryOp.BitAnd,
    lex.TokenKind.PipeEq => ast.BinaryOp.BitOr,
    lex.TokenKind.CaretEq => ast.BinaryOp.BitXor,
    lex.TokenKind.LtLtEq => ast.BinaryOp.Shl,
    lex.TokenKind.GtGtEq => ast.BinaryOp.Shr,
    _ => ast.BinaryOp.Add,
  };
}

fn is_field_assign_start(p: Parser) -> bool {
  if !kind_is(peek_kind(p), lex.TokenKind.Ident) { return false; }
  let toks: Vec[lex.Token] = p.toks;
  let n: i32 = toks.len();
  let mut i: i32 = p.pos + 1;
  let mut saw_field: bool = false;
  while (i + 1) < n && kind_is(toks.get(i).kind, lex.TokenKind.Dot) && kind_is(toks.get(i + 1).kind, lex.TokenKind.Ident) {
    saw_field = true;
    i = i + 2;
  }
  if !saw_field { return false; }
  if i >= n { return false; }
  return is_assign_op(toks.get(i).kind);
}

fn join_field_path(parts: Vec[String]) -> String {
  let mut out: String = "";
  let mut i: i32 = 0;
  while i < parts.len() {
    if i > 0 { out = out.concat("."); }
    out = out.concat(parts.get(i));
    i = i + 1;
  }
  return out;
}

fn advance(p: Parser) -> AdvanceResult {
  let tok: lex.Token = peek(p);
  let mut q: Parser = p;
  let toks: Vec[lex.Token] = q.toks;
  if q.pos < toks.len() { q.pos = q.pos + 1; }
  return AdvanceResult { p: q, tok: tok };
}

fn expect(p: Parser, want: lex.TokenKind) -> AdvanceResult {
  if p.has_err {
    return AdvanceResult { p: p, tok: dummy_token() };
  }
  let got: lex.TokenKind = peek_kind(p);
  if kind_is(got, want) {
    return advance(p);
  }
  let mut q: Parser = p;
  let at: i32 = peek(p).start;
  q.has_err = true;
  q.err = ParseError.UnexpectedToken(want, got, at);
  return AdvanceResult { p: q, tok: dummy_token() };
}

fn lexeme(p: Parser, t: lex.Token) -> String {
  let text: String = p.text;
  return text.slice(t.start, t.end);
}

fn parse_ident(p: Parser) -> ParseIdentResult {
  let ar: AdvanceResult = expect(p, lex.TokenKind.Ident);
  let name: String = lexeme(ar.p, ar.tok);
  return ParseIdentResult { p: ar.p, name: name, at: ar.tok.start };
}

struct ParseNameRefResult { p: Parser, name: String, at: i32 }

fn parse_name_ref_segment(p: Parser) -> ParseIdentResult {
  if kind_is(peek_kind(p), lex.TokenKind.Ident) {
    return parse_ident(p);
  }
  let ar: AdvanceResult = expect(p, lex.TokenKind.Int);
  let name: String = lexeme(ar.p, ar.tok);
  return ParseIdentResult { p: ar.p, name: name, at: ar.tok.start };
}

fn parse_name_ref(p: Parser) -> ParseNameRefResult {
  let r0: ParseIdentResult = parse_ident(p);
  let mut q: Parser = r0.p;
  let mut out: String = r0.name;
  while kind_is(peek_kind(q), lex.TokenKind.Dot) && !q.has_err {
    let ar1: AdvanceResult = advance(q);
    let r1: ParseIdentResult = parse_name_ref_segment(ar1.p);
    q = r1.p;
    out = out.concat(".").concat(r1.name);
  }
  return ParseNameRefResult { p: q, name: out, at: r0.at };
}

fn parse_range_bound_text(p: Parser) -> ParseConstDefaultResult {
  // Range bounds accept decimal int constants and char literals.
  if kind_is(peek_kind(p), lex.TokenKind.Minus) && kind_is(peek2_kind(p), lex.TokenKind.Int) {
    let ar0: AdvanceResult = advance(p);
    let ar1: AdvanceResult = expect(ar0.p, lex.TokenKind.Int);
    return ParseConstDefaultResult { p: ar1.p, ok: true, text: "-".concat(lexeme(ar1.p, ar1.tok)) };
  }
  if kind_is(peek_kind(p), lex.TokenKind.Int) {
    let ar0: AdvanceResult = advance(p);
    return ParseConstDefaultResult { p: ar0.p, ok: true, text: lexeme(ar0.p, ar0.tok) };
  }
  if kind_is(peek_kind(p), lex.TokenKind.Char) {
    let cr: ParseCharResult = parse_char_inner(p);
    return ParseConstDefaultResult { p: cr.p, ok: true, text: cr.text };
  }
  return ParseConstDefaultResult { p: p, ok: false, text: "" };
}

fn parse_type_name(p: Parser) -> ParseTypeResult {
  // Unit type: `()`
  if kind_is(peek_kind(p), lex.TokenKind.LParen) && kind_is(peek2_kind(p), lex.TokenKind.RParen) {
    let ar1: AdvanceResult = advance(p);
    let ar2: AdvanceResult = expect(ar1.p, lex.TokenKind.RParen);
    let mut parts: Vec[String] = Vec();
    parts.push("()");
    return ParseTypeResult { p: ar2.p, ty: ast.TypeName { parts: parts, args: Vec() } };
  }

  // Reference syntax sugar (transition):
  // - `&T`
  // - `&mut T`
  // - `&'static T`
  // - `&'static mut T`
  // We encode these as synthetic type names and resolve them in typecheck.
  if kind_is(peek_kind(p), lex.TokenKind.Amp) {
    let ar0: AdvanceResult = advance(p); // &
    let mut q: Parser = ar0.p;
    let mut marker: String = "@ref";
    if kind_is(peek_kind(q), lex.TokenKind.Tick) {
      let ar1: AdvanceResult = advance(q); // '
      let rl: ParseIdentResult = parse_ident(ar1.p);
      q = rl.p;
      if q.has_err {
        return ParseTypeResult { p: q, ty: ast.TypeName { parts: Vec(), args: Vec() } };
      }
      if rl.name == "static" {
        marker = "@ref_static";
      } else {
        q.has_err = true;
        q.err = ParseError.InvalidType(rl.at, "named lifetime is not supported; only 'static is allowed");
        return ParseTypeResult { p: q, ty: ast.TypeName { parts: Vec(), args: Vec() } };
      }
    }
    if kind_is(peek_kind(q), lex.TokenKind.KwMut) {
      let ar2: AdvanceResult = advance(q); // mut
      q = ar2.p;
      marker = marker.concat("_mut");
    }
    let tr: ParseTypeResult = parse_type_name(q);
    let mut partsr: Vec[String] = Vec();
    partsr.push(marker);
    let mut argsr: Vec[ast.TypeName] = Vec();
    argsr.push(tr.ty);
    return ParseTypeResult { p: tr.p, ty: ast.TypeName { parts: partsr, args: argsr } };
  }

  // Reflect type: `@field_type(T, I)`
  // Range type: `@range(lo..=hi) Base`
  // Verified type: `@verified(check_fn) Base`
  if kind_is(peek_kind(p), lex.TokenKind.At) {
    let ar0: AdvanceResult = advance(p); // @
    let rkw: ParseIdentResult = parse_ident(ar0.p);
    let mut q: Parser = rkw.p;
    if rkw.name == "field_type" {
      let ar1f: AdvanceResult = expect(q, lex.TokenKind.LParen);
      let trt: ParseTypeResult = parse_type_name(ar1f.p);
      let arcf: AdvanceResult = expect(trt.p, lex.TokenKind.Comma);
      let drf: ParseConstDefaultResult = parse_const_default_text(arcf.p);
      if !drf.ok {
        let mut qerrf: Parser = drf.p;
        qerrf.has_err = true;
        qerrf.err = ParseError.UnexpectedToken(lex.TokenKind.Int, peek_kind(drf.p), peek(drf.p).start);
        return ParseTypeResult { p: qerrf, ty: ast.TypeName { parts: Vec(), args: Vec() } };
      }
      let mut qf: Parser = drf.p;
      if kind_is(peek_kind(qf), lex.TokenKind.Comma) {
        let arx: AdvanceResult = advance(qf);
        qf = arx.p;
      }
      let ar2f: AdvanceResult = expect(qf, lex.TokenKind.RParen);
      let mut partsf: Vec[String] = Vec();
      partsf.push("@field_type");
      partsf.push(drf.text);
      let mut argsf: Vec[ast.TypeName] = Vec();
      argsf.push(trt.ty);
      return ParseTypeResult { p: ar2f.p, ty: ast.TypeName { parts: partsf, args: argsf } };
    }

    if rkw.name == "verified" {
      let ar1v: AdvanceResult = expect(q, lex.TokenKind.LParen);
      let rnv: ParseNameRefResult = parse_name_ref(ar1v.p);
      let mut qv: Parser = rnv.p;
      let namev: String = rnv.name;
      if kind_is(peek_kind(qv), lex.TokenKind.Comma) {
        let arx: AdvanceResult = advance(qv);
        qv = arx.p;
      }
      let ar2v: AdvanceResult = expect(qv, lex.TokenKind.RParen);
      let trv: ParseTypeResult = parse_type_name(ar2v.p);
      let mut partsv: Vec[String] = Vec();
      partsv.push("@verified");
      partsv.push(namev);
      let mut argsv: Vec[ast.TypeName] = Vec();
      argsv.push(trv.ty);
      return ParseTypeResult { p: trv.p, ty: ast.TypeName { parts: partsv, args: argsv } };
    }

    if rkw.name != "range" {
      q.has_err = true;
      q.err = ParseError.UnexpectedToken(lex.TokenKind.Ident, peek_kind(q), rkw.at);
      return ParseTypeResult { p: q, ty: ast.TypeName { parts: Vec(), args: Vec() } };
    }
    let ar1: AdvanceResult = expect(q, lex.TokenKind.LParen);
    let lo_r: ParseConstDefaultResult = parse_range_bound_text(ar1.p);
    if !lo_r.ok {
      let mut qerr: Parser = lo_r.p;
      qerr.has_err = true;
      qerr.err = ParseError.InvalidType(peek(lo_r.p).start, "expected integer or char literal for range bound");
      return ParseTypeResult { p: qerr, ty: ast.TypeName { parts: Vec(), args: Vec() } };
    }
    let lo_s: String = lo_r.text;
    let ardd: AdvanceResult = expect(lo_r.p, lex.TokenKind.DotDotEq);
    let hi_r: ParseConstDefaultResult = parse_range_bound_text(ardd.p);
    if !hi_r.ok {
      let mut qerr: Parser = hi_r.p;
      qerr.has_err = true;
      qerr.err = ParseError.InvalidType(peek(hi_r.p).start, "expected integer or char literal for range bound");
      return ParseTypeResult { p: qerr, ty: ast.TypeName { parts: Vec(), args: Vec() } };
    }
    let hi_s: String = hi_r.text;
    let ar2: AdvanceResult = expect(hi_r.p, lex.TokenKind.RParen);
    let trb: ParseTypeResult = parse_type_name(ar2.p);
    let mut parts: Vec[String] = Vec();
    parts.push("@range");
    parts.push(lo_s);
    parts.push(hi_s);
    let mut args: Vec[ast.TypeName] = Vec();
    args.push(trb.ty);
    return ParseTypeResult { p: trb.p, ty: ast.TypeName { parts: parts, args: args } };
  }

  let r0: ParseIdentResult = parse_ident(p);
  let mut q: Parser = r0.p;
  let mut parts: Vec[String] = Vec();
  parts.push(r0.name);
  while kind_is(peek_kind(q), lex.TokenKind.Dot) && !q.has_err {
    let ar1: AdvanceResult = advance(q);
    let r2: ParseIdentResult = parse_name_ref_segment(ar1.p);
    q = r2.p;
    parts.push(r2.name);
  }

  let mut args: Vec[ast.TypeName] = Vec();
  if kind_is(peek_kind(q), lex.TokenKind.LBracket) {
    let ar3: AdvanceResult = advance(q);
    q = ar3.p;
    if !kind_is(peek_kind(q), lex.TokenKind.RBracket) {
      while !q.has_err {
        let tr: ParseTypeResult = parse_type_name(q);
        q = tr.p;
        args.push(tr.ty);
        if kind_is(peek_kind(q), lex.TokenKind.Comma) {
          let ar4: AdvanceResult = advance(q);
          q = ar4.p;
          if kind_is(peek_kind(q), lex.TokenKind.RBracket) {
            break;
          }
          continue;
        }
        break;
      }
    }
    let ar5: AdvanceResult = expect(q, lex.TokenKind.RBracket);
    q = ar5.p;
  }
  return ParseTypeResult { p: q, ty: ast.TypeName { parts: parts, args: args } };
}

fn add_expr(p: Parser, sp: ast.Span, node: ast.ExprNode) -> ParseExprResult {
  let r: ast.AddExprResult = ast.expr_pool_add(p.exprs, node, sp);
  let mut q: Parser = p;
  q.exprs = r.pool;
  return ParseExprResult { p: q, id: r.id };
}

fn str_is_triple_quoted(lit: String) -> bool {
  return lit.len() >= 6 && lit.slice(0, 3) == "\"\"\"" && lit.slice(lit.len() - 3, lit.len()) == "\"\"\"";
}

fn normalize_newlines(s0: String) -> String {
  let mut out: String = "";
  let mut i: i32 = 0;
  while i < s0.len() {
    let b: i32 = s0.byte_at(i);
    if b == 13 { // \r
      if (i + 1) < s0.len() && s0.byte_at(i + 1) == 10 {
        i = i + 2;
      } else {
        i = i + 1;
      }
      out = out.concat("\n");
      continue;
    }
    out = out.concat(s0.slice(i, i + 1));
    i = i + 1;
  }
  return out;
}

fn split_lines_keep_empty(s: String) -> Vec[String] {
  let mut out: Vec[String] = Vec();
  let mut cur: String = "";
  let mut i: i32 = 0;
  while i < s.len() {
    let b: i32 = s.byte_at(i);
    if b == 10 {
      out.push(cur);
      cur = "";
      i = i + 1;
      continue;
    }
    cur = cur.concat(s.slice(i, i + 1));
    i = i + 1;
  }
  out.push(cur);
  return out;
}

fn join_lines(ls: Vec[String]) -> String {
  let mut out: String = "";
  let mut i: i32 = 0;
  while i < ls.len() {
    if i > 0 { out = out.concat("\n"); }
    out = out.concat(ls.get(i));
    i = i + 1;
  }
  return out;
}

fn trim_one_trailing_empty_line(ls: Vec[String]) -> Vec[String] {
  if ls.len() == 0 { return ls; }
  if ls.get(ls.len() - 1) != "" { return ls; }
  let mut out: Vec[String] = Vec();
  let mut i: i32 = 0;
  while i < (ls.len() - 1) {
    out.push(ls.get(i));
    i = i + 1;
  }
  return out;
}

fn line_indent_info(line: String) -> LineIndentInfo {
  let mut i: i32 = 0;
  while i < line.len() {
    let b: i32 = line.byte_at(i);
    if b == 32 { // space
      i = i + 1;
      continue;
    }
    if b == 9 { // tab
      return LineIndentInfo { blank: false, has_tab_indent: true, indent: i };
    }
    return LineIndentInfo { blank: false, has_tab_indent: false, indent: i };
  }
  return LineIndentInfo { blank: true, has_tab_indent: false, indent: 0 };
}

fn unescape_relaxed(s: String) -> DecodeStringResult {
  let mut out: String = "";
  let mut i: i32 = 0;
  while i < s.len() {
    let b: i32 = s.byte_at(i);
    if b == 92 { // '\\'
      if (i + 1) < s.len() {
        let nb: i32 = s.byte_at(i + 1);
        if nb == 110 { out = out.concat("\n"); i = i + 2; continue; } // n
        if nb == 114 { out = out.concat("\r"); i = i + 2; continue; } // r
        if nb == 116 { out = out.concat("\t"); i = i + 2; continue; } // t
        if nb == 34 { out = out.concat("\""); i = i + 2; continue; }  // "
        if nb == 92 { out = out.concat("\\"); i = i + 2; continue; }  // \
        // Backward-compatible: unknown escape drops '\' and keeps char.
        out = out.concat(s.slice(i + 1, i + 2));
        i = i + 2;
        continue;
      }
      out = out.concat("\\");
      i = i + 1;
      continue;
    }
    out = out.concat(s.slice(i, i + 1));
    i = i + 1;
  }
  return DecodeStringResult { ok: true, text: out, err: "" };
}

fn decode_char_lit_relaxed(lit: String) -> String {
  // Expected source forms:
  //   'a' '\n' '\'' 'ä½ '
  if lit.len() < 3 { return "0"; }
  let s: String = lit.slice(1, lit.len() - 1);
  if s.len() == 0 { return "0"; }

  if s.byte_at(0) == 92 { // '\'
    if s.len() < 2 { return "92"; }
    let e: i32 = s.byte_at(1);
    if e == 110 { return "10"; } // n
    if e == 114 { return "13"; } // r
    if e == 116 { return "9"; }  // t
    if e == 48 { return "0"; }   // 0
    if e == 39 { return "39"; }  // '
    if e == 34 { return "34"; }  // "
    if e == 92 { return "92"; }  // \
    // Backward-compatible: unknown escape keeps escaped byte.
    return e.to_string();
  }

  let b0: i32 = s.byte_at(0);
  if b0 <= 127 { return b0.to_string(); }
  if b0 >= 194 && b0 <= 223 && s.len() >= 2 && is_utf8_cont_byte(s.byte_at(1)) {
    let cp: i32 = ((b0 & 31) << 6) | (s.byte_at(1) & 63);
    return cp.to_string();
  }
  if b0 >= 224 && b0 <= 239 && s.len() >= 3 && is_utf8_cont_byte(s.byte_at(1)) && is_utf8_cont_byte(s.byte_at(2)) {
    let cp: i32 = ((b0 & 15) << 12) | ((s.byte_at(1) & 63) << 6) | (s.byte_at(2) & 63);
    return cp.to_string();
  }
  if b0 >= 240 && b0 <= 244 && s.len() >= 4 && is_utf8_cont_byte(s.byte_at(1)) && is_utf8_cont_byte(s.byte_at(2)) && is_utf8_cont_byte(s.byte_at(3)) {
    let cp: i32 = ((b0 & 7) << 18) | ((s.byte_at(1) & 63) << 12) | ((s.byte_at(2) & 63) << 6) | (s.byte_at(3) & 63);
    return cp.to_string();
  }

  return b0.to_string();
}

fn decode_string_lit(lit: String) -> DecodeStringResult {
  if !str_is_triple_quoted(lit) {
    let mut s0: String = lit;
    let n0: i32 = s0.len();
    if n0 >= 2 { s0 = s0.slice(1, n0 - 1); }
    return unescape_relaxed(s0);
  }

  let mut body: String = lit.slice(3, lit.len() - 3);
  body = normalize_newlines(body);
  if body.len() > 0 && body.byte_at(0) == 10 {
    body = body.slice(1, body.len());
  }

  let mut lines: Vec[String] = split_lines_keep_empty(body);
  lines = trim_one_trailing_empty_line(lines);

  let mut min_indent: i32 = -1;
  let mut i: i32 = 0;
  while i < lines.len() {
    let inf: LineIndentInfo = line_indent_info(lines.get(i));
    if inf.has_tab_indent {
      return DecodeStringResult { ok: false, text: "", err: "tab indentation is not allowed in multiline string" };
    }
    if !inf.blank {
      if min_indent == -1 || inf.indent < min_indent { min_indent = inf.indent; }
    }
    i = i + 1;
  }
  if min_indent < 0 {
    return DecodeStringResult { ok: true, text: "", err: "" };
  }

  let mut norm: Vec[String] = Vec();
  let mut j: i32 = 0;
  while j < lines.len() {
    let ln: String = lines.get(j);
    let inf2: LineIndentInfo = line_indent_info(ln);
    if inf2.has_tab_indent {
      return DecodeStringResult { ok: false, text: "", err: "tab indentation is not allowed in multiline string" };
    }
    if inf2.blank {
      norm.push("");
    } else if ln.len() <= min_indent {
      norm.push("");
    } else {
      norm.push(ln.slice(min_indent, ln.len()));
    }
    j = j + 1;
  }

  return unescape_relaxed(join_lines(norm));
}

fn parse_string_inner(p: Parser) -> ParseStringResult {
  let ar: AdvanceResult = expect(p, lex.TokenKind.Str);
  let at: i32 = ar.tok.start;
  let d: DecodeStringResult = decode_string_lit(lexeme(ar.p, ar.tok));
  if !d.ok {
    let mut q: Parser = ar.p;
    q.has_err = true;
    q.err = ParseError.InvalidString(at, d.err);
    return ParseStringResult { p: q, s: "", at: at };
  }
  return ParseStringResult { p: ar.p, s: d.text, at: at };
}

fn parse_char_inner(p: Parser) -> ParseCharResult {
  let ar: AdvanceResult = expect(p, lex.TokenKind.Char);
  let at: i32 = ar.tok.start;
  let lit: String = lexeme(ar.p, ar.tok);
  return ParseCharResult { p: ar.p, text: decode_char_lit_relaxed(lit), at: at };
}

fn parse_import_name(p: Parser) -> ParseImportNameResult {
  let sp_name: ast.Span = span_tok(p, peek(p));
  let r0: ParseIdentResult = parse_ident(p);
  let mut q: Parser = r0.p;
  let mut alias: String = "";
  if kind_is(peek_kind(q), lex.TokenKind.KwAs) {
    let ar1: AdvanceResult = advance(q);
    let r2: ParseIdentResult = parse_ident(ar1.p);
    q = r2.p;
    alias = r2.name;
  }
  return ParseImportNameResult { p: q, nm: ast.ImportName { name: r0.name, alias: alias, sp: sp_name } };
}

fn parse_import_decl(p: Parser) -> ParseImportResult {
  let ar1: AdvanceResult = expect(p, lex.TokenKind.KwImport);
  let dsp: ast.Span = span_tok(p, ar1.tok);

  // Named imports: `import { a, b as c } from "path"`
  if kind_is(peek_kind(ar1.p), lex.TokenKind.LBrace) {
    let ar2: AdvanceResult = advance(ar1.p);
    let mut q: Parser = ar2.p;
    let mut names: Vec[ast.ImportName] = Vec();
    if !kind_is(peek_kind(q), lex.TokenKind.RBrace) {
      while !q.has_err {
        let nr: ParseImportNameResult = parse_import_name(q);
        q = nr.p;
        names.push(nr.nm);
        if kind_is(peek_kind(q), lex.TokenKind.Comma) {
          let ar3: AdvanceResult = advance(q);
          q = ar3.p;
          if kind_is(peek_kind(q), lex.TokenKind.RBrace) {
            break;
          }
          continue;
        }
        break;
      }
    }
    let ar4: AdvanceResult = expect(q, lex.TokenKind.RBrace);
    let ar5: AdvanceResult = expect(ar4.p, lex.TokenKind.KwFrom);
    let r6: ParseStringResult = parse_string_inner(ar5.p);
    return ParseImportResult { p: r6.p, imp: ast.ImportDecl { file: p.file, sp: dsp, path: r6.s, alias: "", names: names } };
  }

  // Module import: `import "path" as alias`
  let r2: ParseStringResult = parse_string_inner(ar1.p);
  let mut q: Parser = r2.p;
  let path: String = r2.s;
  let mut alias: String = "";
  if kind_is(peek_kind(q), lex.TokenKind.KwAs) {
    let ar3: AdvanceResult = advance(q);
    let r4: ParseIdentResult = parse_ident(ar3.p);
    q = r4.p;
    alias = r4.name;
  }
  return ParseImportResult { p: q, imp: ast.ImportDecl { file: p.file, sp: dsp, path: path, alias: alias, names: Vec() } };
}

fn parse_braced_expr(p: Parser) -> ParseBracedExprResult {
  // Back-compat helper used by if-expr parsing; now parses a full block expression.
  let r: ParseExprResult = parse_expr_block(p);
  return ParseBracedExprResult { p: r.p, id: r.id };
}

fn if_expr_has_else_ahead(p: Parser) -> bool {
  // Look ahead to see if this `if` is syntactically an if-expression (has an `else`
  // immediately after its then-branch). This is used to disambiguate `if` inside
  // expression blocks so `{ if cond { a } else { b } }` parses as a block tail expression,
  // while still allowing statement `if` without `else`.
  if !kind_is(peek_kind(p), lex.TokenKind.KwIf) { return false; }
  let toks: Vec[lex.Token] = p.toks;
  let mut i: i32 = p.pos + 1;
  let mut dp: i32 = 0; // ()
  let mut db: i32 = 0; // []
  let mut dc: i32 = 0; // {} inside condition
  let mut then_i: i32 = -1;

  while i < toks.len() {
    let k: lex.TokenKind = toks.get(i).kind;
    if kind_is(k, lex.TokenKind.Eof) { return false; }
    if kind_is(k, lex.TokenKind.LParen) { dp = dp + 1; }
    else if kind_is(k, lex.TokenKind.RParen) { if dp > 0 { dp = dp - 1; } }
    else if kind_is(k, lex.TokenKind.LBracket) { db = db + 1; }
    else if kind_is(k, lex.TokenKind.RBracket) { if db > 0 { db = db - 1; } }
    else if kind_is(k, lex.TokenKind.LBrace) {
      if dp == 0 && db == 0 && dc == 0 { then_i = i; break; }
      dc = dc + 1;
    } else if kind_is(k, lex.TokenKind.RBrace) {
      if dc > 0 { dc = dc - 1; }
    }
    i = i + 1;
  }
  if then_i == -1 { return false; }

  // Match the then-branch `{ ... }`.
  i = then_i + 1;
  let mut brace: i32 = 1;
  while i < toks.len() {
    let k2: lex.TokenKind = toks.get(i).kind;
    if kind_is(k2, lex.TokenKind.Eof) { return false; }
    if kind_is(k2, lex.TokenKind.LBrace) { brace = brace + 1; }
    else if kind_is(k2, lex.TokenKind.RBrace) {
      brace = brace - 1;
      if brace == 0 { i = i + 1; break; }
    }
    i = i + 1;
  }
  if brace != 0 { return false; }
  return i < toks.len() && kind_is(toks.get(i).kind, lex.TokenKind.KwElse);
}

fn parse_expr_block(p: Parser) -> ParseExprResult {
  // `{ stmt*; tailExpr }` where tailExpr is optional (missing => unit).
  let ar1: AdvanceResult = expect(p, lex.TokenKind.LBrace);
  let mut q: Parser = ar1.p;
  let sp0: ast.Span = span_tok(p, ar1.tok);
  let mut stmts: Vec[ast.Stmt] = Vec();
  let mut has_tail: bool = false;
  let mut tail: i32 = -1;

  while !q.has_err && !kind_is(peek_kind(q), lex.TokenKind.RBrace) && !kind_is(peek_kind(q), lex.TokenKind.Eof) {
    let k: lex.TokenKind = peek_kind(q);

    let is_stmt: bool =
      kind_is(k, lex.TokenKind.KwLet) ||
      (kind_is(k, lex.TokenKind.KwIf) && !if_expr_has_else_ahead(q)) ||
      kind_is(k, lex.TokenKind.KwFor) ||
      kind_is(k, lex.TokenKind.KwWhile) ||
      kind_is(k, lex.TokenKind.KwLoop) ||
      kind_is(k, lex.TokenKind.KwBreak) ||
      kind_is(k, lex.TokenKind.KwContinue) ||
      kind_is(k, lex.TokenKind.KwReturn) ||
      // assignment: ident <assign-op> ...
      (kind_is(k, lex.TokenKind.Ident) && is_assign_op(peek2_kind(q))) ||
      // field assignment: ident(.ident)+ <assign-op> ...
      is_field_assign_start(q);

    if is_stmt {
      let sr: ParseStmtResult = parse_stmt(q);
      q = sr.p;
      stmts.push(sr.st);
      continue;
    }

    let er: ParseExprResult = parse_expr(q, 0);
    q = er.p;
    if q.has_err {
      return ParseExprResult { p: q, id: -1 };
    }
    if kind_is(peek_kind(q), lex.TokenKind.Semicolon) {
      let ar2: AdvanceResult = advance(q);
      q = ar2.p;
      stmts.push(ast.Stmt.ExprStmt(span_expr(q.exprs, er.id), er.id));
      continue;
    }
    has_tail = true;
    tail = er.id;
    break;
  }

  let ar3: AdvanceResult = expect(q, lex.TokenKind.RBrace);
  let b: ast.ExprBlock = ast.ExprBlock { stmts: stmts, has_tail: has_tail, tail: tail };
  return add_expr(ar3.p, sp0, ast.ExprNode.Block(b));
}

fn parse_if_expr(p: Parser) -> ParseExprResult {
  // if <cond> { <expr> } else { <expr> }
  let ar1: AdvanceResult = expect(p, lex.TokenKind.KwIf);
  let sp0: ast.Span = span_tok(p, ar1.tok);
  let r2: ParseExprResult = parse_expr(ar1.p, 0);
  let br1: ParseBracedExprResult = parse_braced_expr(r2.p);
  let ar3: AdvanceResult = expect(br1.p, lex.TokenKind.KwElse);

  // else if ...  ==> else { if ... } (AST nests If)
  if kind_is(peek_kind(ar3.p), lex.TokenKind.KwIf) {
    let r4: ParseExprResult = parse_if_expr(ar3.p);
    return add_expr(r4.p, sp0, ast.ExprNode.If(r2.id, br1.id, r4.id));
  }
  let br2: ParseBracedExprResult = parse_braced_expr(ar3.p);
  return add_expr(br2.p, sp0, ast.ExprNode.If(r2.id, br1.id, br2.id));
}

fn is_reflect_intrinsic_name(iname: String, is_compile_error: bool) -> bool {
  return is_compile_error ||
    iname == "size_of" ||
    iname == "align_of" ||
    iname == "type" ||
    iname == "type_name" ||
    iname == "target_os" ||
    iname == "target_arch" ||
    iname == "target_ptr_bits" ||
    iname == "field_count" ||
    iname == "field_name" ||
    iname == "field_type" ||
    iname == "field_type_id" ||
    iname == "same_type" ||
    iname == "assignable_to" ||
    iname == "castable_to" ||
    iname == "eq_comparable_with" ||
    iname == "ordered_with" ||
    iname == "same_layout" ||
    iname == "bitcastable" ||
    iname == "is_integer" ||
    iname == "is_signed_int" ||
    iname == "is_unsigned_int" ||
    iname == "is_float" ||
    iname == "is_bool" ||
    iname == "is_string" ||
    iname == "is_struct" ||
    iname == "is_enum" ||
    iname == "is_vec" ||
    iname == "is_range" ||
    iname == "is_eq_comparable" ||
    iname == "is_ordered" ||
    iname == "is_unit" ||
    iname == "is_numeric" ||
    iname == "is_zero_sized";
}

fn parse_reflect_intrinsic_primary(p: Parser) -> ParseExprResult {
  let ar0: AdvanceResult = expect(p, lex.TokenKind.At);
  let sp0: ast.Span = span_tok(p, ar0.tok);
  let mut qname: Parser = ar0.p;
  let mut iname: String = "";
  let mut iname_at: i32 = peek(qname).start;
  if kind_is(peek_kind(qname), lex.TokenKind.Ident) {
    let rname: ParseIdentResult = parse_ident(qname);
    qname = rname.p;
    iname = rname.name;
    iname_at = rname.at;
  } else if kind_is(peek_kind(qname), lex.TokenKind.KwType) {
    let ar_kw: AdvanceResult = advance(qname);
    qname = ar_kw.p;
    iname = "type";
    iname_at = ar_kw.tok.start;
  } else {
    let mut qerr0: Parser = qname;
    qerr0.has_err = true;
    qerr0.err = ParseError.UnexpectedToken(lex.TokenKind.Ident, peek_kind(qname), peek(qname).start);
    return ParseExprResult { p: qerr0, id: -1 };
  }

  let is_compile_error: bool = iname == "compile_error";
  if !is_reflect_intrinsic_name(iname, is_compile_error) {
    let mut q0: Parser = qname;
    q0.has_err = true;
    q0.err = ParseError.UnexpectedToken(lex.TokenKind.Ident, peek_kind(qname), iname_at);
    return ParseExprResult { p: q0, id: -1 };
  }

  let ar1: AdvanceResult = expect(qname, lex.TokenKind.LParen);
  let is_target_intrinsic: bool = iname == "target_os" || iname == "target_arch" || iname == "target_ptr_bits";
  if is_compile_error {
    let er: ParseExprResult = parse_expr(ar1.p, 0);
    if er.p.has_err { return er; }
    let mut q2c: Parser = er.p;
    if kind_is(peek_kind(q2c), lex.TokenKind.Comma) {
      let arx: AdvanceResult = advance(q2c);
      q2c = arx.p;
    }
    let ar2c: AdvanceResult = expect(q2c, lex.TokenKind.RParen);
    let idc: ParseExprResult = add_expr(ar2c.p, sp0, ast.ExprNode.Ident("@".concat(iname)));
    if idc.p.has_err { return idc; }
    let mut args0: Vec[i32] = Vec();
    args0.push(er.id);
    return add_expr(idc.p, sp0, ast.ExprNode.Call(idc.id, Vec(), args0));
  }

  if is_target_intrinsic {
    let mut q2z: Parser = ar1.p;
    if kind_is(peek_kind(q2z), lex.TokenKind.Comma) {
      let arc: AdvanceResult = advance(q2z);
      q2z = arc.p;
    }
    let ar2z: AdvanceResult = expect(q2z, lex.TokenKind.RParen);
    let idz: ParseExprResult = add_expr(ar2z.p, sp0, ast.ExprNode.Ident("@".concat(iname)));
    if idz.p.has_err { return idz; }
    return add_expr(idz.p, sp0, ast.ExprNode.Call(idz.id, Vec(), Vec()));
  }

  let tr: ParseTypeResult = parse_type_name(ar1.p);
  let mut q2: Parser = tr.p;
  let mut targs: Vec[ast.TypeName] = Vec();
  targs.push(tr.ty);
  if iname == "field_name" || iname == "field_type" || iname == "field_type_id" {
    let arx: AdvanceResult = expect(q2, lex.TokenKind.Comma);
    q2 = arx.p;
    let dr: ParseConstDefaultResult = parse_const_default_text(q2);
    if !dr.ok {
      let mut qerr: Parser = dr.p;
      qerr.has_err = true;
      qerr.err = ParseError.UnexpectedToken(lex.TokenKind.Int, peek_kind(dr.p), peek(dr.p).start);
      return ParseExprResult { p: qerr, id: -1 };
    }
    q2 = dr.p;
    targs.push(const_generic_arg_tn(dr.text));
  } else if iname == "same_type" || iname == "assignable_to" || iname == "castable_to" || iname == "eq_comparable_with" || iname == "ordered_with" || iname == "same_layout" || iname == "bitcastable" {
    let arx2: AdvanceResult = expect(q2, lex.TokenKind.Comma);
    q2 = arx2.p;
    let tr2: ParseTypeResult = parse_type_name(q2);
    q2 = tr2.p;
    targs.push(tr2.ty);
  }
  if kind_is(peek_kind(q2), lex.TokenKind.Comma) {
    let arx3: AdvanceResult = advance(q2);
    q2 = arx3.p;
  }
  let ar2: AdvanceResult = expect(q2, lex.TokenKind.RParen);

  let idr: ParseExprResult = add_expr(ar2.p, sp0, ast.ExprNode.Ident("@".concat(iname)));
  if idr.p.has_err { return idr; }
  return add_expr(idr.p, sp0, ast.ExprNode.Call(idr.id, targs, Vec()));
}

fn parse_quote_expr_primary(p: Parser) -> ParseExprResult {
  // `quote expr { ... }` is surface sugar lowered to `quote!(...)`.
  let ar0: AdvanceResult = expect(p, lex.TokenKind.Ident); // quote
  let sp0: ast.Span = span_tok(p, ar0.tok);
  let ar1: AdvanceResult = expect(ar0.p, lex.TokenKind.Ident); // expr
  let ar2: AdvanceResult = expect(ar1.p, lex.TokenKind.LBrace);
  let er: ParseExprResult = parse_expr(ar2.p, 0);
  if er.p.has_err { return er; }
  let ar3: AdvanceResult = expect(er.p, lex.TokenKind.RBrace);
  let idq: ParseExprResult = add_expr(ar3.p, sp0, ast.ExprNode.Ident("quote"));
  if idq.p.has_err { return idq; }
  let mut args: Vec[i32] = Vec();
  args.push(er.id);
  return add_expr(idq.p, sp0, ast.ExprNode.MacroCall(idq.id, Vec(), args));
}

fn parse_primary(p: Parser) -> ParseExprResult {
  if p.has_err {
    return ParseExprResult { p: p, id: -1 };
  }
  let k: lex.TokenKind = peek_kind(p);

  if kind_is(k, lex.TokenKind.Int) {
    let ar: AdvanceResult = advance(p);
    let tok: lex.Token = ar.tok;
    return add_expr(ar.p, span_tok(p, tok), ast.ExprNode.Int(lexeme(ar.p, tok)));
  }

  if kind_is(k, lex.TokenKind.Float) {
    let ar: AdvanceResult = advance(p);
    let tok: lex.Token = ar.tok;
    return add_expr(ar.p, span_tok(p, tok), ast.ExprNode.Float(lexeme(ar.p, tok)));
  }

  if kind_is(k, lex.TokenKind.Char) {
    let sp0: ast.Span = span_tok(p, peek(p));
    let r: ParseCharResult = parse_char_inner(p);
    return add_expr(r.p, sp0, ast.ExprNode.Int(r.text));
  }

  if kind_is(k, lex.TokenKind.KwTrue) {
    let ar: AdvanceResult = advance(p);
    return add_expr(ar.p, span_tok(p, ar.tok), ast.ExprNode.Bool(true));
  }
  if kind_is(k, lex.TokenKind.KwFalse) {
    let ar: AdvanceResult = advance(p);
    return add_expr(ar.p, span_tok(p, ar.tok), ast.ExprNode.Bool(false));
  }

  // Surface quote syntax:
  //   quote expr { ... }
  if kind_is(k, lex.TokenKind.Ident) &&
    peek_ident_is(p, "quote") &&
    peek2_ident_is(p, "expr") &&
    kind_is(peek3_kind(p), lex.TokenKind.LBrace) {
    return parse_quote_expr_primary(p);
  }

  if kind_is(k, lex.TokenKind.Ident) {
    let sp0: ast.Span = span_tok(p, peek(p));
    let r: ParseIdentResult = parse_ident(p);
    return add_expr(r.p, sp0, ast.ExprNode.Ident(r.name));
  }

  if kind_is(k, lex.TokenKind.At) {
    return parse_reflect_intrinsic_primary(p);
  }

  // Enum variant shorthand: `.Variant`
  if kind_is(k, lex.TokenKind.Dot) {
    let ar: AdvanceResult = advance(p);
    let sp0: ast.Span = span_tok(p, ar.tok);
    let r: ParseIdentResult = parse_ident(ar.p);
    return add_expr(r.p, sp0, ast.ExprNode.DotIdent(r.name));
  }

  if kind_is(k, lex.TokenKind.Str) {
    let sp0: ast.Span = span_tok(p, peek(p));
    let r: ParseStringResult = parse_string_inner(p);
    return add_expr(r.p, sp0, ast.ExprNode.Str(r.s));
  }

  if kind_is(k, lex.TokenKind.KwMatch) {
    let ar1: AdvanceResult = advance(p);
    let sp0: ast.Span = span_tok(p, ar1.tok);
    let r2: ParseExprResult = parse_expr(ar1.p, 0);
    let ar3: AdvanceResult = expect(r2.p, lex.TokenKind.LBrace);
    let mut q: Parser = ar3.p;
    let mut arms: Vec[ast.MatchArm] = Vec();
    while !q.has_err && !kind_is(peek_kind(q), lex.TokenKind.RBrace) && !kind_is(peek_kind(q), lex.TokenKind.Eof) {
      let pr: ParsePatResult = parse_pat(q);
      let ar4: AdvanceResult = expect(pr.p, lex.TokenKind.FatArrow);
      let er: ParseExprResult = parse_expr(ar4.p, 0);
      q = er.p;
      arms.push(ast.MatchArm { pat: pr.pat, expr: er.id });
      if kind_is(peek_kind(q), lex.TokenKind.Comma) {
        let ar5: AdvanceResult = advance(q);
        q = ar5.p;
        continue;
      }
      break;
    }
    let ar6: AdvanceResult = expect(q, lex.TokenKind.RBrace);
    return add_expr(ar6.p, sp0, ast.ExprNode.Match(r2.id, arms));
  }

  if kind_is(k, lex.TokenKind.KwIf) {
    return parse_if_expr(p);
  }

  if kind_is(k, lex.TokenKind.KwTry) {
    let ar1: AdvanceResult = advance(p);
    if !kind_is(peek_kind(ar1.p), lex.TokenKind.LBrace) {
      let mut q: Parser = ar1.p;
      q.has_err = true;
      q.err = ParseError.UnexpectedToken(lex.TokenKind.LBrace, peek_kind(ar1.p), peek(ar1.p).start);
      return ParseExprResult { p: q, id: -1 };
    }
    let br: ParseExprResult = parse_expr_block(ar1.p);
    if br.p.has_err { return br; }
    let sp0: ast.Span = span_tok(p, ar1.tok);
    return add_expr(br.p, sp0, ast.ExprNode.TryBlock(br.id));
  }

  if kind_is(k, lex.TokenKind.LBrace) {
    return parse_expr_block(p);
  }

  let mut q: Parser = p;
  let at: i32 = peek(p).start;
  q.has_err = true;
  q.err = ParseError.UnexpectedToken(lex.TokenKind.Ident, k, at);
  return ParseExprResult { p: q, id: -1 };
}

fn const_generic_arg_tn(text: String) -> ast.TypeName {
  let mut parts: Vec[String] = Vec();
  parts.push("@const");
  parts.push(text);
  return ast.TypeName { parts: parts, args: Vec() };
}

fn parse_const_default_text(p: Parser) -> ParseConstDefaultResult {
  if kind_is(peek_kind(p), lex.TokenKind.Minus) && kind_is(peek2_kind(p), lex.TokenKind.Int) {
    let ar0: AdvanceResult = advance(p);
    let ar1: AdvanceResult = expect(ar0.p, lex.TokenKind.Int);
    return ParseConstDefaultResult { p: ar1.p, ok: true, text: "-".concat(lexeme(ar1.p, ar1.tok)) };
  }
  if kind_is(peek_kind(p), lex.TokenKind.Int) {
    let ar0: AdvanceResult = advance(p);
    return ParseConstDefaultResult { p: ar0.p, ok: true, text: lexeme(ar0.p, ar0.tok) };
  }
  return ParseConstDefaultResult { p: p, ok: false, text: "" };
}

fn parse_generic_call_arg(p: Parser) -> ParseTypeResult {
  // Generic call args support:
  // - type args: `T`, `Vec[i32]`, ...
  // - const int args: `3`, `-5` (encoded as pseudo type `@const`)
  if kind_is(peek_kind(p), lex.TokenKind.Minus) && kind_is(peek2_kind(p), lex.TokenKind.Int) {
    let ar0: AdvanceResult = advance(p);
    let ar1: AdvanceResult = expect(ar0.p, lex.TokenKind.Int);
    let text: String = "-".concat(lexeme(ar1.p, ar1.tok));
    return ParseTypeResult { p: ar1.p, ty: const_generic_arg_tn(text) };
  }
  if kind_is(peek_kind(p), lex.TokenKind.Int) {
    let ar0: AdvanceResult = advance(p);
    let text: String = lexeme(ar0.p, ar0.tok);
    return ParseTypeResult { p: ar0.p, ty: const_generic_arg_tn(text) };
  }
  return parse_type_name(p);
}

fn parse_postfix(p: Parser, base: i32) -> ParseExprResult {
  let mut q: Parser = p;
  let mut cur: i32 = base;
  let mut pending_targs: Vec[ast.TypeName] = Vec();
  while !q.has_err {
    // Struct literal: `TypePath { field: expr, ... }`
    //
    // Ambiguity note: blocks also start with `{`. We only parse a struct literal
    // when the first field looks like `ident :` (i.e. `{ Ident Colon ... }`).
    if kind_is(peek_kind(q), lex.TokenKind.LBrace) &&
      kind_is(peek2_kind(q), lex.TokenKind.Ident) &&
      kind_is(peek3_kind(q), lex.TokenKind.Colon) {
      if pending_targs.len() != 0 {
        let sp_t: ast.Span = span_expr(q.exprs, cur);
        let r_t: ParseExprResult = add_expr(q, sp_t, ast.ExprNode.Call(cur, pending_targs, Vec()));
        q = r_t.p;
        cur = r_t.id;
        pending_targs = Vec();
      }
      let sp0: ast.Span = span_expr(q.exprs, cur);
      let ar1: AdvanceResult = advance(q);
      let mut r: Parser = ar1.p;
      let mut fields: Vec[ast.StructLitField] = Vec();
      while !r.has_err && !kind_is(peek_kind(r), lex.TokenKind.RBrace) && !kind_is(peek_kind(r), lex.TokenKind.Eof) {
        let fr: ParseIdentResult = parse_ident(r);
        let ar2: AdvanceResult = expect(fr.p, lex.TokenKind.Colon);
        let er: ParseExprResult = parse_expr(ar2.p, 0);
        r = er.p;
        fields.push(ast.StructLitField { name: fr.name, expr: er.id });
        if kind_is(peek_kind(r), lex.TokenKind.Comma) {
          let ar3: AdvanceResult = advance(r);
          r = ar3.p;
          if kind_is(peek_kind(r), lex.TokenKind.RBrace) {
            break;
          }
          continue;
        }
        break;
      }
      let ar4: AdvanceResult = expect(r, lex.TokenKind.RBrace);
      let r5: ParseExprResult = add_expr(ar4.p, sp0, ast.ExprNode.StructLit(cur, fields));
      q = r5.p;
      cur = r5.id;
      continue;
    }
    if kind_is(peek_kind(q), lex.TokenKind.Dot) {
      let sp0: ast.Span = span_expr(q.exprs, cur);
      if pending_targs.len() != 0 {
        let r_t: ParseExprResult = add_expr(q, sp0, ast.ExprNode.Call(cur, pending_targs, Vec()));
        q = r_t.p;
        cur = r_t.id;
        pending_targs = Vec();
      }
      let ar1: AdvanceResult = advance(q);
      // Preferred async surface syntax: `expr.await`.
      // Keep the same AST node (`ExprNode.Await`) as prefix `await expr`.
      if kind_is(peek_kind(ar1.p), lex.TokenKind.KwAwait) {
        let arw: AdvanceResult = advance(ar1.p);
        let r_await: ParseExprResult = add_expr(arw.p, sp0, ast.ExprNode.Await(cur));
        q = r_await.p;
        cur = r_await.id;
        continue;
      }
      let r2: ParseIdentResult = parse_ident(ar1.p);
      let r3: ParseExprResult = add_expr(r2.p, sp0, ast.ExprNode.Member(cur, r2.name));
      q = r3.p;
      cur = r3.id;
      continue;
    }
    if kind_is(peek_kind(q), lex.TokenKind.KwAs) {
      if pending_targs.len() != 0 {
        let mut qq: Parser = q;
        let at: i32 = peek(q).start;
        qq.has_err = true;
        qq.err = ParseError.UnexpectedToken(lex.TokenKind.LParen, lex.TokenKind.KwAs, at);
        return ParseExprResult { p: qq, id: cur };
      }
      let sp0: ast.Span = span_expr(q.exprs, cur);
      let ar1: AdvanceResult = advance(q);
      let tr: ParseTypeResult = parse_type_name(ar1.p);
      let r2: ParseExprResult = add_expr(tr.p, sp0, ast.ExprNode.As(cur, tr.ty));
      q = r2.p;
      cur = r2.id;
      continue;
    }
    if kind_is(peek_kind(q), lex.TokenKind.LBracket) {
      if pending_targs.len() != 0 {
        let mut qq: Parser = q;
        let at: i32 = peek(q).start;
        qq.has_err = true;
        qq.err = ParseError.UnexpectedToken(lex.TokenKind.LBracket, lex.TokenKind.LBracket, at);
        return ParseExprResult { p: qq, id: cur };
      }
      let ar0: AdvanceResult = advance(q);
      let mut r: Parser = ar0.p;
      if !kind_is(peek_kind(r), lex.TokenKind.RBracket) {
        while !r.has_err {
          let tr: ParseTypeResult = parse_generic_call_arg(r);
          r = tr.p;
          pending_targs.push(tr.ty);
          if kind_is(peek_kind(r), lex.TokenKind.Comma) {
            let arx: AdvanceResult = advance(r);
            r = arx.p;
            if kind_is(peek_kind(r), lex.TokenKind.RBracket) {
              break;
            }
            continue;
          }
          break;
        }
      }
      let ar1: AdvanceResult = expect(r, lex.TokenKind.RBracket);
      q = ar1.p;
      continue;
    }
    if kind_is(peek_kind(q), lex.TokenKind.Not) {
      let sp0: ast.Span = span_expr(q.exprs, cur);
      let bang: AdvanceResult = advance(q);
      let ar1: AdvanceResult = expect(bang.p, lex.TokenKind.LParen);
      let mut r: Parser = ar1.p;
      let mut args: Vec[i32] = Vec();
      if !kind_is(peek_kind(r), lex.TokenKind.RParen) {
        while !r.has_err {
          let er: ParseExprResult = parse_expr(r, 0);
          r = er.p;
          args.push(er.id);
          if kind_is(peek_kind(r), lex.TokenKind.Comma) {
            let ar2: AdvanceResult = advance(r);
            r = ar2.p;
            if kind_is(peek_kind(r), lex.TokenKind.RParen) {
              break;
            }
            continue;
          }
          break;
        }
      }
      let ar3: AdvanceResult = expect(r, lex.TokenKind.RParen);
      let r4: ParseExprResult = add_expr(ar3.p, sp0, ast.ExprNode.MacroCall(cur, pending_targs, args));
      q = r4.p;
      cur = r4.id;
      pending_targs = Vec();
      continue;
    }
    if kind_is(peek_kind(q), lex.TokenKind.LParen) {
      let sp0: ast.Span = span_expr(q.exprs, cur);
      let ar1: AdvanceResult = advance(q);
      let mut r: Parser = ar1.p;
      let mut args: Vec[i32] = Vec();
      if !kind_is(peek_kind(r), lex.TokenKind.RParen) {
        while !r.has_err {
          let er: ParseExprResult = parse_expr(r, 0);
          r = er.p;
          args.push(er.id);
          if kind_is(peek_kind(r), lex.TokenKind.Comma) {
            let ar2: AdvanceResult = advance(r);
            r = ar2.p;
            if kind_is(peek_kind(r), lex.TokenKind.RParen) {
              break;
            }
            continue;
          }
          break;
        }
      }
      let ar3: AdvanceResult = expect(r, lex.TokenKind.RParen);
      let r4: ParseExprResult = add_expr(ar3.p, sp0, ast.ExprNode.Call(cur, pending_targs, args));
      q = r4.p;
      cur = r4.id;
      pending_targs = Vec();
      continue;
    }
    if kind_is(peek_kind(q), lex.TokenKind.Question) {
      if pending_targs.len() != 0 {
        let mut qq: Parser = q;
        let at: i32 = peek(q).start;
        qq.has_err = true;
        qq.err = ParseError.UnexpectedToken(lex.TokenKind.LParen, lex.TokenKind.Question, at);
        return ParseExprResult { p: qq, id: cur };
      }
      let arq: AdvanceResult = advance(q);
      let spq: ast.Span = span_expr(arq.p.exprs, cur);
      let rq: ParseExprResult = add_expr(arq.p, spq, ast.ExprNode.Try(cur));
      q = rq.p;
      cur = rq.id;
      continue;
    }
    break;
  }
  if pending_targs.len() != 0 {
    let mut qq: Parser = q;
    let at: i32 = peek(q).start;
    qq.has_err = true;
    qq.err = ParseError.UnexpectedToken(lex.TokenKind.LParen, peek_kind(q), at);
    return ParseExprResult { p: qq, id: cur };
  }
  return ParseExprResult { p: q, id: cur };
}

fn parse_pat(p: Parser) -> ParsePatResult {
  let sp0: ast.Span = span_tok(p, peek(p));
  let k: lex.TokenKind = peek_kind(p);
  // Negative integer pattern: `-123`
  if kind_is(k, lex.TokenKind.Minus) && kind_is(peek2_kind(p), lex.TokenKind.Int) {
    let ar0: AdvanceResult = advance(p);
    let ar1: AdvanceResult = expect(ar0.p, lex.TokenKind.Int);
    let tok: lex.Token = ar1.tok;
    let text: String = "-".concat(lexeme(ar1.p, tok));
    return ParsePatResult { p: ar1.p, pat: ast.Pat.Int(sp0, text) };
  }
  if kind_is(k, lex.TokenKind.Int) {
    let ar1: AdvanceResult = advance(p);
    let tok: lex.Token = ar1.tok;
    return ParsePatResult { p: ar1.p, pat: ast.Pat.Int(sp0, lexeme(ar1.p, tok)) };
  }
  if kind_is(k, lex.TokenKind.Char) {
    let r: ParseCharResult = parse_char_inner(p);
    return ParsePatResult { p: r.p, pat: ast.Pat.Int(sp0, r.text) };
  }
  if kind_is(k, lex.TokenKind.Str) {
    let r: ParseStringResult = parse_string_inner(p);
    return ParsePatResult { p: r.p, pat: ast.Pat.Str(sp0, r.s) };
  }
  if kind_is(k, lex.TokenKind.KwTrue) {
    let ar1: AdvanceResult = advance(p);
    return ParsePatResult { p: ar1.p, pat: ast.Pat.Bool(sp0, true) };
  }
  if kind_is(k, lex.TokenKind.KwFalse) {
    let ar1: AdvanceResult = advance(p);
    return ParsePatResult { p: ar1.p, pat: ast.Pat.Bool(sp0, false) };
  }

  // Enum variant shorthand pattern: `.Variant(x, y, ...)`
  if kind_is(k, lex.TokenKind.Dot) {
    let ar0: AdvanceResult = advance(p);
    let r0: ParseIdentResult = parse_ident(ar0.p);
    let mut q: Parser = r0.p;
    let mut args: Vec[ast.Pat] = Vec();
    if kind_is(peek_kind(q), lex.TokenKind.LParen) {
      let ar3: AdvanceResult = advance(q);
      q = ar3.p;
      if !kind_is(peek_kind(q), lex.TokenKind.RParen) {
        while !q.has_err {
          let pr: ParsePatResult = parse_pat(q);
          q = pr.p;
          args.push(pr.pat);
          if kind_is(peek_kind(q), lex.TokenKind.Comma) {
            let ar4: AdvanceResult = advance(q);
            q = ar4.p;
            if kind_is(peek_kind(q), lex.TokenKind.RParen) { break; }
            continue;
          }
          break;
        }
      }
      let ar5: AdvanceResult = expect(q, lex.TokenKind.RParen);
      q = ar5.p;
    }
    return ParsePatResult { p: q, pat: ast.Pat.EnumVariant(sp0, Vec(), r0.name, args) };
  }

  // Wildcard: `_`
  if kind_is(k, lex.TokenKind.Ident) {
    let r0: ParseIdentResult = parse_ident(p);
    if r0.name == "_" {
      return ParsePatResult { p: r0.p, pat: ast.Pat.Wild(sp0) };
    }

    // path: a.b.c
    let mut q: Parser = r0.p;
    let mut parts: Vec[String] = Vec();
    parts.push(r0.name);
    while kind_is(peek_kind(q), lex.TokenKind.Dot) && !q.has_err {
      let ar1: AdvanceResult = advance(q);
      let r2: ParseIdentResult = parse_ident(ar1.p);
      q = r2.p;
      parts.push(r2.name);
    }

    // optional payload patterns: (p0, p1, ...)
    let mut args: Vec[ast.Pat] = Vec();
    if kind_is(peek_kind(q), lex.TokenKind.LParen) {
      let ar3: AdvanceResult = advance(q);
      q = ar3.p;
      if !kind_is(peek_kind(q), lex.TokenKind.RParen) {
        while !q.has_err {
          let pr: ParsePatResult = parse_pat(q);
          q = pr.p;
          args.push(pr.pat);
          if kind_is(peek_kind(q), lex.TokenKind.Comma) {
            let ar4: AdvanceResult = advance(q);
            q = ar4.p;
            if kind_is(peek_kind(q), lex.TokenKind.RParen) {
              break;
            }
            continue;
          }
          break;
        }
      }
      let ar5: AdvanceResult = expect(q, lex.TokenKind.RParen);
      q = ar5.p;
    }

    if parts.len() >= 2 {
      let n: i32 = parts.len();
      let variant: String = parts.get(n - 1);
      let mut enum_parts: Vec[String] = Vec();
      let mut i: i32 = 0;
      while i < n - 1 {
        enum_parts.push(parts.get(i));
        i = i + 1;
      }
      return ParsePatResult { p: q, pat: ast.Pat.EnumVariant(sp0, enum_parts, variant, args) };
    }

    if args.len() != 0 {
      // `x(...)` with no path doesn't exist in this subset.
      let mut qq: Parser = q;
      let at: i32 = peek(p).start;
      qq.has_err = true;
      qq.err = ParseError.UnexpectedToken(lex.TokenKind.FatArrow, lex.TokenKind.LParen, at);
      return ParsePatResult { p: qq, pat: ast.Pat.Wild(sp0) };
    }
    return ParsePatResult { p: q, pat: ast.Pat.Bind(sp0, parts.get(0)) };
  }

  let mut q: Parser = p;
  let at: i32 = peek(p).start;
  q.has_err = true;
  q.err = ParseError.UnexpectedToken(lex.TokenKind.Ident, k, at);
  return ParsePatResult { p: q, pat: ast.Pat.Wild(sp0) };
}

fn parse_prefix(p: Parser) -> ParseExprResult {
  let k: lex.TokenKind = peek_kind(p);
  if kind_is(k, lex.TokenKind.Dollar) {
    // `$x` is surface sugar lowered to `unquote!(x)`.
    let ar0: AdvanceResult = advance(p);
    let sp0: ast.Span = span_tok(p, ar0.tok);
    let er: ParseExprResult = parse_expr(ar0.p, 11);
    if er.p.has_err { return er; }
    let idu: ParseExprResult = add_expr(er.p, sp0, ast.ExprNode.Ident("unquote"));
    if idu.p.has_err { return idu; }
    let mut args: Vec[i32] = Vec();
    args.push(er.id);
    return add_expr(idu.p, sp0, ast.ExprNode.MacroCall(idu.id, Vec(), args));
  }
  if kind_is(k, lex.TokenKind.Plus) {
    let ar: AdvanceResult = advance(p);
    let r: ParseExprResult = parse_expr(ar.p, 11);
    if r.p.has_err { return r; }
    return add_expr(r.p, span_tok(p, ar.tok), ast.ExprNode.Unary(ast.UnaryOp.Pos, r.id));
  }
  if kind_is(k, lex.TokenKind.Minus) {
    let ar: AdvanceResult = advance(p);
    let r: ParseExprResult = parse_expr(ar.p, 11);
    if r.p.has_err { return r; }
    return add_expr(r.p, span_tok(p, ar.tok), ast.ExprNode.Unary(ast.UnaryOp.Neg, r.id));
  }
  if kind_is(k, lex.TokenKind.Not) {
    let ar: AdvanceResult = advance(p);
    let r: ParseExprResult = parse_expr(ar.p, 11);
    if r.p.has_err { return r; }
    return add_expr(r.p, span_tok(p, ar.tok), ast.ExprNode.Unary(ast.UnaryOp.Not, r.id));
  }
  if kind_is(k, lex.TokenKind.KwAwait) {
    let ar: AdvanceResult = advance(p);
    let r: ParseExprResult = parse_expr(ar.p, 11);
    if r.p.has_err { return r; }
    return add_expr(r.p, span_tok(p, ar.tok), ast.ExprNode.Await(r.id));
  }
  if kind_is(k, lex.TokenKind.LParen) {
    let ar1: AdvanceResult = advance(p);
    let r2: ParseExprResult = parse_expr(ar1.p, 0);
    let ar3: AdvanceResult = expect(r2.p, lex.TokenKind.RParen);
    // Allow postfix ops on parenthesized expressions: `(expr).method(...)`.
    return parse_postfix(ar3.p, r2.id);
  }
  let r0: ParseExprResult = parse_primary(p);
  return parse_postfix(r0.p, r0.id);
}

fn infix_prec(k: lex.TokenKind) -> i32 {
  return match k {
    lex.TokenKind.OrOr => 1,
    lex.TokenKind.AndAnd => 2,
    lex.TokenKind.Pipe => 3,
    lex.TokenKind.Caret => 4,
    lex.TokenKind.Amp => 5,
    lex.TokenKind.EqEq => 6,
    lex.TokenKind.Ne => 6,
    lex.TokenKind.Lt => 7,
    lex.TokenKind.Le => 7,
    lex.TokenKind.Gt => 7,
    lex.TokenKind.Ge => 7,
    lex.TokenKind.LtLt => 8,
    lex.TokenKind.GtGt => 8,
    lex.TokenKind.Plus => 9,
    lex.TokenKind.Minus => 9,
    lex.TokenKind.Star => 10,
    lex.TokenKind.Slash => 10,
    lex.TokenKind.Percent => 10,
    _ => 0,
  };
}

fn infix_op(k: lex.TokenKind) -> ast.BinaryOp {
  return match k {
    lex.TokenKind.Plus => ast.BinaryOp.Add,
    lex.TokenKind.Minus => ast.BinaryOp.Sub,
    lex.TokenKind.Star => ast.BinaryOp.Mul,
    lex.TokenKind.Slash => ast.BinaryOp.Div,
    lex.TokenKind.Percent => ast.BinaryOp.Mod,
    lex.TokenKind.Amp => ast.BinaryOp.BitAnd,
    lex.TokenKind.Pipe => ast.BinaryOp.BitOr,
    lex.TokenKind.Caret => ast.BinaryOp.BitXor,
    lex.TokenKind.LtLt => ast.BinaryOp.Shl,
    lex.TokenKind.GtGt => ast.BinaryOp.Shr,
    lex.TokenKind.EqEq => ast.BinaryOp.Eq,
    lex.TokenKind.Ne => ast.BinaryOp.Ne,
    lex.TokenKind.Lt => ast.BinaryOp.Lt,
    lex.TokenKind.Le => ast.BinaryOp.Le,
    lex.TokenKind.Gt => ast.BinaryOp.Gt,
    lex.TokenKind.Ge => ast.BinaryOp.Ge,
    lex.TokenKind.AndAnd => ast.BinaryOp.AndAnd,
    lex.TokenKind.OrOr => ast.BinaryOp.OrOr,
    _ => ast.BinaryOp.Add,
  };
}

fn parse_expr(p: Parser, min_prec: i32) -> ParseExprResult {
  let r0: ParseExprResult = parse_prefix(p);
  let mut q: Parser = r0.p;
  let mut left: i32 = r0.id;
  while !q.has_err {
    let k: lex.TokenKind = peek_kind(q);
    let prec: i32 = infix_prec(k);
    if prec < min_prec || prec == 0 {
      break;
    }
    let ar1: AdvanceResult = advance(q);
    let op: ast.BinaryOp = infix_op(k);
    let r2: ParseExprResult = parse_expr(ar1.p, prec + 1);
    let sp0: ast.Span = span_expr(r2.p.exprs, left);
    let r3: ParseExprResult = add_expr(r2.p, sp0, ast.ExprNode.Binary(op, left, r2.id));
    q = r3.p;
    left = r3.id;
  }
  return ParseExprResult { p: q, id: left };
}

fn parse_stmt(p: Parser) -> ParseStmtResult {
  let sp0: ast.Span = span_tok(p, peek(p));
  let k: lex.TokenKind = peek_kind(p);
  if kind_is(k, lex.TokenKind.KwLet) {
    let ar1: AdvanceResult = advance(p);
    let mut q: Parser = ar1.p;

    // optional `mut`
    let mut is_mut: bool = false;
    if kind_is(peek_kind(q), lex.TokenKind.KwMut) {
      let ar2: AdvanceResult = advance(q);
      q = ar2.p;
      is_mut = true;
    }

    let r3: ParseIdentResult = parse_ident(q);
    q = r3.p;
    let name: String = r3.name;

    // optional type annotation: : Type
    let mut has_ann: bool = false;
    let mut ann: ast.TypeName = ast.TypeName { parts: Vec(), args: Vec() };
    if kind_is(peek_kind(q), lex.TokenKind.Colon) {
      let ar4: AdvanceResult = advance(q);
      let r5: ParseTypeResult = parse_type_name(ar4.p);
      q = r5.p;
      has_ann = true;
      ann = r5.ty;
    }

    let ar6: AdvanceResult = expect(q, lex.TokenKind.Eq);
    let r7: ParseExprResult = parse_expr(ar6.p, 0);
    let ar8: AdvanceResult = expect(r7.p, lex.TokenKind.Semicolon);
    return ParseStmtResult { p: ar8.p, st: ast.Stmt.Let(sp0, is_mut, name, has_ann, ann, r7.id) };
  }
  if kind_is(k, lex.TokenKind.KwIf) {
    let ar1: AdvanceResult = advance(p);
    let r2: ParseExprResult = parse_expr(ar1.p, 0);
    let r3: ParseBlockResult = parse_block(r2.p);
    let mut q: Parser = r3.p;
    let mut has_else: bool = false;
    let mut else_b: ast.Block = ast.Block { stmts: Vec() };
    if kind_is(peek_kind(q), lex.TokenKind.KwElse) {
      let ar4: AdvanceResult = advance(q);
      has_else = true;
      if kind_is(peek_kind(ar4.p), lex.TokenKind.KwIf) {
        // else if ... ; lower into else { if ... }
        let r5: ParseStmtResult = parse_stmt(ar4.p);
        let mut ss: Vec[ast.Stmt] = Vec();
        ss.push(r5.st);
        q = r5.p;
        else_b = ast.Block { stmts: ss };
      } else {
        let r5: ParseBlockResult = parse_block(ar4.p);
        q = r5.p;
        else_b = r5.b;
      }
    }
    return ParseStmtResult { p: q, st: ast.Stmt.IfStmt(sp0, r2.id, r3.b, has_else, else_b) };
  }
  if kind_is(k, lex.TokenKind.KwFor) {
    // Surface sugar:
    //   for x in xs { body }
    // lowers to:
    //   {
    //     let __vox_for_iter_<line>_<col> = xs;
    //     let mut __vox_for_idx_<line>_<col> = 0;
    //     while __vox_for_idx_<line>_<col> < __vox_for_iter_<line>_<col>.len() {
    //       let x = __vox_for_iter_<line>_<col>.get(__vox_for_idx_<line>_<col>);
    //       body
    //       __vox_for_idx_<line>_<col> = __vox_for_idx_<line>_<col> + 1;
    //     }
    //   }
    let ar_for: AdvanceResult = advance(p);
    let rn: ParseIdentResult = parse_ident(ar_for.p);
    let ar_in: AdvanceResult = expect(rn.p, lex.TokenKind.KwIn);
    let r_iter: ParseExprResult = parse_expr(ar_in.p, 0);
    let r_body: ParseBlockResult = parse_block(r_iter.p);
    let mut q: Parser = r_body.p;

    let suffix: String = sp0.line.to_string().concat("_").concat(sp0.col.to_string());
    let iter_name: String = "__vox_for_iter_".concat(suffix);
    let idx_name: String = "__vox_for_idx_".concat(suffix);
    let dummy_ty: ast.TypeName = ast.TypeName { parts: Vec(), args: Vec() };

    let st_iter: ast.Stmt = ast.Stmt.Let(sp0, false, iter_name, false, dummy_ty, r_iter.id);

    let add_zero: ast.AddExprResult = ast.expr_pool_add(q.exprs, ast.ExprNode.Int("0"), sp0);
    q.exprs = add_zero.pool;
    let st_idx: ast.Stmt = ast.Stmt.Let(sp0, true, idx_name, false, dummy_ty, add_zero.id);

    let add_idx_cond: ast.AddExprResult = ast.expr_pool_add(q.exprs, ast.ExprNode.Ident(idx_name), sp0);
    q.exprs = add_idx_cond.pool;
    let add_iter_len_recv: ast.AddExprResult = ast.expr_pool_add(q.exprs, ast.ExprNode.Ident(iter_name), sp0);
    q.exprs = add_iter_len_recv.pool;
    let add_len_member: ast.AddExprResult = ast.expr_pool_add(q.exprs, ast.ExprNode.Member(add_iter_len_recv.id, "len"), sp0);
    q.exprs = add_len_member.pool;
    let add_len_call: ast.AddExprResult = ast.expr_pool_add(q.exprs, ast.ExprNode.Call(add_len_member.id, Vec(), Vec()), sp0);
    q.exprs = add_len_call.pool;
    let add_cond: ast.AddExprResult = ast.expr_pool_add(q.exprs, ast.ExprNode.Binary(ast.BinaryOp.Lt, add_idx_cond.id, add_len_call.id), sp0);
    q.exprs = add_cond.pool;

    let add_iter_get_recv: ast.AddExprResult = ast.expr_pool_add(q.exprs, ast.ExprNode.Ident(iter_name), sp0);
    q.exprs = add_iter_get_recv.pool;
    let add_get_member: ast.AddExprResult = ast.expr_pool_add(q.exprs, ast.ExprNode.Member(add_iter_get_recv.id, "get"), sp0);
    q.exprs = add_get_member.pool;
    let add_idx_arg: ast.AddExprResult = ast.expr_pool_add(q.exprs, ast.ExprNode.Ident(idx_name), sp0);
    q.exprs = add_idx_arg.pool;
    let mut get_args: Vec[i32] = Vec();
    get_args.push(add_idx_arg.id);
    let add_get_call: ast.AddExprResult = ast.expr_pool_add(q.exprs, ast.ExprNode.Call(add_get_member.id, Vec(), get_args), sp0);
    q.exprs = add_get_call.pool;
    let st_item: ast.Stmt = ast.Stmt.Let(sp0, false, rn.name, false, dummy_ty, add_get_call.id);

    let add_idx_inc: ast.AddExprResult = ast.expr_pool_add(q.exprs, ast.ExprNode.Ident(idx_name), sp0);
    q.exprs = add_idx_inc.pool;
    let add_one: ast.AddExprResult = ast.expr_pool_add(q.exprs, ast.ExprNode.Int("1"), sp0);
    q.exprs = add_one.pool;
    let add_sum: ast.AddExprResult = ast.expr_pool_add(q.exprs, ast.ExprNode.Binary(ast.BinaryOp.Add, add_idx_inc.id, add_one.id), sp0);
    q.exprs = add_sum.pool;
    let st_inc: ast.Stmt = ast.Stmt.Assign(sp0, idx_name, add_sum.id);

    let mut while_stmts: Vec[ast.Stmt] = Vec();
    while_stmts.push(st_item);
    let mut bi: i32 = 0;
    while bi < r_body.b.stmts.len() {
      while_stmts.push(r_body.b.stmts.get(bi));
      bi = bi + 1;
    }
    while_stmts.push(st_inc);
    let st_while: ast.Stmt = ast.Stmt.WhileStmt(sp0, add_cond.id, ast.Block { stmts: while_stmts });

    let mut lowered: Vec[ast.Stmt] = Vec();
    lowered.push(st_iter);
    lowered.push(st_idx);
    lowered.push(st_while);
    let add_block: ast.AddExprResult = ast.expr_pool_add(
      q.exprs,
      ast.ExprNode.Block(ast.ExprBlock { stmts: lowered, has_tail: false, tail: -1 }),
      sp0,
    );
    q.exprs = add_block.pool;
    return ParseStmtResult { p: q, st: ast.Stmt.ExprStmt(sp0, add_block.id) };
  }
  if kind_is(k, lex.TokenKind.KwWhile) {
    let ar1: AdvanceResult = advance(p);
    let r2: ParseExprResult = parse_expr(ar1.p, 0);
    let r3: ParseBlockResult = parse_block(r2.p);
    return ParseStmtResult { p: r3.p, st: ast.Stmt.WhileStmt(sp0, r2.id, r3.b) };
  }
  if kind_is(k, lex.TokenKind.KwLoop) {
    // Surface sugar: `loop { ... }` lowers to `while true { ... }`.
    let ar1: AdvanceResult = advance(p);
    let r2: ParseBlockResult = parse_block(ar1.p);
    let add_true: ast.AddExprResult = ast.expr_pool_add(
      r2.p.exprs,
      ast.ExprNode.Bool(true),
      sp0,
    );
    let mut q: Parser = r2.p;
    q.exprs = add_true.pool;
    return ParseStmtResult { p: q, st: ast.Stmt.WhileStmt(sp0, add_true.id, r2.b) };
  }
  if kind_is(k, lex.TokenKind.KwBreak) {
    let ar1: AdvanceResult = advance(p);
    let ar2: AdvanceResult = expect(ar1.p, lex.TokenKind.Semicolon);
    return ParseStmtResult { p: ar2.p, st: ast.Stmt.Break(sp0) };
  }
  if kind_is(k, lex.TokenKind.KwContinue) {
    let ar1: AdvanceResult = advance(p);
    let ar2: AdvanceResult = expect(ar1.p, lex.TokenKind.Semicolon);
    return ParseStmtResult { p: ar2.p, st: ast.Stmt.Continue(sp0) };
  }
  if kind_is(k, lex.TokenKind.KwReturn) {
    let ar1: AdvanceResult = advance(p);
    if kind_is(peek_kind(ar1.p), lex.TokenKind.Semicolon) {
      let ar2: AdvanceResult = expect(ar1.p, lex.TokenKind.Semicolon);
      return ParseStmtResult { p: ar2.p, st: ast.Stmt.ReturnStmt(sp0, false, -1) };
    }
    let r2: ParseExprResult = parse_expr(ar1.p, 0);
    let ar3: AdvanceResult = expect(r2.p, lex.TokenKind.Semicolon);
    return ParseStmtResult { p: ar3.p, st: ast.Stmt.ReturnStmt(sp0, true, r2.id) };
  }

  // field assignment: ident(.ident)+ <assign-op> expr ;
  if is_field_assign_start(p) {
    let r1: ParseIdentResult = parse_ident(p);
    let mut ql: Parser = r1.p;
    let mut fields: Vec[String] = Vec();
    while kind_is(peek_kind(ql), lex.TokenKind.Dot) && kind_is(peek2_kind(ql), lex.TokenKind.Ident) {
      let ard: AdvanceResult = expect(ql, lex.TokenKind.Dot);
      let rf: ParseIdentResult = parse_ident(ard.p);
      ql = rf.p;
      fields.push(rf.name);
    }

    let op_tok: lex.Token = peek(ql);
    let ar4: AdvanceResult = advance(ql);
    let r5: ParseExprResult = parse_expr(ar4.p, 0);
    let mut q: Parser = r5.p;
    let mut rhs_id: i32 = r5.id;
    if !kind_is(op_tok.kind, lex.TokenKind.Eq) {
      let lhs_add0: ast.AddExprResult = ast.expr_pool_add(
        q.exprs,
        ast.ExprNode.Ident(r1.name),
        span_tok(q, op_tok),
      );
      let mut lhs_id: i32 = lhs_add0.id;
      let mut q2: Parser = q;
      q2.exprs = lhs_add0.pool;
      let mut fi: i32 = 0;
      while fi < fields.len() {
        let lhs_next: ast.AddExprResult = ast.expr_pool_add(
          q2.exprs,
          ast.ExprNode.Member(lhs_id, fields.get(fi)),
          span_tok(q2, op_tok),
        );
        lhs_id = lhs_next.id;
        q2.exprs = lhs_next.pool;
        fi = fi + 1;
      }
      let bop: ast.BinaryOp = assign_op_to_binary(op_tok.kind);
      let addb: ast.AddExprResult = ast.expr_pool_add(
        q2.exprs,
        ast.ExprNode.Binary(bop, lhs_id, rhs_id),
        span_tok(q2, op_tok),
      );
      q = q2;
      q.exprs = addb.pool;
      rhs_id = addb.id;
    }
    let ar6: AdvanceResult = expect(q, lex.TokenKind.Semicolon);
    return ParseStmtResult { p: ar6.p, st: ast.Stmt.AssignField(sp0, r1.name, join_field_path(fields), rhs_id) };
  }

  // assignment: ident <assign-op> expr ;
  if kind_is(k, lex.TokenKind.Ident) && is_assign_op(peek2_kind(p)) {
    let r1: ParseIdentResult = parse_ident(p);
    let op_tok: lex.Token = peek(r1.p);
    let ar2: AdvanceResult = advance(r1.p);
    let r3: ParseExprResult = parse_expr(ar2.p, 0);
    let mut q: Parser = r3.p;
    let mut rhs_id: i32 = r3.id;
    if !kind_is(op_tok.kind, lex.TokenKind.Eq) {
      let lhs_add: ast.AddExprResult = ast.expr_pool_add(
        q.exprs,
        ast.ExprNode.Ident(r1.name),
        span_tok(q, op_tok),
      );
      let bop: ast.BinaryOp = assign_op_to_binary(op_tok.kind);
      let bin_add: ast.AddExprResult = ast.expr_pool_add(
        lhs_add.pool,
        ast.ExprNode.Binary(bop, lhs_add.id, rhs_id),
        span_tok(q, op_tok),
      );
      q.exprs = bin_add.pool;
      rhs_id = bin_add.id;
    }
    let ar4: AdvanceResult = expect(q, lex.TokenKind.Semicolon);
    return ParseStmtResult { p: ar4.p, st: ast.Stmt.Assign(sp0, r1.name, rhs_id) };
  }

  // expr stmt
  let r1: ParseExprResult = parse_expr(p, 0);
  let ar2: AdvanceResult = expect(r1.p, lex.TokenKind.Semicolon);
  if !ar2.p.has_err {
    return ParseStmtResult { p: ar2.p, st: ast.Stmt.ExprStmt(span_expr(ar2.p.exprs, r1.id), r1.id) };
  }

  let mut q: Parser = p;
  let at: i32 = peek(p).start;
  q.has_err = true;
  q.err = ParseError.UnexpectedToken(lex.TokenKind.KwReturn, k, at);
  return ParseStmtResult { p: q, st: ast.Stmt.ReturnStmt(sp0, false, -1) };
}

fn parse_block(p: Parser) -> ParseBlockResult {
  let ar1: AdvanceResult = expect(p, lex.TokenKind.LBrace);
  let mut q: Parser = ar1.p;
  let mut stmts: Vec[ast.Stmt] = Vec();
  while !q.has_err && !kind_is(peek_kind(q), lex.TokenKind.RBrace) && !kind_is(peek_kind(q), lex.TokenKind.Eof) {
    let r: ParseStmtResult = parse_stmt(q);
    q = r.p;
    stmts.push(r.st);
  }
  let ar2: AdvanceResult = expect(q, lex.TokenKind.RBrace);
  return ParseBlockResult { p: ar2.p, b: ast.Block { stmts: stmts } };
}

fn parse_fn_decl(
  p: Parser,
  vis: i32,
  is_pub: bool,
  ffi_imports: Vec[ast.FfiImportAttr],
  ffi_exports: Vec[ast.FfiExportAttr],
  effects: Vec[ast.EffectAttr],
  resources: Vec[ast.ResourceAttr],
  cfgs: Vec[ast.CfgAttr],
  track_caller: bool,
  deprecated_message: String,
) -> ParseFnResult {
  let mut q0: Parser = p;
  let mut is_async: bool = false;
  if kind_is(peek_kind(q0), lex.TokenKind.KwAsync) {
    let ar0: AdvanceResult = advance(q0);
    q0 = ar0.p;
    is_async = true;
  }
  let ar1: AdvanceResult = expect(q0, lex.TokenKind.KwFn);
  let r2: ParseIdentResult = parse_ident(ar1.p);
  let mut q: Parser = r2.p;
  let mut tps: Vec[String] = Vec();
  let mut tpps: Vec[String] = Vec();
  let mut cps: Vec[ast.ConstParamDecl] = Vec();
  let mut tpbs: Vec[ast.TypeParamBoundsDecl] = Vec();
  let mut cwbs: Vec[ast.ConstWhereDecl] = Vec();
  if kind_is(peek_kind(q), lex.TokenKind.LBracket) {
    let r3: ParseFnTypeParamsResult = parse_fn_type_params(q);
    q = r3.p;
    tps = r3.tps;
    tpps = r3.tpps;
    cps = r3.cps;
    tpbs = r3.tpbs;
  }
  let _ar4: AdvanceResult = expect(q, lex.TokenKind.LParen);
  let r5: ParseParamsResult = parse_params(_ar4.p);
  let _ar6: AdvanceResult = expect(r5.p, lex.TokenKind.RParen);
  let _ar7: AdvanceResult = expect(_ar6.p, lex.TokenKind.Arrow);
  let r8: ParseTypeResult = parse_type_name(_ar7.p);
  let mut q2: Parser = r8.p;
  let mut tpbs2: Vec[ast.TypeParamBoundsDecl] = tpbs;
  let mut cwbs2: Vec[ast.ConstWhereDecl] = cwbs;
  if kind_is(peek_kind(q2), lex.TokenKind.KwWhere) {
    let wr: ParseWhereBoundsResult = parse_where_bounds(q2);
    q2 = wr.p;
    let mut wi: i32 = 0;
    while wi < wr.tpbs.len() {
      tpbs2.push(wr.tpbs.get(wi));
      wi = wi + 1;
    }
    wi = 0;
    while wi < wr.cwbs.len() {
      cwbs2.push(wr.cwbs.get(wi));
      wi = wi + 1;
    }
  }

  let mut q3: Parser = q2;
  let mut body: ast.Block = ast.Block { stmts: Vec() };
  if ffi_imports.len() != 0 {
    if kind_is(peek_kind(q3), lex.TokenKind.Semicolon) {
      let ar8: AdvanceResult = advance(q3);
      q3 = ar8.p;
    } else if !q3.has_err {
      let mut qe: Parser = q3;
      let at: i32 = peek(q3).start;
      qe.has_err = true;
      qe.err = ParseError.UnexpectedToken(lex.TokenKind.Semicolon, peek_kind(q3), at);
      q3 = qe;
    }
  } else if kind_is(peek_kind(q3), lex.TokenKind.LBrace) {
    let r9: ParseBlockResult = parse_block(q3);
    q3 = r9.p;
    body = r9.b;
  } else if !q3.has_err {
    let mut qe: Parser = q3;
    let at: i32 = peek(q3).start;
    qe.has_err = true;
    qe.err = ParseError.UnexpectedToken(lex.TokenKind.LBrace, peek_kind(q3), at);
    q3 = qe;
  }

  let params: Vec[ast.Param] = r5.params;
  return ParseFnResult {
    p: q3,
    f: ast.FuncDecl {
      file: p.file,
      sp: span_tok(p, ar1.tok),
      vis: vis,
      is_pub: is_pub,
      is_async: is_async,
      track_caller: track_caller,
      deprecated_message: deprecated_message,
      name: r2.name,
      type_params: tps,
      type_param_packs: tpps,
      const_params: cps,
      type_param_bounds: tpbs2,
      const_where_bounds: cwbs2,
      params: params,
      ret: r8.ty,
      cfgs: cfgs,
      ffi_imports: ffi_imports,
      ffi_exports: ffi_exports,
      effects: effects,
      resources: resources,
      body: body,
    },
  };
}

fn parse_fn_type_params(p: Parser) -> ParseFnTypeParamsResult {
  let ar1: AdvanceResult = expect(p, lex.TokenKind.LBracket);
  let mut q: Parser = ar1.p;
  let mut tps: Vec[String] = Vec();
  let mut tpps: Vec[String] = Vec();
  let mut cps: Vec[ast.ConstParamDecl] = Vec();
  let mut tpbs: Vec[ast.TypeParamBoundsDecl] = Vec();
  let mut seen_const: bool = false;
  let mut seen_const_default: bool = false;
  if kind_is(peek_kind(q), lex.TokenKind.RBracket) {
    let ar2: AdvanceResult = expect(q, lex.TokenKind.RBracket);
    return ParseFnTypeParamsResult { p: ar2.p, tps: tps, tpps: tpps, cps: cps, tpbs: tpbs };
  }
  while !q.has_err {
    if kind_is(peek_kind(q), lex.TokenKind.KwConst) {
      seen_const = true;
      let ar2: AdvanceResult = advance(q);
      let r1: ParseIdentResult = parse_ident(ar2.p);
      let ar3: AdvanceResult = expect(r1.p, lex.TokenKind.Colon);
      let tr: ParseTypeResult = parse_type_name(ar3.p);
      q = tr.p;
      let mut has_default: bool = false;
      let mut default_text: String = "";
      if kind_is(peek_kind(q), lex.TokenKind.Eq) {
        let ar4: AdvanceResult = advance(q);
        let dr: ParseConstDefaultResult = parse_const_default_text(ar4.p);
        if !dr.ok {
          let mut qerr: Parser = dr.p;
          qerr.has_err = true;
          qerr.err = ParseError.UnexpectedToken(lex.TokenKind.Int, peek_kind(dr.p), peek(dr.p).start);
          return ParseFnTypeParamsResult { p: qerr, tps: tps, tpps: tpps, cps: cps, tpbs: tpbs };
        }
        q = dr.p;
        has_default = true;
        default_text = dr.text;
        seen_const_default = true;
      } else if seen_const_default {
        let mut qerr2: Parser = q;
        qerr2.has_err = true;
        qerr2.err = ParseError.UnexpectedToken(lex.TokenKind.Eq, peek_kind(q), peek(q).start);
        return ParseFnTypeParamsResult { p: qerr2, tps: tps, tpps: tpps, cps: cps, tpbs: tpbs };
      }
      cps.push(ast.ConstParamDecl { name: r1.name, ty: tr.ty, has_default: has_default, default_text: default_text });
    } else {
      if seen_const {
        let mut qerr: Parser = q;
        qerr.has_err = true;
        qerr.err = ParseError.UnexpectedToken(lex.TokenKind.KwConst, peek_kind(q), peek(q).start);
        return ParseFnTypeParamsResult { p: qerr, tps: tps, tpps: tpps, cps: cps, tpbs: tpbs };
      }
      let r1: ParseIdentResult = parse_ident(q);
      q = r1.p;
      if kind_is(peek_kind(q), lex.TokenKind.DotDotDot) {
        let arp: AdvanceResult = advance(q);
        q = arp.p;
        tpps.push(r1.name);
      }
      tps.push(r1.name);

      let mut bounds: Vec[ast.TypeName] = Vec();
      if kind_is(peek_kind(q), lex.TokenKind.Colon) {
        let ar4: AdvanceResult = advance(q);
        q = ar4.p;
        while !q.has_err {
          let tr2: ParseTypeResult = parse_type_name(q);
          q = tr2.p;
          bounds.push(tr2.ty);
          if kind_is(peek_kind(q), lex.TokenKind.Plus) {
            let ar5: AdvanceResult = advance(q);
            q = ar5.p;
            continue;
          }
          break;
        }
      }
      if bounds.len() != 0 {
        tpbs.push(ast.TypeParamBoundsDecl { name: r1.name, bounds: bounds });
      }
    }

    if kind_is(peek_kind(q), lex.TokenKind.Comma) {
      let ar6: AdvanceResult = advance(q);
      q = ar6.p;
      if kind_is(peek_kind(q), lex.TokenKind.RBracket) {
        break;
      }
      continue;
    }
    break;
  }
  let ar7: AdvanceResult = expect(q, lex.TokenKind.RBracket);
  return ParseFnTypeParamsResult { p: ar7.p, tps: tps, tpps: tpps, cps: cps, tpbs: tpbs };
}

fn parse_type_params(p: Parser) -> ParseTypeParamsResult {
  let ar1: AdvanceResult = expect(p, lex.TokenKind.LBracket);
  let mut q: Parser = ar1.p;
  let mut tps: Vec[String] = Vec();
  let mut tpbs: Vec[ast.TypeParamBoundsDecl] = Vec();
  if kind_is(peek_kind(q), lex.TokenKind.RBracket) {
    let ar2: AdvanceResult = expect(q, lex.TokenKind.RBracket);
    return ParseTypeParamsResult { p: ar2.p, tps: tps, tpbs: tpbs };
  }
  while !q.has_err {
    let r1: ParseIdentResult = parse_ident(q);
    q = r1.p;
    tps.push(r1.name);

    let mut bounds: Vec[ast.TypeName] = Vec();
    if kind_is(peek_kind(q), lex.TokenKind.Colon) {
      let ar2: AdvanceResult = advance(q);
      q = ar2.p;
      while !q.has_err {
        let tr: ParseTypeResult = parse_type_name(q);
        q = tr.p;
        bounds.push(tr.ty);
        if kind_is(peek_kind(q), lex.TokenKind.Plus) {
          let ar3: AdvanceResult = advance(q);
          q = ar3.p;
          continue;
        }
        break;
      }
    }
    if bounds.len() != 0 {
      tpbs.push(ast.TypeParamBoundsDecl { name: r1.name, bounds: bounds });
    }

    if kind_is(peek_kind(q), lex.TokenKind.Comma) {
      let ar4: AdvanceResult = advance(q);
      q = ar4.p;
      if kind_is(peek_kind(q), lex.TokenKind.RBracket) {
        break;
      }
      continue;
    }
    break;
  }
  let ar5: AdvanceResult = expect(q, lex.TokenKind.RBracket);
  return ParseTypeParamsResult { p: ar5.p, tps: tps, tpbs: tpbs };
}

fn cw_reflect_tag(kind: i32) -> String {
  if kind == ast.comptime_where_lhs_size_of() { return "size_of"; }
  if kind == ast.comptime_where_lhs_align_of() { return "align_of"; }
  if kind == ast.comptime_where_lhs_field_count() { return "field_count"; }
  return "type";
}

fn cw_reflect_text(kind: i32, name: String) -> String {
  return "@".concat(cw_reflect_tag(kind)).concat("(").concat(name).concat(")");
}

fn cw_rhs_reflect_encode(kind: i32, name: String) -> String {
  return "__cwref__:".concat(cw_reflect_tag(kind)).concat(":").concat(name);
}

fn parse_where_bounds(p: Parser) -> ParseWhereBoundsResult {
  let ar1: AdvanceResult = expect(p, lex.TokenKind.KwWhere);
  let mut q: Parser = ar1.p;
  let mut out: Vec[ast.TypeParamBoundsDecl] = Vec();
  let mut cwbs: Vec[ast.ConstWhereDecl] = Vec();
  while !q.has_err {
    if kind_is(peek_kind(q), lex.TokenKind.KwComptime) {
      let ar0: AdvanceResult = advance(q);
      let mut qlhs: Parser = ar0.p;
      let mut lhs_kind: i32 = ast.comptime_where_lhs_const_param();
      let mut lhs_name: String = "";
      if kind_is(peek_kind(qlhs), lex.TokenKind.At) {
        let ar_at: AdvanceResult = advance(qlhs);
        qlhs = ar_at.p;
        let mut rname_name: String = "";
        if kind_is(peek_kind(qlhs), lex.TokenKind.Ident) {
          let rname: ParseIdentResult = parse_ident(qlhs);
          qlhs = rname.p;
          rname_name = rname.name;
        } else if kind_is(peek_kind(qlhs), lex.TokenKind.KwType) {
          let ar_kw: AdvanceResult = advance(qlhs);
          qlhs = ar_kw.p;
          rname_name = "type";
        } else {
          let mut qerr_name0: Parser = qlhs;
          qerr_name0.has_err = true;
          qerr_name0.err = ParseError.UnexpectedToken(lex.TokenKind.Ident, peek_kind(qlhs), peek(qlhs).start);
          return ParseWhereBoundsResult { p: qerr_name0, tpbs: out, cwbs: cwbs };
        }
        if rname_name == "size_of" {
          lhs_kind = ast.comptime_where_lhs_size_of();
        } else if rname_name == "align_of" {
          lhs_kind = ast.comptime_where_lhs_align_of();
        } else if rname_name == "field_count" {
          lhs_kind = ast.comptime_where_lhs_field_count();
        } else if rname_name == "type" {
          lhs_kind = ast.comptime_where_lhs_type();
        } else {
          let mut qerr_name: Parser = qlhs;
          qerr_name.has_err = true;
          qerr_name.err = ParseError.UnexpectedToken(lex.TokenKind.Ident, peek_kind(qlhs), peek(qlhs).start);
          return ParseWhereBoundsResult { p: qerr_name, tpbs: out, cwbs: cwbs };
        }
        let ar_l: AdvanceResult = expect(qlhs, lex.TokenKind.LParen);
        let rtp: ParseNameRefResult = parse_name_ref(ar_l.p);
        let ar_r: AdvanceResult = expect(rtp.p, lex.TokenKind.RParen);
        qlhs = ar_r.p;
        lhs_name = rtp.name;
      } else {
        let r1: ParseNameRefResult = parse_name_ref(qlhs);
        qlhs = r1.p;
        lhs_name = r1.name;
      }
      let opk: lex.TokenKind = peek_kind(qlhs);
      let is_cmp: bool =
        kind_is(opk, lex.TokenKind.EqEq) ||
        kind_is(opk, lex.TokenKind.Ne) ||
        kind_is(opk, lex.TokenKind.Lt) ||
        kind_is(opk, lex.TokenKind.Le) ||
        kind_is(opk, lex.TokenKind.Gt) ||
        kind_is(opk, lex.TokenKind.Ge);
      if !is_cmp {
        let mut qerr0: Parser = qlhs;
        qerr0.has_err = true;
        qerr0.err = ParseError.UnexpectedToken(lex.TokenKind.Lt, opk, peek(qlhs).start);
        return ParseWhereBoundsResult { p: qerr0, tpbs: out, cwbs: cwbs };
      }
      let op: ast.BinaryOp =
        if kind_is(opk, lex.TokenKind.EqEq) { ast.BinaryOp.Eq } else
        if kind_is(opk, lex.TokenKind.Ne) { ast.BinaryOp.Ne } else
        if kind_is(opk, lex.TokenKind.Lt) { ast.BinaryOp.Lt } else
        if kind_is(opk, lex.TokenKind.Le) { ast.BinaryOp.Le } else
        if kind_is(opk, lex.TokenKind.Gt) { ast.BinaryOp.Gt } else { ast.BinaryOp.Ge };
      let ar2: AdvanceResult = advance(qlhs);
      let mut qrhs: Parser = ar2.p;
      if kind_is(peek_kind(qrhs), lex.TokenKind.At) {
        let ar_rhs_at: AdvanceResult = advance(qrhs);
        let mut qrhs0: Parser = ar_rhs_at.p;
        let mut rhs_kind: i32 = ast.comptime_where_lhs_const_param();
        if kind_is(peek_kind(qrhs0), lex.TokenKind.Ident) {
          let rname: ParseIdentResult = parse_ident(qrhs0);
          qrhs0 = rname.p;
          if rname.name == "size_of" {
            rhs_kind = ast.comptime_where_lhs_size_of();
          } else if rname.name == "align_of" {
            rhs_kind = ast.comptime_where_lhs_align_of();
          } else if rname.name == "field_count" {
            rhs_kind = ast.comptime_where_lhs_field_count();
          } else {
            let mut qerr_name: Parser = qrhs0;
            qerr_name.has_err = true;
            qerr_name.err = ParseError.UnexpectedToken(lex.TokenKind.Ident, peek_kind(qrhs0), peek(qrhs0).start);
            return ParseWhereBoundsResult { p: qerr_name, tpbs: out, cwbs: cwbs };
          }
        } else if kind_is(peek_kind(qrhs0), lex.TokenKind.KwType) {
          let ar_kw: AdvanceResult = advance(qrhs0);
          qrhs0 = ar_kw.p;
          rhs_kind = ast.comptime_where_lhs_type();
        } else {
          let mut qerr_name0: Parser = qrhs0;
          qerr_name0.has_err = true;
          qerr_name0.err = ParseError.UnexpectedToken(lex.TokenKind.Ident, peek_kind(qrhs0), peek(qrhs0).start);
          return ParseWhereBoundsResult { p: qerr_name0, tpbs: out, cwbs: cwbs };
        }
        let ar_rhs_l: AdvanceResult = expect(qrhs0, lex.TokenKind.LParen);
        let rr_tp: ParseNameRefResult = parse_name_ref(ar_rhs_l.p);
        let ar_rhs_r: AdvanceResult = expect(rr_tp.p, lex.TokenKind.RParen);
        qrhs = ar_rhs_r.p;
        let rhs_text: String = cw_reflect_text(rhs_kind, rr_tp.name);
        cwbs.push(ast.ConstWhereDecl {
          lhs_kind: lhs_kind,
          name: lhs_name,
          op: op,
          rhs_is_param: true,
          rhs_param: cw_rhs_reflect_encode(rhs_kind, rr_tp.name),
          rhs_text: rhs_text,
        });
      } else if kind_is(peek_kind(qrhs), lex.TokenKind.Ident) {
        let rr: ParseIdentResult = parse_ident(qrhs);
        qrhs = rr.p;
        cwbs.push(ast.ConstWhereDecl {
          lhs_kind: lhs_kind,
          name: lhs_name,
          op: op,
          rhs_is_param: true,
          rhs_param: rr.name,
          rhs_text: rr.name,
        });
      } else {
        let dr: ParseConstDefaultResult = parse_const_default_text(qrhs);
        if !dr.ok {
          let mut qerr1: Parser = dr.p;
          qerr1.has_err = true;
          qerr1.err = ParseError.UnexpectedToken(lex.TokenKind.Int, peek_kind(dr.p), peek(dr.p).start);
          return ParseWhereBoundsResult { p: qerr1, tpbs: out, cwbs: cwbs };
        }
        qrhs = dr.p;
        cwbs.push(ast.ConstWhereDecl {
          lhs_kind: lhs_kind,
          name: lhs_name,
          op: op,
          rhs_is_param: false,
          rhs_param: "",
          rhs_text: dr.text,
        });
      }
      q = qrhs;
    } else {
      let r1: ParseNameRefResult = parse_name_ref(q);
      q = r1.p;
      let ar2: AdvanceResult = expect(q, lex.TokenKind.Colon);
      q = ar2.p;

      let mut bounds: Vec[ast.TypeName] = Vec();
      while !q.has_err {
        let tr: ParseTypeResult = parse_type_name(q);
        q = tr.p;
        bounds.push(tr.ty);
        if kind_is(peek_kind(q), lex.TokenKind.Plus) {
          let ar3: AdvanceResult = advance(q);
          q = ar3.p;
          continue;
        }
        break;
      }
      out.push(ast.TypeParamBoundsDecl { name: r1.name, bounds: bounds });
    }

    if kind_is(peek_kind(q), lex.TokenKind.Comma) {
      let ar4: AdvanceResult = advance(q);
      q = ar4.p;
      // allow trailing comma before block/semicolon
      if kind_is(peek_kind(q), lex.TokenKind.LBrace) || kind_is(peek_kind(q), lex.TokenKind.Semicolon) { break; }
      continue;
    }
    break;
  }
  return ParseWhereBoundsResult { p: q, tpbs: out, cwbs: cwbs };
}

fn parse_field_decl(p: Parser) -> ParseFieldResult {
  let mut q: Parser = p;
  let mut is_pub: bool = false;
  let mut vis: i32 = ast.vis_private();
  let pr: ParsePubResult = parse_pub_marker(q);
  q = pr.p;
  is_pub = pr.is_pub;
  vis = pr.vis;
  let r2: ParseIdentResult = parse_ident(q);
  let ar3: AdvanceResult = expect(r2.p, lex.TokenKind.Colon);
  let r4: ParseTypeResult = parse_type_name(ar3.p);
  return ParseFieldResult { p: r4.p, f: ast.FieldDecl { vis: vis, is_pub: is_pub, name: r2.name, ty: r4.ty } };
}

fn parse_struct_decl(p: Parser, vis: i32, is_pub: bool) -> ParseStructResult {
  let ar1: AdvanceResult = expect(p, lex.TokenKind.KwStruct);
  let r2: ParseIdentResult = parse_ident(ar1.p);
  let mut q0: Parser = r2.p;
  let mut tps: Vec[String] = Vec();
  let mut tpbs: Vec[ast.TypeParamBoundsDecl] = Vec();
  let mut cwbs: Vec[ast.ConstWhereDecl] = Vec();
  if kind_is(peek_kind(q0), lex.TokenKind.LBracket) {
    let rtp: ParseTypeParamsResult = parse_type_params(q0);
    q0 = rtp.p;
    tps = rtp.tps;
    tpbs = rtp.tpbs;
  }
  if kind_is(peek_kind(q0), lex.TokenKind.KwWhere) {
    let wr: ParseWhereBoundsResult = parse_where_bounds(q0);
    q0 = wr.p;
    let mut wi: i32 = 0;
    while wi < wr.tpbs.len() {
      tpbs.push(wr.tpbs.get(wi));
      wi = wi + 1;
    }
    wi = 0;
    while wi < wr.cwbs.len() {
      cwbs.push(wr.cwbs.get(wi));
      wi = wi + 1;
    }
  }
  let ar3: AdvanceResult = expect(q0, lex.TokenKind.LBrace);
  let mut q: Parser = ar3.p;
  let mut fields: Vec[ast.FieldDecl] = Vec();
  if !kind_is(peek_kind(q), lex.TokenKind.RBrace) {
    while !q.has_err {
      let r: ParseFieldResult = parse_field_decl(q);
      q = r.p;
      fields.push(r.f);
      if kind_is(peek_kind(q), lex.TokenKind.Comma) {
        let ar4: AdvanceResult = advance(q);
        q = ar4.p;
        if kind_is(peek_kind(q), lex.TokenKind.RBrace) {
          break;
        }
        continue;
      }
      break;
    }
  }
  let ar5: AdvanceResult = expect(q, lex.TokenKind.RBrace);
  return ParseStructResult {
    p: ar5.p,
    s: ast.StructDecl {
      file: p.file,
      sp: span_tok(p, ar1.tok),
      vis: vis,
      is_pub: is_pub,
      name: r2.name,
      type_params: tps,
      type_param_bounds: tpbs,
      const_where_bounds: cwbs,
      fields: fields,
    },
  };
}

fn parse_enum_variant_decl(p: Parser) -> ParseVariantResult {
  let r1: ParseIdentResult = parse_ident(p);
  let mut q: Parser = r1.p;
  let mut fields: Vec[ast.TypeName] = Vec();
  if kind_is(peek_kind(q), lex.TokenKind.LParen) {
    let ar2: AdvanceResult = advance(q);
    q = ar2.p;
    if !kind_is(peek_kind(q), lex.TokenKind.RParen) {
      while !q.has_err {
        let tr: ParseTypeResult = parse_type_name(q);
        q = tr.p;
        fields.push(tr.ty);
        if kind_is(peek_kind(q), lex.TokenKind.Comma) {
          let ar3: AdvanceResult = advance(q);
          q = ar3.p;
          if kind_is(peek_kind(q), lex.TokenKind.RParen) {
            break;
          }
          continue;
        }
        break;
      }
    }
    let ar4: AdvanceResult = expect(q, lex.TokenKind.RParen);
    q = ar4.p;
  }
  return ParseVariantResult { p: q, v: ast.EnumVariantDecl { name: r1.name, fields: fields } };
}

fn parse_enum_decl(p: Parser, vis: i32, is_pub: bool) -> ParseEnumResult {
  let ar1: AdvanceResult = expect(p, lex.TokenKind.KwEnum);
  let r2: ParseIdentResult = parse_ident(ar1.p);
  let mut q0: Parser = r2.p;
  let mut tps: Vec[String] = Vec();
  let mut tpbs: Vec[ast.TypeParamBoundsDecl] = Vec();
  let mut cwbs: Vec[ast.ConstWhereDecl] = Vec();
  if kind_is(peek_kind(q0), lex.TokenKind.LBracket) {
    let rtp: ParseTypeParamsResult = parse_type_params(q0);
    q0 = rtp.p;
    tps = rtp.tps;
    tpbs = rtp.tpbs;
  }
  if kind_is(peek_kind(q0), lex.TokenKind.KwWhere) {
    let wr: ParseWhereBoundsResult = parse_where_bounds(q0);
    q0 = wr.p;
    let mut wi: i32 = 0;
    while wi < wr.tpbs.len() {
      tpbs.push(wr.tpbs.get(wi));
      wi = wi + 1;
    }
    wi = 0;
    while wi < wr.cwbs.len() {
      cwbs.push(wr.cwbs.get(wi));
      wi = wi + 1;
    }
  }
  let ar3: AdvanceResult = expect(q0, lex.TokenKind.LBrace);
  let mut q: Parser = ar3.p;
  let mut vars: Vec[ast.EnumVariantDecl] = Vec();
  if !kind_is(peek_kind(q), lex.TokenKind.RBrace) {
    while !q.has_err {
      let vr: ParseVariantResult = parse_enum_variant_decl(q);
      q = vr.p;
      vars.push(vr.v);
      if kind_is(peek_kind(q), lex.TokenKind.Comma) {
        let ar4: AdvanceResult = advance(q);
        q = ar4.p;
        if kind_is(peek_kind(q), lex.TokenKind.RBrace) {
          break;
        }
        continue;
      }
      break;
    }
  }
  let ar5: AdvanceResult = expect(q, lex.TokenKind.RBrace);
  return ParseEnumResult {
    p: ar5.p,
    e: ast.EnumDecl {
      file: p.file,
      sp: span_tok(p, ar1.tok),
      vis: vis,
      is_pub: is_pub,
      name: r2.name,
      type_params: tps,
      type_param_bounds: tpbs,
      const_where_bounds: cwbs,
      variants: vars,
    },
  };
}

fn parse_trait_method_decl(
  p: Parser,
  effects: Vec[ast.EffectAttr],
  resources: Vec[ast.ResourceAttr],
  deprecated_message: String,
) -> ParseTraitMethodResult {
  let mut q0: Parser = p;
  let mut is_async: bool = false;
  if kind_is(peek_kind(q0), lex.TokenKind.KwAsync) {
    let ar0: AdvanceResult = advance(q0);
    q0 = ar0.p;
    is_async = true;
  }
  let ar1: AdvanceResult = expect(q0, lex.TokenKind.KwFn);
  let r2: ParseIdentResult = parse_ident(ar1.p);
  q0 = r2.p;
  let mut tps: Vec[String] = Vec();
  let mut tpps: Vec[String] = Vec();
  let mut cps: Vec[ast.ConstParamDecl] = Vec();
  let mut tpbs: Vec[ast.TypeParamBoundsDecl] = Vec();
  let mut cwbs: Vec[ast.ConstWhereDecl] = Vec();
  if kind_is(peek_kind(q0), lex.TokenKind.LBracket) {
    let rtp: ParseFnTypeParamsResult = parse_fn_type_params(q0);
    q0 = rtp.p;
    tps = rtp.tps;
    tpps = rtp.tpps;
    cps = rtp.cps;
    tpbs = rtp.tpbs;
  }
  let ar3: AdvanceResult = expect(q0, lex.TokenKind.LParen);
  let r4: ParseParamsResult = parse_params(ar3.p);
  let ar5: AdvanceResult = expect(r4.p, lex.TokenKind.RParen);
  let ar6: AdvanceResult = expect(ar5.p, lex.TokenKind.Arrow);
  let r7: ParseTypeResult = parse_type_name(ar6.p);
  let mut q: Parser = r7.p;
  let mut tpbs2: Vec[ast.TypeParamBoundsDecl] = tpbs;
  let mut cwbs2: Vec[ast.ConstWhereDecl] = cwbs;
  if kind_is(peek_kind(q), lex.TokenKind.KwWhere) {
    let wr: ParseWhereBoundsResult = parse_where_bounds(q);
    q = wr.p;
    let mut wi: i32 = 0;
    while wi < wr.tpbs.len() {
      tpbs2.push(wr.tpbs.get(wi));
      wi = wi + 1;
    }
    wi = 0;
    while wi < wr.cwbs.len() {
      cwbs2.push(wr.cwbs.get(wi));
      wi = wi + 1;
    }
  }
  let mut has_body: bool = false;
  let mut body: ast.Block = ast.Block { stmts: Vec() };
  if kind_is(peek_kind(q), lex.TokenKind.LBrace) {
    let br: ParseBlockResult = parse_block(q);
    q = br.p;
    has_body = true;
    body = br.b;
  } else
  if kind_is(peek_kind(q), lex.TokenKind.Semicolon) {
    let ar8: AdvanceResult = advance(q);
    q = ar8.p;
  } else {
    let mut qq: Parser = q;
    let at: i32 = peek(q).start;
    qq.has_err = true;
    qq.err = ParseError.UnexpectedToken(lex.TokenKind.Semicolon, peek_kind(q), at);
    q = qq;
  }
  return ParseTraitMethodResult {
    p: q,
    m: ast.TraitMethodDecl {
      sp: span_tok(p, ar1.tok),
      is_async: is_async,
      deprecated_message: deprecated_message,
      name: r2.name,
      type_params: tps,
      type_param_packs: tpps,
      const_params: cps,
      type_param_bounds: tpbs2,
      const_where_bounds: cwbs2,
      params: r4.params,
      ret: r7.ty,
      effects: effects,
      resources: resources,
      has_body: has_body,
      body: body,
    },
  };
}

fn parse_trait_assoc_type_decl(p: Parser) -> ParseTraitAssocTypeResult {
  let ar1: AdvanceResult = expect(p, lex.TokenKind.KwType);
  let r2: ParseIdentResult = parse_ident(ar1.p);
  let mut q: Parser = r2.p;
  if kind_is(peek_kind(q), lex.TokenKind.Semicolon) {
    let ar3: AdvanceResult = advance(q);
    q = ar3.p;
  } else {
    let mut qq: Parser = q;
    let at: i32 = peek(q).start;
    qq.has_err = true;
    qq.err = ParseError.UnexpectedToken(lex.TokenKind.Semicolon, peek_kind(q), at);
    q = qq;
  }
  return ParseTraitAssocTypeResult { p: q, a: ast.TraitAssocTypeDecl { sp: span_tok(p, ar1.tok), name: r2.name } };
}

fn parse_impl_assoc_type_binding(p: Parser) -> ParseImplAssocTypeResult {
  let ar1: AdvanceResult = expect(p, lex.TokenKind.KwType);
  let r2: ParseIdentResult = parse_ident(ar1.p);
  let ar3: AdvanceResult = expect(r2.p, lex.TokenKind.Eq);
  let r4: ParseTypeResult = parse_type_name(ar3.p);
  let mut q: Parser = r4.p;
  if kind_is(peek_kind(q), lex.TokenKind.Semicolon) {
    let ar5: AdvanceResult = advance(q);
    q = ar5.p;
  } else {
    let mut qq: Parser = q;
    let at: i32 = peek(q).start;
    qq.has_err = true;
    qq.err = ParseError.UnexpectedToken(lex.TokenKind.Semicolon, peek_kind(q), at);
    q = qq;
  }
  return ParseImplAssocTypeResult { p: q, a: ast.ImplAssocTypeBinding { sp: span_tok(p, ar1.tok), name: r2.name, ty: r4.ty } };
}

fn parse_trait_decl(p: Parser, vis: i32, is_pub: bool) -> ParseTraitResult {
  let ar1: AdvanceResult = expect(p, lex.TokenKind.KwTrait);
  let r2: ParseIdentResult = parse_ident(ar1.p);
  let mut q0: Parser = r2.p;
  let mut supers: Vec[ast.TypeName] = Vec();
  if kind_is(peek_kind(q0), lex.TokenKind.Colon) {
    let arx: AdvanceResult = advance(q0);
    q0 = arx.p;
    while !q0.has_err {
      let tr: ParseTypeResult = parse_type_name(q0);
      q0 = tr.p;
      supers.push(tr.ty);
      if kind_is(peek_kind(q0), lex.TokenKind.Plus) {
        let ary: AdvanceResult = advance(q0);
        q0 = ary.p;
        continue;
      }
      break;
    }
  }
  let ar3: AdvanceResult = expect(q0, lex.TokenKind.LBrace);
  let mut q: Parser = ar3.p;
  let mut assocs: Vec[ast.TraitAssocTypeDecl] = Vec();
  let mut ms: Vec[ast.TraitMethodDecl] = Vec();
  if !kind_is(peek_kind(q), lex.TokenKind.RBrace) {
    while !q.has_err {
      if kind_is(peek_kind(q), lex.TokenKind.KwType) {
        let ar: ParseTraitAssocTypeResult = parse_trait_assoc_type_decl(q);
        q = ar.p;
        assocs.push(ar.a);
      } else {
        let ar: ParseTopFnAttrsResult = parse_top_fn_attrs(q);
        q = ar.p;
        if ar.ffi_imports.len() != 0 || ar.ffi_exports.len() != 0 {
          q = set_method_ffi_attr_error(q);
          continue;
        }
        if ar.cfgs.len() != 0 {
          q = set_method_cfg_attr_error(q);
          continue;
        }
        if ar.track_caller {
          q = set_method_track_caller_attr_error(q);
          continue;
        }
        let mr: ParseTraitMethodResult = parse_trait_method_decl(q, ar.effects, ar.resources, ar.deprecated_message);
        q = mr.p;
        ms.push(mr.m);
      }
      if kind_is(peek_kind(q), lex.TokenKind.Comma) {
        let ar4: AdvanceResult = advance(q);
        q = ar4.p;
        if kind_is(peek_kind(q), lex.TokenKind.RBrace) { break; }
        continue;
      }
      if kind_is(peek_kind(q), lex.TokenKind.RBrace) { break; }
      continue;
    }
  }
  let ar5: AdvanceResult = expect(q, lex.TokenKind.RBrace);
  return ParseTraitResult {
    p: ar5.p,
    t: ast.TraitDecl { file: p.file, sp: span_tok(p, ar1.tok), vis: vis, is_pub: is_pub, name: r2.name, supers: supers, assoc_types: assocs, methods: ms },
  };
}

fn parse_impl_decl(p: Parser) -> ParseImplResult {
  let ar1: AdvanceResult = expect(p, lex.TokenKind.KwImpl);
  let mut q0: Parser = ar1.p;
  let mut tps: Vec[String] = Vec();
  let mut tpbs: Vec[ast.TypeParamBoundsDecl] = Vec();
  let mut cwbs: Vec[ast.ConstWhereDecl] = Vec();
  let mut is_negative: bool = false;
  if kind_is(peek_kind(q0), lex.TokenKind.LBracket) {
    let rtp: ParseTypeParamsResult = parse_type_params(q0);
    q0 = rtp.p;
    tps = rtp.tps;
    tpbs = rtp.tpbs;
  }
  if kind_is(peek_kind(q0), lex.TokenKind.Not) {
    let ar_neg: AdvanceResult = advance(q0);
    q0 = ar_neg.p;
    is_negative = true;
  }
  let hr: ParseTypeResult = parse_type_name(q0);
  let mut is_inherent: bool = false;
  let mut trait_name: ast.TypeName = ast.TypeName { parts: Vec(), args: Vec() };
  let mut for_ty: ast.TypeName = ast.TypeName { parts: Vec(), args: Vec() };
  let mut q1: Parser = hr.p;
  if kind_is(peek_kind(q1), lex.TokenKind.KwFor) {
    let ar2: AdvanceResult = advance(q1);
    let fr: ParseTypeResult = parse_type_name(ar2.p);
    trait_name = hr.ty;
    for_ty = fr.ty;
    q1 = fr.p;
  } else {
    is_inherent = true;
    for_ty = hr.ty;
  }
  if kind_is(peek_kind(q1), lex.TokenKind.KwWhere) {
    let wr: ParseWhereBoundsResult = parse_where_bounds(q1);
    q1 = wr.p;
    cwbs = wr.cwbs;
  }
  if is_negative && is_inherent {
    let mut q_bad: Parser = q1;
    q_bad.has_err = true;
    q_bad.err = ParseError.InvalidType(peek(q1).start, "negative impl requires trait impl form");
    return ParseImplResult {
      p: q_bad,
      i: ast.ImplDecl {
        file: p.file,
        sp: span_tok(p, ar1.tok),
        is_inherent: true,
        is_negative: true,
        type_params: tps,
        type_param_bounds: tpbs,
        const_where_bounds: cwbs,
        trait_name: trait_name,
        for_ty: for_ty,
        assoc_types: Vec(),
        methods: Vec(),
      },
    };
  }
  let ar3: AdvanceResult = expect(q1, lex.TokenKind.LBrace);
  let mut q: Parser = ar3.p;
  let mut assoc_types: Vec[ast.ImplAssocTypeBinding] = Vec();
  let mut methods: Vec[ast.FuncDecl] = Vec();
  while !q.has_err && !kind_is(peek_kind(q), lex.TokenKind.RBrace) && !kind_is(peek_kind(q), lex.TokenKind.Eof) {
    if kind_is(peek_kind(q), lex.TokenKind.KwType) {
      let ar: ParseImplAssocTypeResult = parse_impl_assoc_type_binding(q);
      q = ar.p;
      assoc_types.push(ar.a);
    } else {
      let ar0: ParseTopFnAttrsResult = parse_top_fn_attrs(q);
      q = ar0.p;
      if ar0.ffi_imports.len() != 0 || ar0.ffi_exports.len() != 0 {
        q = set_method_ffi_attr_error(q);
        continue;
      }
      if ar0.cfgs.len() != 0 {
        q = set_method_cfg_attr_error(q);
        continue;
      }
      if ar0.track_caller {
        q = set_method_track_caller_attr_error(q);
        continue;
      }
      let r: ParseFnResult = parse_fn_decl(q, ast.vis_private(), false, Vec(), Vec(), ar0.effects, ar0.resources, Vec(), false, ar0.deprecated_message);
      q = r.p;
      methods.push(r.f);
    }
  }
  let ar4: AdvanceResult = expect(q, lex.TokenKind.RBrace);
  return ParseImplResult {
    p: ar4.p,
    i: ast.ImplDecl {
      file: p.file,
      sp: span_tok(p, ar1.tok),
      is_inherent: is_inherent,
      is_negative: is_negative,
      type_params: tps,
      type_param_bounds: tpbs,
      const_where_bounds: cwbs,
      trait_name: trait_name,
      for_ty: for_ty,
      assoc_types: assoc_types,
      methods: methods,
    },
  };
}

fn parse_type_alias_decl(p: Parser, vis: i32, is_pub: bool) -> ParseTypeAliasResult {
  // `type Name = Type;` (semicolon optional)
  let ar0: AdvanceResult = expect(p, lex.TokenKind.KwType);
  let r1: ParseIdentResult = parse_ident(ar0.p);
  let ar2: AdvanceResult = expect(r1.p, lex.TokenKind.Eq);
  let r3: ParseTypeResult = parse_type_name(ar2.p);
  let mut q: Parser = r3.p;
  if kind_is(peek_kind(q), lex.TokenKind.Semicolon) {
    let ar4: AdvanceResult = advance(q);
    q = ar4.p;
  }
  return ParseTypeAliasResult { p: q, t: ast.TypeAliasDecl { file: p.file, sp: span_tok(p, ar0.tok), vis: vis, is_pub: is_pub, name: r1.name, ty: r3.ty } };
}

fn parse_const_decl(p: Parser, vis: i32, is_pub: bool) -> ParseConstResult {
  // `const Name: Type = Expr;` (semicolon optional)
  let ar0: AdvanceResult = expect(p, lex.TokenKind.KwConst);
  let r1: ParseIdentResult = parse_ident(ar0.p);
  let ar2: AdvanceResult = expect(r1.p, lex.TokenKind.Colon);
  let r3: ParseTypeResult = parse_type_name(ar2.p);
  let ar4: AdvanceResult = expect(r3.p, lex.TokenKind.Eq);
  let r5: ParseExprResult = parse_expr(ar4.p, 0);
  let mut q: Parser = r5.p;
  if kind_is(peek_kind(q), lex.TokenKind.Semicolon) {
    let ar6: AdvanceResult = advance(q);
    q = ar6.p;
  }
  return ParseConstResult { p: q, c: ast.ConstDecl { file: p.file, sp: span_tok(p, ar0.tok), vis: vis, is_pub: is_pub, name: r1.name, ty: r3.ty, init: r5.id } };
}

fn parse_type_decl(p: Parser, vis: i32, is_pub: bool) -> ParseTypeDeclResult {
  // Either:
  // - type alias: `type Name = TypeName;`
  // - union type decl (tagged union): `type Name = A: TA | B: TB;` (stage1 v0 only labeled form)
  let ar0: AdvanceResult = expect(p, lex.TokenKind.KwType);
  let r1: ParseIdentResult = parse_ident(ar0.p);
  let ar2: AdvanceResult = expect(r1.p, lex.TokenKind.Eq);

  // Disambiguation: union uses labeled arms `Ident :`.
  if kind_is(peek_kind(ar2.p), lex.TokenKind.Ident) && kind_is(peek2_kind(ar2.p), lex.TokenKind.Colon) {
    let mut q: Parser = ar2.p;
    let mut vars: Vec[ast.EnumVariantDecl] = Vec();
    while !q.has_err {
      let rlbl: ParseIdentResult = parse_ident(q);
      let arcol: AdvanceResult = expect(rlbl.p, lex.TokenKind.Colon);
      let rty: ParseTypeResult = parse_type_name(arcol.p);
      vars.push(ast.EnumVariantDecl { name: rlbl.name, fields: vec1_type(rty.ty) });
      q = rty.p;
      if kind_is(peek_kind(q), lex.TokenKind.Pipe) {
        let arbar: AdvanceResult = advance(q);
        q = arbar.p;
        continue;
      }
      break;
    }
    if kind_is(peek_kind(q), lex.TokenKind.Semicolon) {
      let arsemi: AdvanceResult = advance(q);
      q = arsemi.p;
    }
    return ParseTypeDeclResult {
      p: q,
      is_union: true,
      t: ast.TypeAliasDecl { file: "", sp: ast.span0(), vis: ast.vis_private(), is_pub: false, name: "", ty: ast.TypeName { parts: Vec(), args: Vec() } },
      e: ast.EnumDecl { file: p.file, sp: span_tok(p, ar0.tok), vis: vis, is_pub: is_pub, name: r1.name, type_params: Vec(), type_param_bounds: Vec(), const_where_bounds: Vec(), variants: vars },
    };
  }

  // Alias fallback.
  let r3: ParseTypeResult = parse_type_name(ar2.p);
  let mut q2: Parser = r3.p;
  if kind_is(peek_kind(q2), lex.TokenKind.Semicolon) {
    let ar4: AdvanceResult = advance(q2);
    q2 = ar4.p;
  }
  return ParseTypeDeclResult {
    p: q2,
    is_union: false,
    t: ast.TypeAliasDecl { file: p.file, sp: span_tok(p, ar0.tok), vis: vis, is_pub: is_pub, name: r1.name, ty: r3.ty },
    e: ast.EnumDecl { file: "", sp: ast.span0(), vis: ast.vis_private(), is_pub: false, name: "", type_params: Vec(), type_param_bounds: Vec(), const_where_bounds: Vec(), variants: Vec() },
  };
}

fn vec1_type(x: ast.TypeName) -> Vec[ast.TypeName] {
  let mut v: Vec[ast.TypeName] = Vec();
  v.push(x);
  return v;
}

fn parse_params(p: Parser) -> ParseParamsResult {
  let mut q: Parser = p;
  let mut params: Vec[ast.Param] = Vec();
  if kind_is(peek_kind(q), lex.TokenKind.RParen) {
    return ParseParamsResult { p: q, params: params };
  }
  while !q.has_err {
    let r1: ParseIdentResult = parse_ident(q);
    let ar2: AdvanceResult = expect(r1.p, lex.TokenKind.Colon);
    let r3: ParseTypeResult = parse_type_name(ar2.p);
    let mut pty: ast.TypeName = r3.ty;
    let mut q1: Parser = r3.p;
    if kind_is(peek_kind(q1), lex.TokenKind.DotDotDot) {
      let ar_pack: AdvanceResult = advance(q1);
      q1 = ar_pack.p;
      let mut pparts: Vec[String] = Vec();
      pparts.push("@pack");
      let mut pargs: Vec[ast.TypeName] = Vec();
      pargs.push(pty);
      pty = ast.TypeName { parts: pparts, args: pargs };
    }
    params.push(ast.Param { name: r1.name, ty: pty });
    q = q1;
    if kind_is(peek_kind(q), lex.TokenKind.Comma) {
      let ar4: AdvanceResult = advance(q);
      q = ar4.p;
      if kind_is(peek_kind(q), lex.TokenKind.RParen) {
        break;
      }
      continue;
    }
    break;
  }
  return ParseParamsResult { p: q, params: params };
}

fn is_ffi_target(s: String) -> bool {
  return s == "c" || s == "wasm";
}

fn is_cfg_key(s: String) -> bool {
  return s == "target_os" || s == "target_arch" || s == "target_ptr_bits";
}

fn parse_attr_arg_text(p: Parser) -> ParseStringResult {
  if kind_is(peek_kind(p), lex.TokenKind.Str) {
    return parse_string_inner(p);
  }
  if kind_is(peek_kind(p), lex.TokenKind.Int) {
    let ar: AdvanceResult = expect(p, lex.TokenKind.Int);
    return ParseStringResult { p: ar.p, s: lexeme(ar.p, ar.tok), at: ar.tok.start };
  }
  if kind_is(peek_kind(p), lex.TokenKind.Ident) {
    let ri: ParseIdentResult = parse_ident(p);
    return ParseStringResult { p: ri.p, s: ri.name, at: ri.at };
  }
  let mut q: Parser = p;
  q.has_err = true;
  q.err = ParseError.InvalidType(peek(p).start, "bad function attribute arguments");
  return ParseStringResult { p: q, s: "", at: peek(p).start };
}

fn set_method_ffi_attr_error(p: Parser) -> Parser {
  let mut q: Parser = p;
  q.has_err = true;
  q.err = ParseError.InvalidType(peek(p).start, "ffi attributes are only allowed on top-level fn");
  return q;
}

fn set_method_track_caller_attr_error(p: Parser) -> Parser {
  let mut q: Parser = p;
  q.has_err = true;
  q.err = ParseError.InvalidType(peek(p).start, "track_caller attribute is only allowed on top-level fn");
  return q;
}

fn set_method_cfg_attr_error(p: Parser) -> Parser {
  let mut q: Parser = p;
  q.has_err = true;
  q.err = ParseError.InvalidType(peek(p).start, "cfg attribute is only allowed on top-level fn");
  return q;
}

fn parse_top_fn_attrs(p: Parser) -> ParseTopFnAttrsResult {
  let mut q: Parser = p;
  let mut ffi_imports: Vec[ast.FfiImportAttr] = Vec();
  let mut ffi_exports: Vec[ast.FfiExportAttr] = Vec();
  let mut effects: Vec[ast.EffectAttr] = Vec();
  let mut resources: Vec[ast.ResourceAttr] = Vec();
  let mut cfgs: Vec[ast.CfgAttr] = Vec();
  let mut track_caller: bool = false;
  let mut deprecated_message: String = "";

  while !q.has_err && kind_is(peek_kind(q), lex.TokenKind.At) {
    let ar_at: AdvanceResult = expect(q, lex.TokenKind.At);
    let sp0: ast.Span = span_tok(q, ar_at.tok);
    let rn: ParseIdentResult = parse_ident(ar_at.p);
    let mut args: Vec[String] = Vec();
    let mut qa: Parser = rn.p;
    if kind_is(peek_kind(qa), lex.TokenKind.LParen) {
      let ar_l: AdvanceResult = advance(qa);
      qa = ar_l.p;
      if !kind_is(peek_kind(qa), lex.TokenKind.RParen) {
        while !qa.has_err {
          let rs: ParseStringResult = parse_attr_arg_text(qa);
          qa = rs.p;
          if qa.has_err {
            return ParseTopFnAttrsResult {
              p: qa,
              ffi_imports: ffi_imports,
              ffi_exports: ffi_exports,
              effects: effects,
              resources: resources,
              cfgs: cfgs,
              track_caller: track_caller,
              deprecated_message: deprecated_message,
            };
          }
          args.push(rs.s);
          if kind_is(peek_kind(qa), lex.TokenKind.Comma) {
            let ar_c: AdvanceResult = advance(qa);
            qa = ar_c.p;
            if kind_is(peek_kind(qa), lex.TokenKind.RParen) { break; }
            continue;
          }
          break;
        }
      }
      let ar_r: AdvanceResult = expect(qa, lex.TokenKind.RParen);
      q = ar_r.p;
    } else if rn.name == "track_caller" || rn.name == "deprecated" {
      q = qa;
    } else {
      let mut qe_l: Parser = qa;
      qe_l.has_err = true;
      qe_l.err = ParseError.UnexpectedToken(lex.TokenKind.LParen, peek_kind(qa), peek(qa).start);
      return ParseTopFnAttrsResult {
        p: qe_l,
        ffi_imports: ffi_imports,
        ffi_exports: ffi_exports,
        effects: effects,
        resources: resources,
        cfgs: cfgs,
        track_caller: track_caller,
        deprecated_message: deprecated_message,
      };
    }
    if q.has_err {
      return ParseTopFnAttrsResult {
        p: q,
        ffi_imports: ffi_imports,
        ffi_exports: ffi_exports,
        effects: effects,
        resources: resources,
        cfgs: cfgs,
        track_caller: track_caller,
        deprecated_message: deprecated_message,
      };
    }

    if rn.name == "ffi_import" {
      if args.len() == 2 && args.get(0) == "c" {
        ffi_imports.push(ast.FfiImportAttr { sp: sp0, target: "c", module: "", symbol: args.get(1) });
      } else if args.len() == 3 && args.get(0) == "wasm" {
        ffi_imports.push(ast.FfiImportAttr { sp: sp0, target: "wasm", module: args.get(1), symbol: args.get(2) });
      } else {
        let mut qe: Parser = q;
        qe.has_err = true;
        qe.err = ParseError.InvalidType(rn.at, "bad ffi attribute arguments");
        return ParseTopFnAttrsResult {
          p: qe,
          ffi_imports: ffi_imports,
          ffi_exports: ffi_exports,
          effects: effects,
          resources: resources,
          cfgs: cfgs,
          track_caller: track_caller,
          deprecated_message: deprecated_message,
        };
      }
    } else if rn.name == "ffi_export" {
      if args.len() == 2 && is_ffi_target(args.get(0)) {
        ffi_exports.push(ast.FfiExportAttr { sp: sp0, target: args.get(0), symbol: args.get(1) });
      } else {
        let mut qe2: Parser = q;
        qe2.has_err = true;
        qe2.err = ParseError.InvalidType(rn.at, "bad ffi attribute arguments");
        return ParseTopFnAttrsResult {
          p: qe2,
          ffi_imports: ffi_imports,
          ffi_exports: ffi_exports,
          effects: effects,
          resources: resources,
          cfgs: cfgs,
          track_caller: track_caller,
          deprecated_message: deprecated_message,
        };
      }
    } else if rn.name == "effect" {
      if args.len() == 1 && args.get(0) != "" {
        effects.push(ast.EffectAttr { sp: sp0, name: args.get(0) });
      } else {
        let mut qe4: Parser = q;
        qe4.has_err = true;
        qe4.err = ParseError.InvalidType(rn.at, "bad effect attribute arguments");
        return ParseTopFnAttrsResult {
          p: qe4,
          ffi_imports: ffi_imports,
          ffi_exports: ffi_exports,
          effects: effects,
          resources: resources,
          cfgs: cfgs,
          track_caller: track_caller,
          deprecated_message: deprecated_message,
        };
      }
    } else if rn.name == "cfg" {
      if args.len() == 2 && is_cfg_key(args.get(0)) && args.get(1) != "" {
        cfgs.push(ast.CfgAttr { sp: sp0, key: args.get(0), value: args.get(1) });
      } else {
        let mut qe_cfg: Parser = q;
        qe_cfg.has_err = true;
        qe_cfg.err = ParseError.InvalidType(rn.at, "bad cfg attribute arguments");
        return ParseTopFnAttrsResult {
          p: qe_cfg,
          ffi_imports: ffi_imports,
          ffi_exports: ffi_exports,
          effects: effects,
          resources: resources,
          cfgs: cfgs,
          track_caller: track_caller,
          deprecated_message: deprecated_message,
        };
      }
    } else if rn.name == "resource" {
      if args.len() == 2 && args.get(1) != "" {
        if args.get(0) == "read" {
          resources.push(ast.ResourceAttr { sp: sp0, kind: ast.resource_read(), name: args.get(1) });
        } else if args.get(0) == "write" {
          resources.push(ast.ResourceAttr { sp: sp0, kind: ast.resource_write(), name: args.get(1) });
        } else {
          let mut qe5: Parser = q;
          qe5.has_err = true;
          qe5.err = ParseError.InvalidType(rn.at, "bad resource attribute arguments");
          return ParseTopFnAttrsResult {
            p: qe5,
            ffi_imports: ffi_imports,
            ffi_exports: ffi_exports,
            effects: effects,
            resources: resources,
            cfgs: cfgs,
            track_caller: track_caller,
            deprecated_message: deprecated_message,
          };
        }
      } else {
        let mut qe6: Parser = q;
        qe6.has_err = true;
        qe6.err = ParseError.InvalidType(rn.at, "bad resource attribute arguments");
        return ParseTopFnAttrsResult {
          p: qe6,
          ffi_imports: ffi_imports,
          ffi_exports: ffi_exports,
          effects: effects,
          resources: resources,
          cfgs: cfgs,
          track_caller: track_caller,
          deprecated_message: deprecated_message,
        };
      }
    } else if rn.name == "track_caller" {
      if args.len() == 0 {
        track_caller = true;
      } else {
        let mut qe7: Parser = q;
        qe7.has_err = true;
        qe7.err = ParseError.InvalidType(rn.at, "track_caller takes no arguments");
        return ParseTopFnAttrsResult {
          p: qe7,
          ffi_imports: ffi_imports,
          ffi_exports: ffi_exports,
          effects: effects,
          resources: resources,
          cfgs: cfgs,
          track_caller: track_caller,
          deprecated_message: deprecated_message,
        };
      }
    } else if rn.name == "deprecated" {
      if args.len() == 0 {
        deprecated_message = "deprecated";
      } else if args.len() == 1 && args.get(0) != "" {
        deprecated_message = args.get(0);
      } else {
        let mut qe8: Parser = q;
        qe8.has_err = true;
        qe8.err = ParseError.InvalidType(rn.at, "bad deprecated attribute arguments");
        return ParseTopFnAttrsResult {
          p: qe8,
          ffi_imports: ffi_imports,
          ffi_exports: ffi_exports,
          effects: effects,
          resources: resources,
          cfgs: cfgs,
          track_caller: track_caller,
          deprecated_message: deprecated_message,
        };
      }
    } else {
      let mut qe3: Parser = q;
      qe3.has_err = true;
      qe3.err = ParseError.InvalidType(rn.at, "unknown function attribute");
      return ParseTopFnAttrsResult {
        p: qe3,
        ffi_imports: ffi_imports,
        ffi_exports: ffi_exports,
        effects: effects,
        resources: resources,
        cfgs: cfgs,
        track_caller: track_caller,
        deprecated_message: deprecated_message,
      };
    }
  }

  return ParseTopFnAttrsResult {
    p: q,
    ffi_imports: ffi_imports,
    ffi_exports: ffi_exports,
    effects: effects,
    resources: resources,
    cfgs: cfgs,
    track_caller: track_caller,
    deprecated_message: deprecated_message,
  };
}

fn parse_pub_marker(p: Parser) -> ParsePubResult {
  if !kind_is(peek_kind(p), lex.TokenKind.KwPub) {
    return ParsePubResult { p: p, vis: ast.vis_private(), is_pub: false };
  }
  let ar1: AdvanceResult = advance(p);
  let mut q: Parser = ar1.p;
  let mut vis: i32 = ast.vis_pub();
  if kind_is(peek_kind(q), lex.TokenKind.LParen) {
    let ar2: AdvanceResult = advance(q);
    let r3: ParseIdentResult = parse_ident(ar2.p);
    q = r3.p;
    if r3.name == "crate" {
      vis = ast.vis_crate();
    } else if r3.name == "super" {
      vis = ast.vis_super();
    } else {
      let mut qq: Parser = q;
      let at: i32 = peek(q).start;
      qq.has_err = true;
      qq.err = ParseError.UnexpectedToken(lex.TokenKind.Ident, peek_kind(q), at);
      q = qq;
    }
    let ar4: AdvanceResult = expect(q, lex.TokenKind.RParen);
    q = ar4.p;
  }
  return ParsePubResult { p: q, vis: vis, is_pub: true };
}

fn parse_program(p: Parser) -> ParseProgramResult {
  let mut q: Parser = p;
  let mut imports: Vec[ast.ImportDecl] = Vec();
  let mut types: Vec[ast.TypeAliasDecl] = Vec();
  let mut consts: Vec[ast.ConstDecl] = Vec();
  let mut structs: Vec[ast.StructDecl] = Vec();
  let mut enums: Vec[ast.EnumDecl] = Vec();
  let mut traits: Vec[ast.TraitDecl] = Vec();
  let mut impls: Vec[ast.ImplDecl] = Vec();
  let mut funcs: Vec[ast.FuncDecl] = Vec();

  while !q.has_err && !kind_is(peek_kind(q), lex.TokenKind.Eof) {
    if kind_is(peek_kind(q), lex.TokenKind.KwImport) {
      let r: ParseImportResult = parse_import_decl(q);
      q = r.p;
      imports.push(r.imp);
      continue;
    }

    let ar: ParseTopFnAttrsResult = parse_top_fn_attrs(q);
    q = ar.p;

    let pr: ParsePubResult = parse_pub_marker(q);
    q = pr.p;
    let is_pub: bool = pr.is_pub;
    let vis: i32 = pr.vis;

    let k: lex.TokenKind = peek_kind(q);
    let has_fn_attrs: bool =
      ar.ffi_imports.len() != 0 ||
      ar.ffi_exports.len() != 0 ||
      ar.effects.len() != 0 ||
      ar.resources.len() != 0 ||
      ar.cfgs.len() != 0 ||
      ar.track_caller ||
      ar.deprecated_message != "";
    if has_fn_attrs && !kind_is(k, lex.TokenKind.KwFn) && !kind_is(k, lex.TokenKind.KwAsync) {
      let mut qe: Parser = q;
      qe.has_err = true;
      qe.err = ParseError.UnexpectedToken(lex.TokenKind.KwFn, k, peek(q).start);
      q = qe;
      break;
    }

    if kind_is(k, lex.TokenKind.KwType) {
      let r: ParseTypeDeclResult = parse_type_decl(q, vis, is_pub);
      q = r.p;
      if r.is_union {
        enums.push(r.e);
      } else {
        types.push(r.t);
      }
    } else if kind_is(k, lex.TokenKind.KwConst) {
      let r: ParseConstResult = parse_const_decl(q, vis, is_pub);
      q = r.p;
      consts.push(r.c);
    } else if kind_is(k, lex.TokenKind.KwStruct) {
      let r: ParseStructResult = parse_struct_decl(q, vis, is_pub);
      q = r.p;
      structs.push(r.s);
    } else if kind_is(k, lex.TokenKind.KwEnum) {
      let r: ParseEnumResult = parse_enum_decl(q, vis, is_pub);
      q = r.p;
      enums.push(r.e);
    } else if kind_is(k, lex.TokenKind.KwTrait) {
      let r: ParseTraitResult = parse_trait_decl(q, vis, is_pub);
      q = r.p;
      traits.push(r.t);
    } else if kind_is(k, lex.TokenKind.KwImpl) {
      let r: ParseImplResult = parse_impl_decl(q);
      q = r.p;
      impls.push(r.i);
    } else {
      let r: ParseFnResult = parse_fn_decl(q, vis, is_pub, ar.ffi_imports, ar.ffi_exports, ar.effects, ar.resources, ar.cfgs, ar.track_caller, ar.deprecated_message);
      q = r.p;
      funcs.push(r.f);
    }
  }

  return ParseProgramResult { p: q, prog: ast.Program { imports: imports, types: types, consts: consts, structs: structs, enums: enums, traits: traits, impls: impls, funcs: funcs, exprs: q.exprs } };
}

pub fn parse_text_with_path(path: String, text: String) -> ParseResult {
  let lr: lex.LexResult = lex.lex_text(text);
  if !lex_err_none(lr.err) {
    return ParseResult { prog: ast.Program { imports: Vec(), types: Vec(), consts: Vec(), structs: Vec(), enums: Vec(), traits: Vec(), impls: Vec(), funcs: Vec(), exprs: ast.expr_pool() }, err: ParseError.Lex(lr.err) };
  }
  let p: Parser = Parser { file: path, text: text, toks: lr.tokens, pos: 0, has_err: false, err: ParseError.None, exprs: ast.expr_pool() };
  let r: ParseProgramResult = parse_program(p);
  return ParseResult { prog: r.prog, err: r.p.err };
}

pub fn parse_text(text: String) -> ParseResult {
  return parse_text_with_path("src/main.vox", text);
}
